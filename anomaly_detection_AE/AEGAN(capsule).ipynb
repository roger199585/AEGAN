{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from utils.tools import get_config, default_loader, is_image_file, normalize\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sys.path.append('../PerceptualSimilarity')\n",
    "import models as PerceptualSimilarity\n",
    "\n",
    "\n",
    "# personal library\n",
    "from networks import autoencoder, simulator, discriminator\n",
    "from dataloader import MVTecDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限制可以使用的 GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER parameters\n",
    "num_epochs = 50000\n",
    "batch_size = 32\n",
    "val_batch_size = 4\n",
    "ae_lr = 1e-4\n",
    "s_lr = 5e-4\n",
    "d_lr = 5e-4\n",
    "weight_decay = 1e-5\n",
    "UPSET=True\n",
    "expName = 'AEGAN-exp1'\n",
    "writer = SummaryWriter('checkpoint/'+expName)\n",
    "TYPE='capsule'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AEGAN-exp1(capsule)\n",
    "- AE fixed(weight from z_2x2x2_exp2)\n",
    "##### Losses:\n",
    "- d_loss = D(fake_pair).mean() - D(real_pair).mean() + gradient_penalty\n",
    "- g_loss = D(fake_pair).mean()\n",
    "\n",
    "### AEGAN-exp2(wood)\n",
    "- AE fixed(weight from z_2x2x2_exp2)\n",
    "##### Losses:\n",
    "- d_loss = D(fake_pair).mean() - D(real_pair).mean() + gradient_penalty\n",
    "- g_loss = D(fake_pair).mean()\n",
    "\n",
    "### AEGAN-exp3\n",
    "- 用 AE pretrain 至收斂後的 weight\n",
    "- lr 都設定成 5e-4\n",
    "- fake image 用 residual * blur image\n",
    "##### Losses:\n",
    "- d_loss = D(fake_pair).mean() - D(real_pair).mean() + gradient_penalty\n",
    "- g_loss = D(fake_pair).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='train')\n",
    "testDatset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='test')\n",
    "valDataset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='val')\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=valDataset,\n",
    "    batch_size=val_batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=trainDatset,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=testDatset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n",
      "Loading model from: /workspace/PerceptualSimilarity/models/weights/v0.1/alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "AE = autoencoder.Autoencoder().cuda()\n",
    "S = nn.DataParallel(simulator.Simulator(3, 8)).cuda()\n",
    "D = nn.DataParallel(discriminator.Discriminator(6, 16)).cuda()\n",
    "\n",
    "# Loss\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "L2_loss = nn.MSELoss(reduction='none')\n",
    "perceptual_loss = PerceptualSimilarity.PerceptualLoss(model='net-lin', net='alex', use_gpu=True, gpu_ids=[0])\n",
    "\n",
    "# Optimizer\n",
    "optimizer_AE = torch.optim.Adam(\n",
    "    AE.parameters(), \n",
    "    lr=ae_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optimizer_S = torch.optim.Adam(\n",
    "    S.parameters(), \n",
    "    lr=s_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    D.parameters(), \n",
    "    lr=d_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.load_state_dict(torch.load('./save_weight/AE-capsule-z-2x2-exp2/AE_35000.npy'), False)\n",
    "AE = nn.DataParallel(AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Solve: RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n",
    "torch.backends.cudnn.enabled = False \n",
    "\n",
    "# 拿掉煩人的 warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "\n",
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    # print \"real_data: \", real_data.size(), fake_data.size()\n",
    "    BATCH_SIZE = real_data.size(0)\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(BATCH_SIZE, real_data.nelement()//BATCH_SIZE).contiguous().view(BATCH_SIZE, 6, 256, 256)\n",
    "    alpha = alpha.cuda()\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(\n",
    "        outputs=disc_interpolates, \n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
    "        create_graph=True, \n",
    "        retain_graph=True, \n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "def difNormalize(input_matrix, threshold=None):\n",
    "    _min = input_matrix.min()\n",
    "    _max = input_matrix.max()\n",
    "    \n",
    "    input_matrix = (input_matrix - _min) / (_max - _min)\n",
    "    \n",
    "    if threshold != None:\n",
    "        input_matrix[input_matrix < threshold] = 0\n",
    "        input_matrix[input_matrix >= threshold] = 1\n",
    "        \n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50000] s_loss:747.3342 d_loss:-295.5438 val_s_loss:840.2493 val_d_loss:84.5695\n",
      "epoch [2/50000] s_loss:1152.9382 d_loss:-488.1425 val_s_loss:489.1107 val_d_loss:630.5182\n",
      "epoch [3/50000] s_loss:2168.2534 d_loss:-613.0686 val_s_loss:2424.2424 val_d_loss:66.4865\n",
      "epoch [4/50000] s_loss:749.6990 d_loss:-146.2791 val_s_loss:848.3413 val_d_loss:-201.4399\n",
      "epoch [5/50000] s_loss:1095.1962 d_loss:-264.9165 val_s_loss:1124.6499 val_d_loss:-217.4093\n",
      "epoch [6/50000] s_loss:1000.8130 d_loss:-384.5383 val_s_loss:1017.5125 val_d_loss:-310.1885\n",
      "epoch [7/50000] s_loss:1203.9900 d_loss:-405.1081 val_s_loss:1121.7062 val_d_loss:-166.5826\n",
      "epoch [8/50000] s_loss:863.7815 d_loss:-290.4417 val_s_loss:777.2556 val_d_loss:-136.2229\n",
      "epoch [9/50000] s_loss:756.5000 d_loss:-261.5663 val_s_loss:1135.0015 val_d_loss:-578.9932\n",
      "epoch [10/50000] s_loss:644.0583 d_loss:-227.8582 val_s_loss:772.8329 val_d_loss:-298.2228\n",
      "epoch [11/50000] s_loss:577.3713 d_loss:-193.6084 val_s_loss:908.8421 val_d_loss:-451.4731\n",
      "epoch [12/50000] s_loss:501.0077 d_loss:-150.5117 val_s_loss:560.7292 val_d_loss:-173.9227\n",
      "epoch [13/50000] s_loss:500.6118 d_loss:-144.4456 val_s_loss:524.6392 val_d_loss:-148.5635\n",
      "epoch [14/50000] s_loss:472.2179 d_loss:-144.0271 val_s_loss:571.6437 val_d_loss:-266.9576\n",
      "epoch [15/50000] s_loss:397.1043 d_loss:-133.7379 val_s_loss:480.1992 val_d_loss:-195.8078\n",
      "epoch [16/50000] s_loss:417.8664 d_loss:-145.9311 val_s_loss:802.8979 val_d_loss:-478.1166\n",
      "epoch [17/50000] s_loss:879.8271 d_loss:-323.8831 val_s_loss:2122.2202 val_d_loss:-1250.6445\n",
      "epoch [18/50000] s_loss:637.2220 d_loss:-201.3542 val_s_loss:485.8327 val_d_loss:-28.9843\n",
      "epoch [19/50000] s_loss:1024.3616 d_loss:-390.8235 val_s_loss:770.6422 val_d_loss:66.1028\n",
      "epoch [20/50000] s_loss:465.1360 d_loss:-131.9612 val_s_loss:234.3500 val_d_loss:8.7954\n",
      "epoch [21/50000] s_loss:618.3232 d_loss:-186.8389 val_s_loss:341.7370 val_d_loss:13.5051\n",
      "epoch [22/50000] s_loss:306.8956 d_loss:-176.9719 val_s_loss:273.5703 val_d_loss:-39.6202\n",
      "epoch [23/50000] s_loss:431.2502 d_loss:-216.1828 val_s_loss:523.1262 val_d_loss:-147.8575\n",
      "epoch [24/50000] s_loss:518.1119 d_loss:-232.1222 val_s_loss:474.5853 val_d_loss:-176.6573\n",
      "epoch [25/50000] s_loss:666.7076 d_loss:-223.4811 val_s_loss:668.7618 val_d_loss:-233.5390\n",
      "epoch [26/50000] s_loss:491.0167 d_loss:-243.4897 val_s_loss:501.6063 val_d_loss:-217.6139\n",
      "epoch [27/50000] s_loss:329.9447 d_loss:-247.6847 val_s_loss:262.0869 val_d_loss:-135.0396\n",
      "epoch [28/50000] s_loss:247.9229 d_loss:-206.1530 val_s_loss:151.9555 val_d_loss:-90.8949\n",
      "epoch [29/50000] s_loss:297.9757 d_loss:-203.6485 val_s_loss:229.6022 val_d_loss:-127.1902\n",
      "epoch [30/50000] s_loss:292.5114 d_loss:-200.9196 val_s_loss:234.1611 val_d_loss:-115.8077\n",
      "epoch [31/50000] s_loss:163.7742 d_loss:-199.2787 val_s_loss:-76.1946 val_d_loss:74.8440\n",
      "epoch [32/50000] s_loss:616.2146 d_loss:-218.2880 val_s_loss:699.9322 val_d_loss:-221.0896\n",
      "epoch [33/50000] s_loss:302.6943 d_loss:-179.6881 val_s_loss:226.0980 val_d_loss:-104.6526\n",
      "epoch [34/50000] s_loss:125.8878 d_loss:-188.1669 val_s_loss:91.0571 val_d_loss:-120.8536\n",
      "epoch [35/50000] s_loss:93.7569 d_loss:-147.7075 val_s_loss:68.5699 val_d_loss:-108.4574\n",
      "epoch [36/50000] s_loss:285.0344 d_loss:-152.2336 val_s_loss:357.2827 val_d_loss:-189.5249\n",
      "epoch [37/50000] s_loss:105.3938 d_loss:-139.6575 val_s_loss:63.1145 val_d_loss:-87.8555\n",
      "epoch [38/50000] s_loss:49.7293 d_loss:-136.6240 val_s_loss:43.1606 val_d_loss:-126.4095\n",
      "epoch [39/50000] s_loss:66.6275 d_loss:-124.5774 val_s_loss:46.7024 val_d_loss:-91.2457\n",
      "epoch [40/50000] s_loss:184.6736 d_loss:-123.6590 val_s_loss:173.8760 val_d_loss:-104.3994\n",
      "epoch [41/50000] s_loss:89.1719 d_loss:-128.1056 val_s_loss:138.7229 val_d_loss:-134.7498\n",
      "epoch [42/50000] s_loss:221.1012 d_loss:-129.6590 val_s_loss:365.3035 val_d_loss:-228.8491\n",
      "epoch [43/50000] s_loss:78.6542 d_loss:-118.6272 val_s_loss:64.3784 val_d_loss:-97.4763\n",
      "epoch [44/50000] s_loss:-13.7306 d_loss:-107.7533 val_s_loss:-114.7380 val_d_loss:-9.0050\n",
      "epoch [45/50000] s_loss:332.7499 d_loss:-135.7505 val_s_loss:343.6760 val_d_loss:-77.8758\n",
      "epoch [46/50000] s_loss:107.8457 d_loss:-106.3825 val_s_loss:110.8975 val_d_loss:-106.4684\n",
      "epoch [47/50000] s_loss:33.7951 d_loss:-115.2842 val_s_loss:-30.5573 val_d_loss:-45.0136\n",
      "epoch [48/50000] s_loss:187.5498 d_loss:-114.6280 val_s_loss:367.5958 val_d_loss:-240.8600\n",
      "epoch [49/50000] s_loss:-45.0056 d_loss:-99.5014 val_s_loss:-59.5665 val_d_loss:-104.0777\n",
      "epoch [50/50000] s_loss:37.1314 d_loss:-98.0828 val_s_loss:52.1695 val_d_loss:-95.9056\n",
      "epoch [51/50000] s_loss:78.9177 d_loss:-91.1493 val_s_loss:72.1980 val_d_loss:-80.6573\n",
      "epoch [52/50000] s_loss:38.5214 d_loss:-89.8712 val_s_loss:43.5793 val_d_loss:-89.1651\n",
      "epoch [53/50000] s_loss:20.9703 d_loss:-81.9831 val_s_loss:7.2803 val_d_loss:-70.4460\n",
      "epoch [54/50000] s_loss:-12.0181 d_loss:-78.1604 val_s_loss:-6.2606 val_d_loss:-96.0571\n",
      "epoch [55/50000] s_loss:3.4315 d_loss:-76.6623 val_s_loss:34.2173 val_d_loss:-111.4083\n",
      "epoch [56/50000] s_loss:-48.2068 d_loss:-71.6750 val_s_loss:-98.7436 val_d_loss:-22.9787\n",
      "epoch [57/50000] s_loss:12.2413 d_loss:-76.6754 val_s_loss:30.4342 val_d_loss:-79.9455\n",
      "epoch [58/50000] s_loss:-17.2202 d_loss:-69.9234 val_s_loss:-87.2377 val_d_loss:-21.0279\n",
      "epoch [59/50000] s_loss:-8.8642 d_loss:-68.5442 val_s_loss:-91.1634 val_d_loss:-8.1583\n",
      "epoch [60/50000] s_loss:68.4059 d_loss:-73.5906 val_s_loss:103.1356 val_d_loss:-98.8621\n",
      "epoch [61/50000] s_loss:-62.2586 d_loss:-68.2215 val_s_loss:-104.3234 val_d_loss:-38.5955\n",
      "epoch [62/50000] s_loss:345.5415 d_loss:-65.7994 val_s_loss:407.7253 val_d_loss:-82.0853\n",
      "epoch [63/50000] s_loss:125.1770 d_loss:-71.9283 val_s_loss:133.1009 val_d_loss:-71.5637\n",
      "epoch [64/50000] s_loss:34.5113 d_loss:-79.7776 val_s_loss:41.4809 val_d_loss:-81.4648\n",
      "epoch [65/50000] s_loss:-13.4700 d_loss:-77.9614 val_s_loss:-7.4231 val_d_loss:-82.0928\n",
      "epoch [66/50000] s_loss:-10.7079 d_loss:-68.9203 val_s_loss:14.3649 val_d_loss:-78.0486\n",
      "epoch [67/50000] s_loss:7.2305 d_loss:-91.4188 val_s_loss:68.1389 val_d_loss:-117.8822\n",
      "epoch [68/50000] s_loss:-9.0843 d_loss:-60.3692 val_s_loss:-72.4458 val_d_loss:-19.4602\n",
      "epoch [69/50000] s_loss:176.2348 d_loss:-53.0671 val_s_loss:265.4417 val_d_loss:-124.4819\n",
      "epoch [70/50000] s_loss:60.5005 d_loss:-57.8848 val_s_loss:45.9154 val_d_loss:-56.6368\n",
      "epoch [71/50000] s_loss:31.3150 d_loss:-55.0836 val_s_loss:29.6100 val_d_loss:-77.3538\n",
      "epoch [72/50000] s_loss:40.6994 d_loss:-90.9069 val_s_loss:53.7110 val_d_loss:-59.3907\n",
      "epoch [73/50000] s_loss:62.7528 d_loss:-59.1940 val_s_loss:27.4804 val_d_loss:-63.3099\n",
      "epoch [74/50000] s_loss:72.2311 d_loss:-76.7809 val_s_loss:72.3806 val_d_loss:-87.1708\n",
      "epoch [75/50000] s_loss:48.5731 d_loss:-49.5377 val_s_loss:-9.1860 val_d_loss:-22.0685\n",
      "epoch [76/50000] s_loss:9.3910 d_loss:-65.4492 val_s_loss:-26.2103 val_d_loss:-13.6793\n",
      "epoch [77/50000] s_loss:78.7146 d_loss:-69.2032 val_s_loss:34.2523 val_d_loss:-45.8157\n",
      "epoch [78/50000] s_loss:43.5859 d_loss:-101.5897 val_s_loss:-14.9593 val_d_loss:-21.4641\n",
      "epoch [79/50000] s_loss:-32.4420 d_loss:-46.4613 val_s_loss:-55.2221 val_d_loss:-27.8904\n",
      "epoch [80/50000] s_loss:-80.6677 d_loss:-47.5759 val_s_loss:-112.2899 val_d_loss:-12.3791\n",
      "epoch [81/50000] s_loss:96.1569 d_loss:-151.6824 val_s_loss:187.5883 val_d_loss:-125.6322\n",
      "epoch [82/50000] s_loss:24.1528 d_loss:-44.7699 val_s_loss:1.4114 val_d_loss:-35.5787\n",
      "epoch [83/50000] s_loss:-74.7157 d_loss:-49.6253 val_s_loss:-124.2445 val_d_loss:-7.6474\n",
      "epoch [84/50000] s_loss:137.2758 d_loss:-58.1071 val_s_loss:-2.1817 val_d_loss:-8.2491\n",
      "epoch [85/50000] s_loss:163.1608 d_loss:-324.4638 val_s_loss:218.7811 val_d_loss:-78.7930\n",
      "epoch [86/50000] s_loss:63.3654 d_loss:-39.4270 val_s_loss:40.7238 val_d_loss:-17.5839\n",
      "epoch [87/50000] s_loss:72.3092 d_loss:-41.5607 val_s_loss:-53.0639 val_d_loss:-19.3012\n",
      "epoch [88/50000] s_loss:49.2275 d_loss:-170.7584 val_s_loss:138.2542 val_d_loss:-112.4742\n",
      "epoch [89/50000] s_loss:126.2333 d_loss:-28.5232 val_s_loss:47.6352 val_d_loss:-59.3408\n",
      "epoch [90/50000] s_loss:108.3873 d_loss:-126.4677 val_s_loss:12.2615 val_d_loss:-34.1105\n",
      "epoch [91/50000] s_loss:33.3721 d_loss:-39.6152 val_s_loss:-71.7702 val_d_loss:-19.9443\n",
      "epoch [92/50000] s_loss:38.5823 d_loss:-136.3633 val_s_loss:4.6113 val_d_loss:-18.4606\n",
      "epoch [93/50000] s_loss:14.0710 d_loss:-179.4749 val_s_loss:-34.4151 val_d_loss:-16.7398\n",
      "epoch [94/50000] s_loss:9.2492 d_loss:-46.7478 val_s_loss:-37.5041 val_d_loss:-33.0758\n",
      "epoch [95/50000] s_loss:-17.1342 d_loss:-39.2734 val_s_loss:-85.0442 val_d_loss:-11.6933\n",
      "epoch [96/50000] s_loss:-87.1171 d_loss:-51.1339 val_s_loss:-93.1024 val_d_loss:-41.7282\n",
      "epoch [97/50000] s_loss:-109.2659 d_loss:-59.7643 val_s_loss:-102.0768 val_d_loss:-59.9506\n",
      "epoch [98/50000] s_loss:60.6489 d_loss:-33.1888 val_s_loss:36.7478 val_d_loss:-43.7004\n",
      "epoch [99/50000] s_loss:77.2792 d_loss:-82.3296 val_s_loss:-43.6264 val_d_loss:-47.0308\n",
      "epoch [100/50000] s_loss:-27.9214 d_loss:-131.1502 val_s_loss:-31.0686 val_d_loss:-66.8096\n",
      "epoch [101/50000] s_loss:-64.4921 d_loss:-36.7200 val_s_loss:-50.9732 val_d_loss:-60.5356\n",
      "epoch [102/50000] s_loss:-104.6434 d_loss:-45.3528 val_s_loss:-148.3162 val_d_loss:-14.3882\n",
      "epoch [103/50000] s_loss:-34.6080 d_loss:-63.8748 val_s_loss:-118.3182 val_d_loss:-8.8788\n",
      "epoch [104/50000] s_loss:-54.2221 d_loss:-168.9361 val_s_loss:-74.2460 val_d_loss:-19.3794\n",
      "epoch [105/50000] s_loss:-20.8217 d_loss:-120.1104 val_s_loss:43.1319 val_d_loss:-73.3098\n",
      "epoch [106/50000] s_loss:218.2430 d_loss:-135.2459 val_s_loss:33.5498 val_d_loss:-71.9508\n",
      "epoch [107/50000] s_loss:33.8807 d_loss:-24.2670 val_s_loss:-53.7864 val_d_loss:-6.5279\n",
      "epoch [108/50000] s_loss:-20.6804 d_loss:-139.2091 val_s_loss:-70.9768 val_d_loss:-31.6313\n",
      "epoch [109/50000] s_loss:-138.8822 d_loss:-33.5439 val_s_loss:-31.0178 val_d_loss:-112.7181\n",
      "epoch [110/50000] s_loss:-155.1506 d_loss:-43.8133 val_s_loss:-135.6606 val_d_loss:-45.2674\n",
      "epoch [111/50000] s_loss:-34.0148 d_loss:-25.8050 val_s_loss:-79.1647 val_d_loss:-9.8893\n",
      "epoch [112/50000] s_loss:-47.6815 d_loss:-71.6126 val_s_loss:-109.3239 val_d_loss:-12.1609\n",
      "epoch [113/50000] s_loss:-19.1184 d_loss:-82.9077 val_s_loss:-63.5161 val_d_loss:-9.2078\n",
      "epoch [114/50000] s_loss:-132.7050 d_loss:-47.4497 val_s_loss:-161.7311 val_d_loss:-12.1788\n",
      "epoch [115/50000] s_loss:176.1541 d_loss:-196.8802 val_s_loss:235.4311 val_d_loss:-161.3222\n",
      "epoch [116/50000] s_loss:50.8052 d_loss:-28.0666 val_s_loss:-2.0950 val_d_loss:-19.1627\n",
      "epoch [117/50000] s_loss:-36.1773 d_loss:-67.0165 val_s_loss:-15.8911 val_d_loss:-38.1699\n",
      "epoch [118/50000] s_loss:-69.6716 d_loss:-30.9103 val_s_loss:-83.6637 val_d_loss:-28.6696\n",
      "epoch [119/50000] s_loss:-61.1050 d_loss:-110.6223 val_s_loss:-65.7258 val_d_loss:-27.0536\n",
      "epoch [120/50000] s_loss:-69.3734 d_loss:-28.0281 val_s_loss:-95.4863 val_d_loss:-8.6812\n",
      "epoch [121/50000] s_loss:-110.6732 d_loss:-103.9791 val_s_loss:-131.4977 val_d_loss:-10.0959\n",
      "epoch [122/50000] s_loss:3.7936 d_loss:-40.2455 val_s_loss:-8.0191 val_d_loss:-73.1288\n",
      "epoch [123/50000] s_loss:-8.1996 d_loss:-22.4927 val_s_loss:2.7153 val_d_loss:-66.7885\n",
      "epoch [124/50000] s_loss:-77.7601 d_loss:-25.4257 val_s_loss:-73.5247 val_d_loss:-36.4617\n",
      "epoch [125/50000] s_loss:-51.4914 d_loss:-110.2772 val_s_loss:-162.8724 val_d_loss:-7.8815\n",
      "epoch [126/50000] s_loss:-115.2855 d_loss:-35.3570 val_s_loss:-82.2338 val_d_loss:-61.2688\n",
      "epoch [127/50000] s_loss:-161.8112 d_loss:-30.3954 val_s_loss:-135.8843 val_d_loss:-50.2484\n",
      "epoch [128/50000] s_loss:-92.0001 d_loss:-31.9367 val_s_loss:-142.7961 val_d_loss:-44.5351\n",
      "epoch [129/50000] s_loss:-135.8352 d_loss:-29.5176 val_s_loss:-111.4462 val_d_loss:-66.0657\n",
      "epoch [130/50000] s_loss:-116.4270 d_loss:-43.9731 val_s_loss:-72.1148 val_d_loss:-74.5225\n",
      "epoch [131/50000] s_loss:-139.6668 d_loss:-27.8932 val_s_loss:-183.7047 val_d_loss:-5.7098\n",
      "epoch [132/50000] s_loss:104.6182 d_loss:-37.5413 val_s_loss:-25.1611 val_d_loss:-18.3559\n",
      "epoch [133/50000] s_loss:36.2079 d_loss:-21.3723 val_s_loss:-11.1253 val_d_loss:-20.0753\n",
      "epoch [134/50000] s_loss:37.8489 d_loss:-119.3033 val_s_loss:-51.2019 val_d_loss:-7.1863\n",
      "epoch [135/50000] s_loss:-46.6365 d_loss:-89.2280 val_s_loss:-99.9146 val_d_loss:-15.3502\n",
      "epoch [136/50000] s_loss:-84.5020 d_loss:-32.5606 val_s_loss:-129.0908 val_d_loss:-18.2935\n",
      "epoch [137/50000] s_loss:-100.8276 d_loss:-56.6380 val_s_loss:-132.2761 val_d_loss:-4.7205\n",
      "epoch [138/50000] s_loss:-111.3217 d_loss:-35.8351 val_s_loss:-116.1887 val_d_loss:-23.7602\n",
      "epoch [139/50000] s_loss:-99.2457 d_loss:-32.9548 val_s_loss:-120.1912 val_d_loss:-8.9466\n",
      "epoch [140/50000] s_loss:251.3051 d_loss:-130.0897 val_s_loss:-27.4409 val_d_loss:-5.8011\n",
      "epoch [141/50000] s_loss:124.1342 d_loss:-112.1982 val_s_loss:84.2469 val_d_loss:-63.8117\n",
      "epoch [142/50000] s_loss:16.5569 d_loss:-25.9904 val_s_loss:-27.5094 val_d_loss:-8.0614\n",
      "epoch [143/50000] s_loss:-68.0232 d_loss:-33.6673 val_s_loss:-100.5861 val_d_loss:-22.1320\n",
      "epoch [144/50000] s_loss:-144.2728 d_loss:-34.3262 val_s_loss:-92.5767 val_d_loss:-68.8828\n",
      "epoch [145/50000] s_loss:-115.9876 d_loss:-94.9035 val_s_loss:-150.1676 val_d_loss:-1.5656\n",
      "epoch [146/50000] s_loss:136.1623 d_loss:-147.2657 val_s_loss:31.9348 val_d_loss:-36.0835\n",
      "epoch [147/50000] s_loss:-9.5091 d_loss:-109.0834 val_s_loss:55.7380 val_d_loss:-85.9545\n",
      "epoch [148/50000] s_loss:-52.5664 d_loss:-38.3293 val_s_loss:-76.0207 val_d_loss:-8.9652\n",
      "epoch [149/50000] s_loss:-43.9440 d_loss:-42.4360 val_s_loss:-129.2720 val_d_loss:-14.9147\n",
      "epoch [150/50000] s_loss:-64.4228 d_loss:-40.8599 val_s_loss:-91.7506 val_d_loss:-37.7478\n",
      "epoch [151/50000] s_loss:-102.8772 d_loss:-25.2955 val_s_loss:-68.9965 val_d_loss:-68.0340\n",
      "epoch [152/50000] s_loss:-115.1660 d_loss:-26.7409 val_s_loss:-138.3824 val_d_loss:-6.7926\n",
      "epoch [153/50000] s_loss:-61.6158 d_loss:-81.0174 val_s_loss:-155.9217 val_d_loss:-3.3021\n",
      "epoch [154/50000] s_loss:-76.0295 d_loss:-60.6694 val_s_loss:-116.1421 val_d_loss:-11.2772\n",
      "epoch [155/50000] s_loss:-90.0734 d_loss:-39.7227 val_s_loss:-38.1719 val_d_loss:-61.9921\n",
      "epoch [156/50000] s_loss:-86.2264 d_loss:-22.1745 val_s_loss:-135.6808 val_d_loss:-9.3542\n",
      "epoch [157/50000] s_loss:-8.0720 d_loss:-33.0390 val_s_loss:-28.6797 val_d_loss:-64.0613\n",
      "epoch [158/50000] s_loss:25.6388 d_loss:-106.4840 val_s_loss:-38.3830 val_d_loss:-5.1050\n",
      "epoch [159/50000] s_loss:-37.5769 d_loss:-23.6094 val_s_loss:-2.8587 val_d_loss:-51.4250\n",
      "epoch [160/50000] s_loss:-108.9389 d_loss:-32.5038 val_s_loss:-146.9041 val_d_loss:-3.8005\n",
      "epoch [161/50000] s_loss:-68.1416 d_loss:-27.2650 val_s_loss:-75.8407 val_d_loss:-22.1592\n",
      "epoch [162/50000] s_loss:-20.3373 d_loss:-53.4972 val_s_loss:-65.9472 val_d_loss:-6.8327\n",
      "epoch [163/50000] s_loss:-35.6277 d_loss:-37.3347 val_s_loss:-80.6331 val_d_loss:-7.0746\n",
      "epoch [164/50000] s_loss:-79.2964 d_loss:-53.5575 val_s_loss:-118.6920 val_d_loss:-4.6762\n",
      "epoch [165/50000] s_loss:-56.8802 d_loss:-34.2823 val_s_loss:-121.2397 val_d_loss:-9.8979\n",
      "epoch [166/50000] s_loss:-50.5643 d_loss:-20.9777 val_s_loss:-8.2891 val_d_loss:-68.5376\n",
      "epoch [167/50000] s_loss:-77.5794 d_loss:-26.9997 val_s_loss:-48.2991 val_d_loss:-44.8151\n",
      "epoch [168/50000] s_loss:-75.4913 d_loss:-29.9872 val_s_loss:-78.2692 val_d_loss:-46.3359\n",
      "epoch [169/50000] s_loss:-83.6496 d_loss:-37.7627 val_s_loss:-126.2553 val_d_loss:-7.3878\n",
      "epoch [170/50000] s_loss:-33.9893 d_loss:-41.8634 val_s_loss:-76.4314 val_d_loss:-10.1296\n",
      "epoch [171/50000] s_loss:-45.9264 d_loss:-29.2268 val_s_loss:-7.8101 val_d_loss:-55.5606\n",
      "epoch [172/50000] s_loss:-9.9288 d_loss:-35.0096 val_s_loss:-42.9927 val_d_loss:-45.2064\n",
      "epoch [173/50000] s_loss:-34.8951 d_loss:-26.0958 val_s_loss:-71.8597 val_d_loss:-9.5649\n",
      "epoch [174/50000] s_loss:-43.7198 d_loss:-40.8907 val_s_loss:3.2831 val_d_loss:-58.6146\n",
      "epoch [175/50000] s_loss:-69.0466 d_loss:-45.5240 val_s_loss:-27.4632 val_d_loss:-61.6539\n",
      "epoch [176/50000] s_loss:-69.0147 d_loss:-22.2675 val_s_loss:-93.4008 val_d_loss:-7.0188\n",
      "epoch [177/50000] s_loss:125.8087 d_loss:-118.6712 val_s_loss:88.8710 val_d_loss:-76.5113\n",
      "epoch [178/50000] s_loss:60.9154 d_loss:-25.0320 val_s_loss:120.9878 val_d_loss:-69.9404\n",
      "epoch [179/50000] s_loss:24.7260 d_loss:-48.3155 val_s_loss:-19.3361 val_d_loss:-9.9998\n",
      "epoch [180/50000] s_loss:-16.3690 d_loss:-29.5061 val_s_loss:-69.6031 val_d_loss:-5.4863\n",
      "epoch [181/50000] s_loss:-64.9103 d_loss:-29.2688 val_s_loss:-106.5627 val_d_loss:-6.5574\n",
      "epoch [182/50000] s_loss:-64.8709 d_loss:-44.6725 val_s_loss:-90.7641 val_d_loss:-2.9931\n",
      "epoch [183/50000] s_loss:18.6915 d_loss:-72.0348 val_s_loss:-51.3503 val_d_loss:-5.4258\n",
      "epoch [184/50000] s_loss:37.7963 d_loss:-22.7842 val_s_loss:40.3955 val_d_loss:-36.5235\n",
      "epoch [185/50000] s_loss:-25.6939 d_loss:-19.8124 val_s_loss:37.0500 val_d_loss:-66.4858\n",
      "epoch [186/50000] s_loss:-73.9778 d_loss:-26.4639 val_s_loss:-68.2960 val_d_loss:-26.4185\n",
      "epoch [187/50000] s_loss:-94.6875 d_loss:-32.8440 val_s_loss:-84.6533 val_d_loss:-20.2974\n",
      "epoch [188/50000] s_loss:-21.7505 d_loss:-21.2620 val_s_loss:-65.0603 val_d_loss:-9.0679\n",
      "epoch [189/50000] s_loss:-64.7542 d_loss:-30.9253 val_s_loss:-91.3751 val_d_loss:-6.8306\n",
      "epoch [190/50000] s_loss:6.6482 d_loss:-62.4354 val_s_loss:-49.5534 val_d_loss:-3.2420\n",
      "epoch [191/50000] s_loss:-9.3748 d_loss:-33.2187 val_s_loss:-27.2564 val_d_loss:-20.3739\n",
      "epoch [192/50000] s_loss:-59.2258 d_loss:-25.2817 val_s_loss:-41.6822 val_d_loss:-39.4090\n",
      "epoch [193/50000] s_loss:-52.7053 d_loss:-36.1638 val_s_loss:-81.6292 val_d_loss:-7.6251\n",
      "epoch [194/50000] s_loss:-65.3172 d_loss:-32.6898 val_s_loss:-83.1309 val_d_loss:-9.6323\n",
      "epoch [195/50000] s_loss:-72.7624 d_loss:-18.3524 val_s_loss:-97.5987 val_d_loss:-5.3165\n",
      "epoch [196/50000] s_loss:-67.4346 d_loss:-20.0521 val_s_loss:-87.1784 val_d_loss:-1.5798\n",
      "epoch [197/50000] s_loss:-71.5989 d_loss:-25.3399 val_s_loss:-17.2189 val_d_loss:-57.1416\n",
      "epoch [198/50000] s_loss:82.4397 d_loss:-32.6126 val_s_loss:149.5025 val_d_loss:-69.9479\n",
      "epoch [199/50000] s_loss:-16.4659 d_loss:-19.1506 val_s_loss:-37.6207 val_d_loss:-4.2369\n",
      "epoch [200/50000] s_loss:-49.5329 d_loss:-70.0310 val_s_loss:-81.9870 val_d_loss:-1.7601\n",
      "epoch [201/50000] s_loss:-14.8526 d_loss:-48.8948 val_s_loss:-33.1276 val_d_loss:3.1013\n",
      "epoch [202/50000] s_loss:54.7607 d_loss:-48.8023 val_s_loss:59.3117 val_d_loss:-54.1045\n",
      "epoch [203/50000] s_loss:1.9206 d_loss:-24.3397 val_s_loss:-33.0689 val_d_loss:-4.3950\n",
      "epoch [204/50000] s_loss:-40.6962 d_loss:-35.3554 val_s_loss:-68.4156 val_d_loss:-3.2642\n",
      "epoch [205/50000] s_loss:-75.3739 d_loss:-20.1641 val_s_loss:-89.9638 val_d_loss:-6.2680\n",
      "epoch [206/50000] s_loss:-38.2493 d_loss:-25.3278 val_s_loss:-94.7341 val_d_loss:-3.3385\n",
      "epoch [207/50000] s_loss:-52.6131 d_loss:-30.0424 val_s_loss:-92.2231 val_d_loss:-2.6699\n",
      "epoch [208/50000] s_loss:-40.7402 d_loss:-30.3922 val_s_loss:-19.7196 val_d_loss:-45.9954\n",
      "epoch [209/50000] s_loss:-43.0284 d_loss:-23.4878 val_s_loss:-57.7035 val_d_loss:-7.5446\n",
      "epoch [210/50000] s_loss:0.0036 d_loss:-23.0418 val_s_loss:-23.4445 val_d_loss:-6.0613\n",
      "epoch [211/50000] s_loss:48.9688 d_loss:-41.7674 val_s_loss:6.0320 val_d_loss:-4.5259\n",
      "epoch [212/50000] s_loss:81.2225 d_loss:-71.9797 val_s_loss:14.6460 val_d_loss:-3.7601\n",
      "epoch [213/50000] s_loss:31.4451 d_loss:-23.6753 val_s_loss:51.4985 val_d_loss:-35.6033\n",
      "epoch [214/50000] s_loss:22.4700 d_loss:-25.7275 val_s_loss:-24.1124 val_d_loss:-2.1122\n",
      "epoch [215/50000] s_loss:19.1508 d_loss:-68.1744 val_s_loss:41.6730 val_d_loss:-59.3197\n",
      "epoch [216/50000] s_loss:-15.2875 d_loss:-30.8408 val_s_loss:-31.5376 val_d_loss:-6.6616\n",
      "epoch [217/50000] s_loss:-23.0936 d_loss:-45.7523 val_s_loss:-44.8629 val_d_loss:-4.8498\n",
      "epoch [218/50000] s_loss:112.3883 d_loss:-17.0111 val_s_loss:-33.5784 val_d_loss:-3.4972\n",
      "epoch [219/50000] s_loss:6.4496 d_loss:-31.2451 val_s_loss:-25.0145 val_d_loss:-5.2741\n",
      "epoch [220/50000] s_loss:0.9356 d_loss:-26.7132 val_s_loss:-38.6592 val_d_loss:-1.9247\n",
      "epoch [221/50000] s_loss:-37.0444 d_loss:-36.2732 val_s_loss:-56.7389 val_d_loss:-4.2745\n",
      "epoch [222/50000] s_loss:37.1914 d_loss:-45.6786 val_s_loss:-5.5820 val_d_loss:-0.0790\n",
      "epoch [223/50000] s_loss:25.0307 d_loss:-33.0724 val_s_loss:38.0250 val_d_loss:-45.8292\n",
      "epoch [224/50000] s_loss:25.3487 d_loss:-48.0229 val_s_loss:88.4107 val_d_loss:-70.8894\n",
      "epoch [225/50000] s_loss:2.8293 d_loss:-27.4777 val_s_loss:-24.7487 val_d_loss:-6.7012\n",
      "epoch [226/50000] s_loss:5.1110 d_loss:-30.7444 val_s_loss:-35.9783 val_d_loss:-4.2998\n",
      "epoch [227/50000] s_loss:-23.9257 d_loss:-30.7705 val_s_loss:-15.2755 val_d_loss:-22.4864\n",
      "epoch [228/50000] s_loss:12.6258 d_loss:-22.0794 val_s_loss:-41.9565 val_d_loss:-3.9588\n",
      "epoch [229/50000] s_loss:3.2421 d_loss:-22.3024 val_s_loss:-23.3705 val_d_loss:-8.7669\n",
      "epoch [230/50000] s_loss:-11.7420 d_loss:-35.2407 val_s_loss:-46.6060 val_d_loss:-6.6357\n",
      "epoch [231/50000] s_loss:-16.9964 d_loss:-24.4529 val_s_loss:-62.4106 val_d_loss:-3.9282\n",
      "epoch [232/50000] s_loss:-17.6381 d_loss:-40.4933 val_s_loss:-56.2778 val_d_loss:1.6532\n",
      "epoch [233/50000] s_loss:-7.5702 d_loss:-36.2766 val_s_loss:-35.1219 val_d_loss:-10.9630\n",
      "epoch [234/50000] s_loss:5.2432 d_loss:-42.0257 val_s_loss:-20.1942 val_d_loss:-3.1721\n",
      "epoch [235/50000] s_loss:49.9325 d_loss:-17.2310 val_s_loss:-16.3042 val_d_loss:-4.1255\n",
      "epoch [236/50000] s_loss:0.0120 d_loss:-34.4446 val_s_loss:-16.6636 val_d_loss:-18.3978\n",
      "epoch [237/50000] s_loss:-10.6877 d_loss:-21.4663 val_s_loss:-44.4467 val_d_loss:-2.8234\n",
      "epoch [238/50000] s_loss:-42.5073 d_loss:-23.0097 val_s_loss:1.4643 val_d_loss:-49.0688\n",
      "epoch [239/50000] s_loss:-7.1533 d_loss:-21.1235 val_s_loss:-44.7976 val_d_loss:-1.8988\n",
      "epoch [240/50000] s_loss:-8.9978 d_loss:-21.4188 val_s_loss:-28.8038 val_d_loss:-3.5805\n",
      "epoch [241/50000] s_loss:-34.2768 d_loss:-22.9207 val_s_loss:-50.1810 val_d_loss:-2.5090\n",
      "epoch [242/50000] s_loss:-31.3873 d_loss:-22.3547 val_s_loss:-63.0138 val_d_loss:-4.0944\n",
      "epoch [243/50000] s_loss:8.2486 d_loss:-22.3829 val_s_loss:-54.3851 val_d_loss:-3.5741\n",
      "epoch [244/50000] s_loss:48.0959 d_loss:-118.5008 val_s_loss:18.5598 val_d_loss:-2.8180\n",
      "epoch [245/50000] s_loss:88.6219 d_loss:-24.7298 val_s_loss:90.3275 val_d_loss:-24.4754\n",
      "epoch [246/50000] s_loss:54.2677 d_loss:-22.5995 val_s_loss:36.1458 val_d_loss:-1.9526\n",
      "epoch [247/50000] s_loss:62.2081 d_loss:-27.1273 val_s_loss:24.3253 val_d_loss:-3.9319\n",
      "epoch [248/50000] s_loss:52.0782 d_loss:-53.9977 val_s_loss:63.2112 val_d_loss:-55.3323\n",
      "epoch [249/50000] s_loss:15.0935 d_loss:-31.2878 val_s_loss:-2.1325 val_d_loss:-2.2122\n",
      "epoch [250/50000] s_loss:21.4461 d_loss:-24.7250 val_s_loss:-24.0087 val_d_loss:-3.2871\n",
      "epoch [251/50000] s_loss:-14.5111 d_loss:-28.6571 val_s_loss:-47.8970 val_d_loss:-1.5260\n",
      "epoch [252/50000] s_loss:-3.7619 d_loss:-17.7506 val_s_loss:-52.0438 val_d_loss:-3.5229\n",
      "epoch [253/50000] s_loss:-28.6185 d_loss:-37.4387 val_s_loss:-45.5724 val_d_loss:-6.1647\n",
      "epoch [254/50000] s_loss:-35.6870 d_loss:-24.4615 val_s_loss:-55.8822 val_d_loss:-2.3983\n",
      "epoch [255/50000] s_loss:-40.2359 d_loss:-21.8411 val_s_loss:19.2705 val_d_loss:-60.2278\n",
      "epoch [256/50000] s_loss:-30.1323 d_loss:-25.0394 val_s_loss:18.3597 val_d_loss:-53.3916\n",
      "epoch [257/50000] s_loss:-23.0496 d_loss:-19.6139 val_s_loss:30.0373 val_d_loss:-48.4578\n",
      "epoch [258/50000] s_loss:-5.5567 d_loss:-30.3551 val_s_loss:-28.7206 val_d_loss:-3.5024\n",
      "epoch [259/50000] s_loss:34.4722 d_loss:-19.9705 val_s_loss:-40.0875 val_d_loss:-4.5151\n",
      "epoch [260/50000] s_loss:-26.7509 d_loss:-33.8000 val_s_loss:-43.6731 val_d_loss:-2.7100\n",
      "epoch [261/50000] s_loss:-9.9363 d_loss:-17.3237 val_s_loss:-27.0884 val_d_loss:-1.5638\n",
      "epoch [262/50000] s_loss:4.2140 d_loss:-20.0983 val_s_loss:-17.7494 val_d_loss:-0.3470\n",
      "epoch [263/50000] s_loss:17.2596 d_loss:-25.2546 val_s_loss:-11.5866 val_d_loss:-4.1243\n",
      "epoch [264/50000] s_loss:-9.8375 d_loss:-21.2236 val_s_loss:-33.7692 val_d_loss:-0.8130\n",
      "epoch [265/50000] s_loss:-4.9671 d_loss:-37.6738 val_s_loss:-26.7772 val_d_loss:-2.7773\n",
      "epoch [266/50000] s_loss:13.8839 d_loss:-19.8318 val_s_loss:-14.9203 val_d_loss:0.7512\n",
      "epoch [267/50000] s_loss:59.0901 d_loss:-47.2374 val_s_loss:-7.0044 val_d_loss:-0.9859\n",
      "epoch [268/50000] s_loss:7.7647 d_loss:-27.6014 val_s_loss:24.0334 val_d_loss:-26.6876\n",
      "epoch [269/50000] s_loss:-12.4699 d_loss:-26.3723 val_s_loss:-39.6331 val_d_loss:2.2660\n",
      "epoch [270/50000] s_loss:-40.3333 d_loss:-30.3440 val_s_loss:-54.5291 val_d_loss:-2.3307\n",
      "epoch [271/50000] s_loss:79.5864 d_loss:-41.3908 val_s_loss:108.9354 val_d_loss:-56.0436\n",
      "epoch [272/50000] s_loss:12.1464 d_loss:-30.2070 val_s_loss:-12.4615 val_d_loss:-3.1938\n",
      "epoch [273/50000] s_loss:3.8703 d_loss:-40.4400 val_s_loss:16.4230 val_d_loss:-34.5624\n",
      "epoch [274/50000] s_loss:-9.7169 d_loss:-30.9331 val_s_loss:-29.7982 val_d_loss:-3.2930\n",
      "epoch [275/50000] s_loss:36.0333 d_loss:-33.5885 val_s_loss:-25.3240 val_d_loss:-2.8839\n",
      "epoch [276/50000] s_loss:-9.4240 d_loss:-13.8116 val_s_loss:-26.9802 val_d_loss:-1.5933\n",
      "epoch [277/50000] s_loss:10.1719 d_loss:-20.8805 val_s_loss:-35.3819 val_d_loss:0.8917\n",
      "epoch [278/50000] s_loss:11.7452 d_loss:-65.1957 val_s_loss:23.3712 val_d_loss:-32.9924\n",
      "epoch [279/50000] s_loss:20.8553 d_loss:-40.7376 val_s_loss:79.1673 val_d_loss:-60.8503\n",
      "epoch [280/50000] s_loss:27.5147 d_loss:-19.6154 val_s_loss:59.0338 val_d_loss:-43.3704\n",
      "epoch [281/50000] s_loss:11.9952 d_loss:-19.7175 val_s_loss:1.2841 val_d_loss:-7.9187\n",
      "epoch [282/50000] s_loss:42.9574 d_loss:-21.4217 val_s_loss:-16.9284 val_d_loss:-1.3070\n",
      "epoch [283/50000] s_loss:31.6896 d_loss:-25.5441 val_s_loss:-12.7916 val_d_loss:0.1456\n",
      "epoch [284/50000] s_loss:24.3287 d_loss:-65.9375 val_s_loss:-1.3009 val_d_loss:-3.1872\n",
      "epoch [285/50000] s_loss:7.0896 d_loss:-41.6219 val_s_loss:-13.0480 val_d_loss:-1.5296\n",
      "epoch [286/50000] s_loss:19.8718 d_loss:-34.1285 val_s_loss:-28.8785 val_d_loss:-1.7686\n",
      "epoch [287/50000] s_loss:15.8954 d_loss:-29.4488 val_s_loss:-18.2477 val_d_loss:-3.2043\n",
      "epoch [288/50000] s_loss:12.5126 d_loss:-26.2104 val_s_loss:50.2451 val_d_loss:-41.6210\n",
      "epoch [289/50000] s_loss:12.3579 d_loss:-16.5714 val_s_loss:-23.9018 val_d_loss:3.3708\n",
      "epoch [290/50000] s_loss:12.2596 d_loss:-23.0854 val_s_loss:-22.7132 val_d_loss:-2.7391\n",
      "epoch [291/50000] s_loss:25.0956 d_loss:-27.4524 val_s_loss:-13.9724 val_d_loss:-2.7823\n",
      "epoch [292/50000] s_loss:1.1006 d_loss:-25.3937 val_s_loss:-15.6860 val_d_loss:-3.2057\n",
      "epoch [293/50000] s_loss:-3.4864 d_loss:-26.5554 val_s_loss:-29.6938 val_d_loss:-3.1307\n",
      "epoch [294/50000] s_loss:20.5200 d_loss:-20.5271 val_s_loss:25.0043 val_d_loss:-49.4379\n",
      "epoch [295/50000] s_loss:-1.9752 d_loss:-22.4707 val_s_loss:-44.2018 val_d_loss:4.1851\n",
      "epoch [296/50000] s_loss:10.8300 d_loss:-47.7266 val_s_loss:29.6549 val_d_loss:-44.1169\n",
      "epoch [297/50000] s_loss:-15.6151 d_loss:-32.1483 val_s_loss:-49.5834 val_d_loss:2.9134\n",
      "epoch [298/50000] s_loss:25.6780 d_loss:-23.0905 val_s_loss:-51.2471 val_d_loss:-5.1486\n",
      "epoch [299/50000] s_loss:-17.8445 d_loss:-21.4137 val_s_loss:24.6448 val_d_loss:-58.1385\n",
      "epoch [300/50000] s_loss:-18.1665 d_loss:-40.5122 val_s_loss:4.8287 val_d_loss:-37.0962\n",
      "epoch [301/50000] s_loss:33.7324 d_loss:-46.0429 val_s_loss:14.0805 val_d_loss:-31.1389\n",
      "epoch [302/50000] s_loss:83.7939 d_loss:-153.4507 val_s_loss:35.7395 val_d_loss:10.5349\n",
      "epoch [303/50000] s_loss:56.9962 d_loss:-22.4849 val_s_loss:93.5571 val_d_loss:-44.1061\n",
      "epoch [304/50000] s_loss:68.8235 d_loss:-40.7983 val_s_loss:63.8159 val_d_loss:-11.7309\n",
      "epoch [305/50000] s_loss:69.8530 d_loss:-13.1272 val_s_loss:38.7778 val_d_loss:-3.4565\n",
      "epoch [306/50000] s_loss:75.8072 d_loss:-42.4495 val_s_loss:29.5635 val_d_loss:-3.1158\n",
      "epoch [307/50000] s_loss:85.3768 d_loss:-21.3089 val_s_loss:102.0715 val_d_loss:-38.7660\n",
      "epoch [308/50000] s_loss:66.3114 d_loss:-29.6238 val_s_loss:33.3006 val_d_loss:2.3584\n",
      "epoch [309/50000] s_loss:72.5680 d_loss:-21.9050 val_s_loss:19.6179 val_d_loss:-0.7398\n",
      "epoch [310/50000] s_loss:77.2731 d_loss:-74.0596 val_s_loss:6.5261 val_d_loss:0.2909\n",
      "epoch [311/50000] s_loss:54.9351 d_loss:-21.6428 val_s_loss:59.7303 val_d_loss:-21.9910\n",
      "epoch [312/50000] s_loss:39.3830 d_loss:-33.5085 val_s_loss:10.1894 val_d_loss:-8.3357\n",
      "epoch [313/50000] s_loss:11.6134 d_loss:-38.6717 val_s_loss:-20.2579 val_d_loss:-2.4459\n",
      "epoch [314/50000] s_loss:1.1870 d_loss:-20.3320 val_s_loss:-11.0578 val_d_loss:-15.0642\n",
      "epoch [315/50000] s_loss:-26.8167 d_loss:-33.8764 val_s_loss:-52.3106 val_d_loss:-2.7900\n",
      "epoch [316/50000] s_loss:-18.6281 d_loss:-21.1914 val_s_loss:-33.6899 val_d_loss:-4.2704\n",
      "epoch [317/50000] s_loss:-17.9082 d_loss:-23.1338 val_s_loss:-40.4945 val_d_loss:0.2442\n",
      "epoch [318/50000] s_loss:4.9100 d_loss:-19.5852 val_s_loss:17.1473 val_d_loss:-34.4414\n",
      "epoch [319/50000] s_loss:-4.5436 d_loss:-66.2137 val_s_loss:-11.9244 val_d_loss:-7.7638\n",
      "epoch [320/50000] s_loss:-19.5850 d_loss:-17.6029 val_s_loss:22.4492 val_d_loss:-45.9013\n",
      "epoch [321/50000] s_loss:-7.4887 d_loss:-32.2282 val_s_loss:-6.4837 val_d_loss:-27.3148\n",
      "epoch [322/50000] s_loss:-19.5386 d_loss:-25.5904 val_s_loss:-34.2589 val_d_loss:-2.6465\n",
      "epoch [323/50000] s_loss:6.4036 d_loss:-19.8835 val_s_loss:-9.4804 val_d_loss:-3.1632\n",
      "epoch [324/50000] s_loss:-20.0504 d_loss:-15.2851 val_s_loss:-43.6633 val_d_loss:-1.2732\n",
      "epoch [325/50000] s_loss:-26.4153 d_loss:-27.0949 val_s_loss:-68.3904 val_d_loss:7.0136\n",
      "epoch [326/50000] s_loss:14.2099 d_loss:-20.2429 val_s_loss:-46.5724 val_d_loss:-2.4108\n",
      "epoch [327/50000] s_loss:92.5294 d_loss:-62.7293 val_s_loss:7.9859 val_d_loss:-3.6175\n",
      "epoch [328/50000] s_loss:37.9049 d_loss:-20.6973 val_s_loss:72.0819 val_d_loss:-47.5265\n",
      "epoch [329/50000] s_loss:32.3768 d_loss:-59.6736 val_s_loss:-7.3209 val_d_loss:-2.1160\n",
      "epoch [330/50000] s_loss:-6.2494 d_loss:-47.3959 val_s_loss:11.1593 val_d_loss:-42.8205\n",
      "epoch [331/50000] s_loss:39.2548 d_loss:-37.9126 val_s_loss:-65.1807 val_d_loss:-2.9023\n",
      "epoch [332/50000] s_loss:-50.5487 d_loss:-30.5826 val_s_loss:-13.3514 val_d_loss:-38.0118\n",
      "epoch [333/50000] s_loss:-27.4574 d_loss:-37.7271 val_s_loss:-76.5771 val_d_loss:-4.8925\n",
      "epoch [334/50000] s_loss:-56.6617 d_loss:-30.3122 val_s_loss:-64.6046 val_d_loss:-8.7826\n",
      "epoch [335/50000] s_loss:-39.7314 d_loss:-26.2829 val_s_loss:-9.6130 val_d_loss:-41.8842\n",
      "epoch [336/50000] s_loss:8.1717 d_loss:-20.7399 val_s_loss:41.2713 val_d_loss:-59.4475\n",
      "epoch [337/50000] s_loss:-13.9977 d_loss:-20.4039 val_s_loss:32.1091 val_d_loss:-49.4331\n",
      "epoch [338/50000] s_loss:-18.1838 d_loss:-19.3809 val_s_loss:-43.8909 val_d_loss:-1.2917\n",
      "epoch [339/50000] s_loss:-33.8925 d_loss:-24.0740 val_s_loss:-56.4045 val_d_loss:-1.4912\n",
      "epoch [340/50000] s_loss:-28.8967 d_loss:-22.7617 val_s_loss:-52.4484 val_d_loss:-4.2459\n",
      "epoch [341/50000] s_loss:3.5005 d_loss:-26.6867 val_s_loss:-27.9686 val_d_loss:-3.5408\n",
      "epoch [342/50000] s_loss:-0.0804 d_loss:-18.5983 val_s_loss:54.1379 val_d_loss:-52.1117\n",
      "epoch [343/50000] s_loss:-0.8091 d_loss:-18.0783 val_s_loss:-20.8956 val_d_loss:-0.1369\n",
      "epoch [344/50000] s_loss:-8.4118 d_loss:-19.6677 val_s_loss:-32.3208 val_d_loss:-4.1544\n",
      "epoch [345/50000] s_loss:10.9794 d_loss:-36.4745 val_s_loss:-14.5424 val_d_loss:-0.3851\n",
      "epoch [346/50000] s_loss:37.0569 d_loss:-25.0197 val_s_loss:21.6713 val_d_loss:-2.1748\n",
      "epoch [347/50000] s_loss:38.3819 d_loss:-14.5025 val_s_loss:15.1216 val_d_loss:-1.9526\n",
      "epoch [348/50000] s_loss:16.0429 d_loss:-24.7604 val_s_loss:-9.9269 val_d_loss:7.2314\n",
      "epoch [349/50000] s_loss:10.6247 d_loss:-30.2041 val_s_loss:-13.3546 val_d_loss:-0.5584\n",
      "epoch [350/50000] s_loss:31.6521 d_loss:-16.1253 val_s_loss:18.4410 val_d_loss:-1.4818\n",
      "epoch [351/50000] s_loss:32.4893 d_loss:-19.9328 val_s_loss:-2.1544 val_d_loss:-3.3645\n",
      "epoch [352/50000] s_loss:2.8100 d_loss:-19.6543 val_s_loss:-22.2130 val_d_loss:4.3177\n",
      "epoch [353/50000] s_loss:-1.3102 d_loss:-20.4570 val_s_loss:22.1152 val_d_loss:-30.5406\n",
      "epoch [354/50000] s_loss:-2.8323 d_loss:-28.4375 val_s_loss:-31.2855 val_d_loss:-0.5261\n",
      "epoch [355/50000] s_loss:-11.7786 d_loss:-24.1898 val_s_loss:-30.6048 val_d_loss:-1.6908\n",
      "epoch [356/50000] s_loss:7.6469 d_loss:-19.4398 val_s_loss:-8.5031 val_d_loss:-2.5402\n",
      "epoch [357/50000] s_loss:26.2566 d_loss:-21.5920 val_s_loss:37.6154 val_d_loss:-34.3373\n",
      "epoch [358/50000] s_loss:8.3381 d_loss:-15.1141 val_s_loss:46.3406 val_d_loss:-45.2423\n",
      "epoch [359/50000] s_loss:1.8055 d_loss:-22.5087 val_s_loss:32.0415 val_d_loss:-34.0398\n",
      "epoch [360/50000] s_loss:-27.3739 d_loss:-25.3282 val_s_loss:10.1211 val_d_loss:-41.5535\n",
      "epoch [361/50000] s_loss:-31.1435 d_loss:-34.6807 val_s_loss:-60.0794 val_d_loss:2.9476\n",
      "epoch [362/50000] s_loss:-1.7478 d_loss:-21.1001 val_s_loss:-17.1810 val_d_loss:-1.4631\n",
      "epoch [363/50000] s_loss:4.8576 d_loss:-21.0050 val_s_loss:-28.4400 val_d_loss:-0.1899\n",
      "epoch [364/50000] s_loss:2.8304 d_loss:-50.9383 val_s_loss:36.3307 val_d_loss:-33.2946\n",
      "epoch [365/50000] s_loss:20.0428 d_loss:-14.4931 val_s_loss:53.9896 val_d_loss:-40.1590\n",
      "epoch [366/50000] s_loss:75.4958 d_loss:-16.7422 val_s_loss:2.0546 val_d_loss:-1.5193\n",
      "epoch [367/50000] s_loss:42.8663 d_loss:-22.4813 val_s_loss:7.5197 val_d_loss:-2.4481\n",
      "epoch [368/50000] s_loss:28.5877 d_loss:-61.0212 val_s_loss:3.3323 val_d_loss:-3.6205\n",
      "epoch [369/50000] s_loss:12.1851 d_loss:-18.6276 val_s_loss:-12.5700 val_d_loss:-2.7747\n",
      "epoch [370/50000] s_loss:7.6583 d_loss:-20.8212 val_s_loss:-23.8718 val_d_loss:-3.5017\n",
      "epoch [371/50000] s_loss:46.4390 d_loss:-18.1955 val_s_loss:-9.3100 val_d_loss:-3.7249\n",
      "epoch [372/50000] s_loss:6.9412 d_loss:-18.7718 val_s_loss:-6.6188 val_d_loss:-4.7470\n",
      "epoch [373/50000] s_loss:14.2856 d_loss:-24.8323 val_s_loss:48.5077 val_d_loss:-51.4663\n",
      "epoch [374/50000] s_loss:34.1281 d_loss:-17.9918 val_s_loss:3.3399 val_d_loss:-1.3774\n",
      "epoch [375/50000] s_loss:29.9868 d_loss:-84.5540 val_s_loss:10.3786 val_d_loss:-1.5075\n",
      "epoch [376/50000] s_loss:22.2163 d_loss:-46.6772 val_s_loss:45.4125 val_d_loss:-36.7195\n",
      "epoch [377/50000] s_loss:50.5137 d_loss:-25.1740 val_s_loss:31.0267 val_d_loss:-1.5827\n",
      "epoch [378/50000] s_loss:35.1717 d_loss:-27.9469 val_s_loss:54.1465 val_d_loss:-26.9014\n",
      "epoch [379/50000] s_loss:38.3977 d_loss:-25.4322 val_s_loss:11.9325 val_d_loss:2.9239\n",
      "epoch [380/50000] s_loss:95.2818 d_loss:-35.0927 val_s_loss:54.9338 val_d_loss:3.4641\n",
      "epoch [381/50000] s_loss:60.2884 d_loss:-14.8027 val_s_loss:75.7993 val_d_loss:-35.1518\n",
      "epoch [382/50000] s_loss:86.9325 d_loss:-67.6608 val_s_loss:110.1265 val_d_loss:-61.5909\n",
      "epoch [383/50000] s_loss:60.0145 d_loss:-42.0413 val_s_loss:31.3929 val_d_loss:0.2799\n",
      "epoch [384/50000] s_loss:35.2435 d_loss:-21.4970 val_s_loss:6.6644 val_d_loss:-1.5804\n",
      "epoch [385/50000] s_loss:117.3118 d_loss:-84.7992 val_s_loss:56.0746 val_d_loss:-1.7680\n",
      "epoch [386/50000] s_loss:111.6353 d_loss:-205.7077 val_s_loss:101.7194 val_d_loss:-5.1870\n",
      "epoch [387/50000] s_loss:90.5730 d_loss:-15.0955 val_s_loss:111.2335 val_d_loss:-46.1063\n",
      "epoch [388/50000] s_loss:64.1473 d_loss:-22.4706 val_s_loss:99.5284 val_d_loss:-41.6079\n",
      "epoch [389/50000] s_loss:146.6761 d_loss:-27.0375 val_s_loss:92.0186 val_d_loss:-43.7684\n",
      "epoch [390/50000] s_loss:57.2776 d_loss:-25.1415 val_s_loss:36.1675 val_d_loss:-3.9050\n",
      "epoch [391/50000] s_loss:53.1003 d_loss:-22.3468 val_s_loss:25.9543 val_d_loss:-3.9415\n",
      "epoch [392/50000] s_loss:45.1597 d_loss:-19.5947 val_s_loss:17.4268 val_d_loss:-4.4578\n",
      "epoch [393/50000] s_loss:13.5714 d_loss:-45.8834 val_s_loss:-6.7591 val_d_loss:-1.1414\n",
      "epoch [394/50000] s_loss:42.2119 d_loss:-19.3614 val_s_loss:48.1297 val_d_loss:-27.5936\n",
      "epoch [395/50000] s_loss:40.1314 d_loss:-22.2224 val_s_loss:13.8203 val_d_loss:-3.4433\n",
      "epoch [396/50000] s_loss:22.1043 d_loss:-25.4658 val_s_loss:6.8864 val_d_loss:-2.7698\n",
      "epoch [397/50000] s_loss:7.1033 d_loss:-21.3409 val_s_loss:27.9943 val_d_loss:-24.3677\n",
      "epoch [398/50000] s_loss:46.9491 d_loss:-44.1852 val_s_loss:22.4401 val_d_loss:-27.6171\n",
      "epoch [399/50000] s_loss:43.1247 d_loss:-26.7245 val_s_loss:-2.1562 val_d_loss:-5.4447\n",
      "epoch [400/50000] s_loss:20.0009 d_loss:-15.2971 val_s_loss:10.6380 val_d_loss:-5.2115\n",
      "epoch [401/50000] s_loss:25.4428 d_loss:-22.1402 val_s_loss:56.7918 val_d_loss:-46.4407\n",
      "epoch [402/50000] s_loss:12.3012 d_loss:-26.4282 val_s_loss:-11.5274 val_d_loss:-2.9554\n",
      "epoch [403/50000] s_loss:18.1790 d_loss:-26.0784 val_s_loss:32.0971 val_d_loss:-37.1837\n",
      "epoch [404/50000] s_loss:13.9459 d_loss:-19.3006 val_s_loss:32.6926 val_d_loss:-41.7636\n",
      "epoch [405/50000] s_loss:38.7261 d_loss:-18.0939 val_s_loss:3.4193 val_d_loss:-2.4341\n",
      "epoch [406/50000] s_loss:26.1709 d_loss:-23.3264 val_s_loss:53.0329 val_d_loss:-39.3040\n",
      "epoch [407/50000] s_loss:28.8802 d_loss:-16.3466 val_s_loss:0.8196 val_d_loss:-3.9120\n",
      "epoch [408/50000] s_loss:46.3236 d_loss:-16.4867 val_s_loss:23.3066 val_d_loss:-4.9861\n",
      "epoch [409/50000] s_loss:38.3640 d_loss:-23.4976 val_s_loss:16.5384 val_d_loss:-2.5829\n",
      "epoch [410/50000] s_loss:37.4602 d_loss:-26.2870 val_s_loss:16.2165 val_d_loss:-2.5152\n",
      "epoch [411/50000] s_loss:20.6064 d_loss:-23.5094 val_s_loss:3.0733 val_d_loss:-2.9990\n",
      "epoch [412/50000] s_loss:45.1661 d_loss:-61.6202 val_s_loss:6.2026 val_d_loss:-4.7013\n",
      "epoch [413/50000] s_loss:67.6271 d_loss:-60.9736 val_s_loss:76.4838 val_d_loss:-38.6862\n",
      "epoch [414/50000] s_loss:51.8147 d_loss:-25.6449 val_s_loss:26.6225 val_d_loss:-1.6114\n",
      "epoch [415/50000] s_loss:39.4930 d_loss:-29.9082 val_s_loss:50.6104 val_d_loss:-27.9083\n",
      "epoch [416/50000] s_loss:21.6524 d_loss:-33.3857 val_s_loss:-1.7970 val_d_loss:7.0871\n",
      "epoch [417/50000] s_loss:55.2188 d_loss:-33.3781 val_s_loss:37.0020 val_d_loss:-8.9565\n",
      "epoch [418/50000] s_loss:39.1366 d_loss:-15.1697 val_s_loss:21.1259 val_d_loss:-1.2054\n",
      "epoch [419/50000] s_loss:9.8601 d_loss:-20.9876 val_s_loss:-7.0415 val_d_loss:-2.0746\n",
      "epoch [420/50000] s_loss:7.5608 d_loss:-23.7728 val_s_loss:-7.6773 val_d_loss:-3.3381\n",
      "epoch [421/50000] s_loss:8.4406 d_loss:-16.7000 val_s_loss:-10.5686 val_d_loss:1.1323\n",
      "epoch [422/50000] s_loss:58.1355 d_loss:-14.1241 val_s_loss:16.4273 val_d_loss:-1.2920\n",
      "epoch [423/50000] s_loss:48.7115 d_loss:-19.7987 val_s_loss:73.5357 val_d_loss:-40.3260\n",
      "epoch [424/50000] s_loss:25.2743 d_loss:-33.9034 val_s_loss:43.4306 val_d_loss:-21.7525\n",
      "epoch [425/50000] s_loss:13.2999 d_loss:-19.9672 val_s_loss:-13.4561 val_d_loss:-1.2500\n",
      "epoch [426/50000] s_loss:-0.4706 d_loss:-31.4278 val_s_loss:-18.0488 val_d_loss:-1.7198\n",
      "epoch [427/50000] s_loss:-1.8525 d_loss:-40.3248 val_s_loss:-22.2621 val_d_loss:-0.4272\n",
      "epoch [428/50000] s_loss:14.1557 d_loss:-31.2068 val_s_loss:-25.0802 val_d_loss:-1.1208\n",
      "epoch [429/50000] s_loss:15.1593 d_loss:-13.1912 val_s_loss:23.0683 val_d_loss:-29.1050\n",
      "epoch [430/50000] s_loss:32.7447 d_loss:-26.6353 val_s_loss:-6.9387 val_d_loss:-1.1656\n",
      "epoch [431/50000] s_loss:5.0721 d_loss:-24.4377 val_s_loss:-13.3738 val_d_loss:-1.8666\n",
      "epoch [432/50000] s_loss:-10.3489 d_loss:-23.1963 val_s_loss:-25.3867 val_d_loss:-3.2547\n",
      "epoch [433/50000] s_loss:-7.1096 d_loss:-37.4490 val_s_loss:15.3293 val_d_loss:-25.1024\n",
      "epoch [434/50000] s_loss:22.7181 d_loss:-16.8080 val_s_loss:5.3178 val_d_loss:-0.6305\n",
      "epoch [435/50000] s_loss:18.2724 d_loss:-16.7471 val_s_loss:-2.5910 val_d_loss:-1.6245\n",
      "epoch [436/50000] s_loss:20.0016 d_loss:-15.9902 val_s_loss:-16.9452 val_d_loss:-2.9536\n",
      "epoch [437/50000] s_loss:2.5554 d_loss:-16.1287 val_s_loss:26.4829 val_d_loss:-43.3450\n",
      "epoch [438/50000] s_loss:14.6134 d_loss:-19.6398 val_s_loss:27.7392 val_d_loss:-29.3747\n",
      "epoch [439/50000] s_loss:13.1894 d_loss:-18.6150 val_s_loss:26.0915 val_d_loss:-31.4169\n",
      "epoch [440/50000] s_loss:18.8601 d_loss:-15.2308 val_s_loss:-6.0620 val_d_loss:0.4423\n",
      "epoch [441/50000] s_loss:11.7189 d_loss:-16.4852 val_s_loss:-3.9301 val_d_loss:-2.2437\n",
      "epoch [442/50000] s_loss:32.4033 d_loss:-22.1671 val_s_loss:14.9472 val_d_loss:-2.4658\n",
      "epoch [443/50000] s_loss:28.5701 d_loss:-19.5376 val_s_loss:8.9997 val_d_loss:-1.9671\n",
      "epoch [444/50000] s_loss:22.8921 d_loss:-36.4175 val_s_loss:33.9252 val_d_loss:-24.3918\n",
      "epoch [445/50000] s_loss:41.9088 d_loss:-17.8607 val_s_loss:1.6449 val_d_loss:-1.7039\n",
      "epoch [446/50000] s_loss:26.5955 d_loss:-46.8109 val_s_loss:33.4206 val_d_loss:-19.4041\n",
      "epoch [447/50000] s_loss:23.9312 d_loss:-15.5010 val_s_loss:2.3561 val_d_loss:-0.9215\n",
      "epoch [448/50000] s_loss:24.9290 d_loss:-31.1241 val_s_loss:45.3129 val_d_loss:-30.8832\n",
      "epoch [449/50000] s_loss:44.1940 d_loss:-20.3053 val_s_loss:20.7421 val_d_loss:-0.2347\n",
      "epoch [450/50000] s_loss:53.4368 d_loss:-20.8385 val_s_loss:40.2204 val_d_loss:-5.2391\n",
      "epoch [451/50000] s_loss:45.4999 d_loss:-24.0875 val_s_loss:54.1032 val_d_loss:-27.8041\n",
      "epoch [452/50000] s_loss:31.7008 d_loss:-29.9596 val_s_loss:6.4176 val_d_loss:-5.2667\n",
      "epoch [453/50000] s_loss:34.6585 d_loss:-27.7765 val_s_loss:58.1807 val_d_loss:-36.6399\n",
      "epoch [454/50000] s_loss:38.3779 d_loss:-25.1824 val_s_loss:67.8910 val_d_loss:-33.3868\n",
      "epoch [455/50000] s_loss:19.8945 d_loss:-20.6119 val_s_loss:8.5431 val_d_loss:0.6283\n",
      "epoch [456/50000] s_loss:7.8057 d_loss:-17.4040 val_s_loss:-12.6220 val_d_loss:-3.9039\n",
      "epoch [457/50000] s_loss:12.8006 d_loss:-40.4348 val_s_loss:-5.9429 val_d_loss:2.8860\n",
      "epoch [458/50000] s_loss:51.3236 d_loss:-19.8344 val_s_loss:74.3628 val_d_loss:-36.6556\n",
      "epoch [459/50000] s_loss:31.2878 d_loss:-21.5187 val_s_loss:67.9274 val_d_loss:-42.8691\n",
      "epoch [460/50000] s_loss:7.6303 d_loss:-26.3703 val_s_loss:23.6926 val_d_loss:-17.5195\n",
      "epoch [461/50000] s_loss:10.6943 d_loss:-34.6909 val_s_loss:20.3932 val_d_loss:-26.6427\n",
      "epoch [462/50000] s_loss:20.2478 d_loss:-18.2242 val_s_loss:0.6381 val_d_loss:-1.4639\n",
      "epoch [463/50000] s_loss:32.8724 d_loss:-14.3291 val_s_loss:10.8604 val_d_loss:-2.6146\n",
      "epoch [464/50000] s_loss:18.3223 d_loss:-27.0377 val_s_loss:-8.2016 val_d_loss:-2.4608\n",
      "epoch [465/50000] s_loss:0.5264 d_loss:-19.6904 val_s_loss:-16.2555 val_d_loss:-2.2254\n",
      "epoch [466/50000] s_loss:4.7777 d_loss:-19.2384 val_s_loss:-18.9695 val_d_loss:4.4972\n",
      "epoch [467/50000] s_loss:-4.4262 d_loss:-40.3438 val_s_loss:-19.9879 val_d_loss:-2.4148\n",
      "epoch [468/50000] s_loss:-5.9036 d_loss:-26.8508 val_s_loss:-19.2753 val_d_loss:-2.1731\n",
      "epoch [469/50000] s_loss:11.1327 d_loss:-21.2507 val_s_loss:42.8218 val_d_loss:-42.9516\n",
      "epoch [470/50000] s_loss:32.6498 d_loss:-22.3189 val_s_loss:-5.6172 val_d_loss:-0.6479\n",
      "epoch [471/50000] s_loss:16.9448 d_loss:-16.8134 val_s_loss:33.1373 val_d_loss:-26.3998\n",
      "epoch [472/50000] s_loss:12.4748 d_loss:-22.9755 val_s_loss:11.7728 val_d_loss:-11.0868\n",
      "epoch [473/50000] s_loss:7.4840 d_loss:-21.9276 val_s_loss:-13.7075 val_d_loss:-2.1947\n",
      "epoch [474/50000] s_loss:-8.5520 d_loss:-19.4677 val_s_loss:-8.7054 val_d_loss:-9.8631\n",
      "epoch [475/50000] s_loss:-10.1939 d_loss:-18.2327 val_s_loss:-5.6125 val_d_loss:-9.6292\n",
      "epoch [476/50000] s_loss:8.4642 d_loss:-18.3650 val_s_loss:-12.8764 val_d_loss:-0.2786\n",
      "epoch [477/50000] s_loss:7.4428 d_loss:-25.6031 val_s_loss:-10.2350 val_d_loss:-2.4061\n",
      "epoch [478/50000] s_loss:21.6237 d_loss:-18.5332 val_s_loss:0.0206 val_d_loss:-1.8983\n",
      "epoch [479/50000] s_loss:7.0361 d_loss:-15.6546 val_s_loss:-5.0596 val_d_loss:-1.0428\n",
      "epoch [480/50000] s_loss:10.7844 d_loss:-32.9045 val_s_loss:29.0700 val_d_loss:-22.4921\n",
      "epoch [481/50000] s_loss:28.5301 d_loss:-13.6652 val_s_loss:9.2357 val_d_loss:1.0497\n",
      "epoch [482/50000] s_loss:34.5530 d_loss:-14.8949 val_s_loss:52.5549 val_d_loss:-27.4789\n",
      "epoch [483/50000] s_loss:22.2578 d_loss:-16.9493 val_s_loss:4.2510 val_d_loss:-2.2629\n",
      "epoch [484/50000] s_loss:7.2736 d_loss:-13.3678 val_s_loss:-5.9866 val_d_loss:-1.4803\n",
      "epoch [485/50000] s_loss:12.0813 d_loss:-17.7135 val_s_loss:-7.5478 val_d_loss:-3.2090\n",
      "epoch [486/50000] s_loss:17.7931 d_loss:-38.2728 val_s_loss:47.5823 val_d_loss:-36.9830\n",
      "epoch [487/50000] s_loss:43.2396 d_loss:-11.6653 val_s_loss:22.1970 val_d_loss:1.2124\n",
      "epoch [488/50000] s_loss:24.3456 d_loss:-17.6833 val_s_loss:3.2148 val_d_loss:-0.2183\n",
      "epoch [489/50000] s_loss:19.8626 d_loss:-14.6716 val_s_loss:3.4638 val_d_loss:-2.4676\n",
      "epoch [490/50000] s_loss:11.4727 d_loss:-24.7391 val_s_loss:13.7069 val_d_loss:-15.0583\n",
      "epoch [491/50000] s_loss:2.7700 d_loss:-24.3307 val_s_loss:-5.7743 val_d_loss:2.2480\n",
      "epoch [492/50000] s_loss:80.6447 d_loss:-34.3587 val_s_loss:66.3538 val_d_loss:4.4271\n",
      "epoch [493/50000] s_loss:102.7556 d_loss:-13.3665 val_s_loss:74.4919 val_d_loss:-1.4800\n",
      "epoch [494/50000] s_loss:82.0004 d_loss:-15.2722 val_s_loss:60.1047 val_d_loss:-1.2357\n",
      "epoch [495/50000] s_loss:68.1261 d_loss:-21.2070 val_s_loss:104.3977 val_d_loss:-47.5039\n",
      "epoch [496/50000] s_loss:56.6899 d_loss:-14.4794 val_s_loss:37.7828 val_d_loss:-2.8185\n",
      "epoch [497/50000] s_loss:28.4671 d_loss:-14.9503 val_s_loss:11.5255 val_d_loss:3.6432\n",
      "epoch [498/50000] s_loss:20.3486 d_loss:-17.5362 val_s_loss:-6.5504 val_d_loss:1.9366\n",
      "epoch [499/50000] s_loss:2.5460 d_loss:-36.4218 val_s_loss:-10.2701 val_d_loss:-2.7569\n",
      "epoch [500/50000] s_loss:52.4527 d_loss:-13.1324 val_s_loss:91.2641 val_d_loss:-41.6360\n",
      "epoch [501/50000] s_loss:-10.0127 d_loss:-16.0212 val_s_loss:-1.8156 val_d_loss:-15.0871\n",
      "epoch [502/50000] s_loss:-9.6362 d_loss:-13.3695 val_s_loss:-22.3502 val_d_loss:-2.8295\n",
      "epoch [503/50000] s_loss:15.4406 d_loss:-14.3678 val_s_loss:26.6890 val_d_loss:-32.1298\n",
      "epoch [504/50000] s_loss:17.6989 d_loss:-18.4773 val_s_loss:1.3500 val_d_loss:-2.3221\n",
      "epoch [505/50000] s_loss:6.7343 d_loss:-13.2817 val_s_loss:-3.5393 val_d_loss:-0.8635\n",
      "epoch [506/50000] s_loss:1.8057 d_loss:-14.6136 val_s_loss:-13.2162 val_d_loss:0.8938\n",
      "epoch [507/50000] s_loss:5.2556 d_loss:-18.6059 val_s_loss:-7.9912 val_d_loss:-1.7308\n",
      "epoch [508/50000] s_loss:3.3832 d_loss:-13.7322 val_s_loss:-9.5116 val_d_loss:-2.9976\n",
      "epoch [509/50000] s_loss:15.8813 d_loss:-16.3236 val_s_loss:44.8351 val_d_loss:-30.1747\n",
      "epoch [510/50000] s_loss:25.4088 d_loss:-13.5366 val_s_loss:14.2896 val_d_loss:-0.5038\n",
      "epoch [511/50000] s_loss:21.1926 d_loss:-16.3954 val_s_loss:37.6858 val_d_loss:-26.1571\n",
      "epoch [512/50000] s_loss:31.3179 d_loss:-17.9005 val_s_loss:2.7328 val_d_loss:-1.5390\n",
      "epoch [513/50000] s_loss:12.2057 d_loss:-11.7746 val_s_loss:-3.0092 val_d_loss:0.2031\n",
      "epoch [514/50000] s_loss:41.0671 d_loss:-19.1423 val_s_loss:66.3225 val_d_loss:-38.3842\n",
      "epoch [515/50000] s_loss:26.4289 d_loss:-19.1562 val_s_loss:17.2254 val_d_loss:-1.2721\n",
      "epoch [516/50000] s_loss:16.7945 d_loss:-17.6036 val_s_loss:7.7590 val_d_loss:-2.8777\n",
      "epoch [517/50000] s_loss:12.5210 d_loss:-12.2981 val_s_loss:-0.3378 val_d_loss:-0.6237\n",
      "epoch [518/50000] s_loss:49.4505 d_loss:-33.3157 val_s_loss:3.9852 val_d_loss:-1.7274\n",
      "epoch [519/50000] s_loss:12.9483 d_loss:-12.7217 val_s_loss:-2.0525 val_d_loss:-2.2898\n",
      "epoch [520/50000] s_loss:22.0759 d_loss:-15.9010 val_s_loss:39.7747 val_d_loss:-21.3821\n",
      "epoch [521/50000] s_loss:22.5021 d_loss:-18.0179 val_s_loss:3.9729 val_d_loss:-1.1352\n",
      "epoch [522/50000] s_loss:11.1770 d_loss:-28.4016 val_s_loss:-0.0940 val_d_loss:-1.9326\n",
      "epoch [523/50000] s_loss:4.3325 d_loss:-20.5581 val_s_loss:-12.8491 val_d_loss:-1.2670\n",
      "epoch [524/50000] s_loss:13.6503 d_loss:-13.1057 val_s_loss:-17.3350 val_d_loss:-2.9484\n",
      "epoch [525/50000] s_loss:19.9108 d_loss:-61.1763 val_s_loss:-14.3573 val_d_loss:0.0483\n",
      "epoch [526/50000] s_loss:23.6139 d_loss:-13.8768 val_s_loss:15.4714 val_d_loss:-12.4566\n",
      "epoch [527/50000] s_loss:46.7162 d_loss:-15.2441 val_s_loss:16.7628 val_d_loss:-1.0442\n",
      "epoch [528/50000] s_loss:42.1791 d_loss:-20.2523 val_s_loss:26.6982 val_d_loss:-4.2532\n",
      "epoch [529/50000] s_loss:22.1568 d_loss:-19.5775 val_s_loss:10.3948 val_d_loss:1.7711\n",
      "epoch [530/50000] s_loss:38.3163 d_loss:-30.9248 val_s_loss:14.4614 val_d_loss:-0.1175\n",
      "epoch [531/50000] s_loss:68.0970 d_loss:-15.9123 val_s_loss:47.8953 val_d_loss:-3.0618\n",
      "epoch [532/50000] s_loss:60.6531 d_loss:-15.4443 val_s_loss:63.4251 val_d_loss:-15.7906\n",
      "epoch [533/50000] s_loss:52.8515 d_loss:-21.8926 val_s_loss:31.6402 val_d_loss:-2.6033\n",
      "epoch [534/50000] s_loss:44.3462 d_loss:-20.5656 val_s_loss:59.0606 val_d_loss:-19.4391\n",
      "epoch [535/50000] s_loss:24.3979 d_loss:-15.0436 val_s_loss:11.8323 val_d_loss:-3.9998\n",
      "epoch [536/50000] s_loss:8.4156 d_loss:-14.5786 val_s_loss:-4.3053 val_d_loss:-2.9665\n",
      "epoch [537/50000] s_loss:14.9798 d_loss:-15.8869 val_s_loss:-3.4940 val_d_loss:-3.7901\n",
      "epoch [538/50000] s_loss:17.1711 d_loss:-11.8852 val_s_loss:3.9315 val_d_loss:-3.3629\n",
      "epoch [539/50000] s_loss:22.6240 d_loss:-20.3104 val_s_loss:26.2080 val_d_loss:-12.0386\n",
      "epoch [540/50000] s_loss:8.8486 d_loss:-10.9835 val_s_loss:-1.2948 val_d_loss:-1.1724\n",
      "epoch [541/50000] s_loss:19.0903 d_loss:-15.3452 val_s_loss:-5.4594 val_d_loss:-3.3248\n",
      "epoch [542/50000] s_loss:4.2995 d_loss:-12.9979 val_s_loss:-10.0821 val_d_loss:-2.8595\n",
      "epoch [543/50000] s_loss:12.4885 d_loss:-25.4058 val_s_loss:5.0166 val_d_loss:-0.6845\n",
      "epoch [544/50000] s_loss:3.5923 d_loss:-17.3256 val_s_loss:2.8342 val_d_loss:-10.2424\n",
      "epoch [545/50000] s_loss:8.3088 d_loss:-18.9413 val_s_loss:-8.4670 val_d_loss:-3.5253\n",
      "epoch [546/50000] s_loss:20.0500 d_loss:-10.4779 val_s_loss:11.6142 val_d_loss:-1.5338\n",
      "epoch [547/50000] s_loss:19.6936 d_loss:-11.3000 val_s_loss:35.6875 val_d_loss:-26.7145\n",
      "epoch [548/50000] s_loss:9.6566 d_loss:-15.3266 val_s_loss:-8.8988 val_d_loss:-2.4326\n",
      "epoch [549/50000] s_loss:19.9641 d_loss:-13.3916 val_s_loss:7.2380 val_d_loss:-2.2611\n",
      "epoch [550/50000] s_loss:16.5350 d_loss:-12.0288 val_s_loss:6.8806 val_d_loss:-2.3530\n",
      "epoch [551/50000] s_loss:19.7985 d_loss:-15.1537 val_s_loss:0.7774 val_d_loss:-1.4634\n",
      "epoch [552/50000] s_loss:3.0345 d_loss:-15.2040 val_s_loss:-8.2553 val_d_loss:-2.4990\n",
      "epoch [553/50000] s_loss:12.8786 d_loss:-13.6929 val_s_loss:1.8327 val_d_loss:-3.3727\n",
      "epoch [554/50000] s_loss:1.8929 d_loss:-20.5326 val_s_loss:-10.0736 val_d_loss:-3.7189\n",
      "epoch [555/50000] s_loss:9.2071 d_loss:-27.2136 val_s_loss:45.3355 val_d_loss:-45.3150\n",
      "epoch [556/50000] s_loss:33.7166 d_loss:-13.1642 val_s_loss:18.2885 val_d_loss:-3.0799\n",
      "epoch [557/50000] s_loss:39.0420 d_loss:-18.1795 val_s_loss:28.2038 val_d_loss:-3.7036\n",
      "epoch [558/50000] s_loss:33.2843 d_loss:-13.4907 val_s_loss:15.6131 val_d_loss:-1.5198\n",
      "epoch [559/50000] s_loss:13.8330 d_loss:-11.1139 val_s_loss:39.1174 val_d_loss:-24.5000\n",
      "epoch [560/50000] s_loss:8.1816 d_loss:-15.1647 val_s_loss:-6.9096 val_d_loss:-0.2940\n",
      "epoch [561/50000] s_loss:17.3559 d_loss:-13.8009 val_s_loss:-6.5950 val_d_loss:10.0476\n",
      "epoch [562/50000] s_loss:11.9205 d_loss:-10.6881 val_s_loss:32.3819 val_d_loss:-23.6877\n",
      "epoch [563/50000] s_loss:19.5445 d_loss:-30.4288 val_s_loss:6.0067 val_d_loss:-2.2534\n",
      "epoch [564/50000] s_loss:22.1353 d_loss:-16.9542 val_s_loss:8.6873 val_d_loss:-1.3184\n",
      "epoch [565/50000] s_loss:30.5846 d_loss:-15.3871 val_s_loss:16.1026 val_d_loss:-3.3477\n",
      "epoch [566/50000] s_loss:10.9448 d_loss:-15.8655 val_s_loss:4.8284 val_d_loss:-3.3553\n",
      "epoch [567/50000] s_loss:4.0275 d_loss:-16.7266 val_s_loss:-11.2101 val_d_loss:1.5931\n",
      "epoch [568/50000] s_loss:30.4950 d_loss:-16.1584 val_s_loss:16.7313 val_d_loss:-24.2190\n",
      "epoch [569/50000] s_loss:33.6319 d_loss:-18.0595 val_s_loss:83.2619 val_d_loss:-52.7937\n",
      "epoch [570/50000] s_loss:43.5405 d_loss:-84.0267 val_s_loss:32.1869 val_d_loss:4.2472\n",
      "epoch [571/50000] s_loss:56.7863 d_loss:-23.0929 val_s_loss:78.9005 val_d_loss:-30.4488\n",
      "epoch [572/50000] s_loss:59.4571 d_loss:-43.6303 val_s_loss:15.8352 val_d_loss:1.9726\n",
      "epoch [573/50000] s_loss:13.2022 d_loss:-14.3826 val_s_loss:39.2460 val_d_loss:-32.6356\n",
      "epoch [574/50000] s_loss:0.8789 d_loss:-16.7081 val_s_loss:-16.2353 val_d_loss:-3.0288\n",
      "epoch [575/50000] s_loss:1.0720 d_loss:-22.8064 val_s_loss:-18.3094 val_d_loss:-1.6662\n",
      "epoch [576/50000] s_loss:28.3241 d_loss:-14.6966 val_s_loss:11.0477 val_d_loss:-1.6822\n",
      "epoch [577/50000] s_loss:18.3035 d_loss:-15.5995 val_s_loss:2.0518 val_d_loss:-1.8098\n",
      "epoch [578/50000] s_loss:6.9570 d_loss:-16.4040 val_s_loss:-15.6480 val_d_loss:5.7788\n",
      "epoch [579/50000] s_loss:-1.4131 d_loss:-18.3897 val_s_loss:7.9643 val_d_loss:-11.6808\n",
      "epoch [580/50000] s_loss:-8.7132 d_loss:-16.7730 val_s_loss:-6.0126 val_d_loss:-13.7462\n",
      "epoch [581/50000] s_loss:8.8499 d_loss:-23.0641 val_s_loss:23.7882 val_d_loss:-23.6579\n",
      "epoch [582/50000] s_loss:33.0511 d_loss:-17.1906 val_s_loss:53.6449 val_d_loss:-33.8965\n",
      "epoch [583/50000] s_loss:42.7442 d_loss:-18.1564 val_s_loss:64.9457 val_d_loss:-26.6825\n",
      "epoch [584/50000] s_loss:32.3264 d_loss:-17.2968 val_s_loss:20.1281 val_d_loss:-2.3195\n",
      "epoch [585/50000] s_loss:17.0588 d_loss:-12.8236 val_s_loss:31.3500 val_d_loss:-13.2839\n",
      "epoch [586/50000] s_loss:6.3888 d_loss:-41.7027 val_s_loss:-5.7955 val_d_loss:-2.6276\n",
      "epoch [587/50000] s_loss:27.9029 d_loss:-13.9313 val_s_loss:39.5278 val_d_loss:-16.5340\n",
      "epoch [588/50000] s_loss:33.6187 d_loss:-22.2489 val_s_loss:18.8591 val_d_loss:-3.1441\n",
      "epoch [589/50000] s_loss:32.2075 d_loss:-15.6282 val_s_loss:46.4293 val_d_loss:-17.5206\n",
      "epoch [590/50000] s_loss:51.9854 d_loss:-18.2970 val_s_loss:14.2793 val_d_loss:-2.3720\n",
      "epoch [591/50000] s_loss:22.4663 d_loss:-14.2682 val_s_loss:2.5633 val_d_loss:-4.3942\n",
      "epoch [592/50000] s_loss:36.1703 d_loss:-51.3518 val_s_loss:19.1027 val_d_loss:-0.9731\n",
      "epoch [593/50000] s_loss:41.5860 d_loss:-11.9248 val_s_loss:20.3500 val_d_loss:-2.1774\n",
      "epoch [594/50000] s_loss:39.5304 d_loss:-18.9933 val_s_loss:51.7245 val_d_loss:-26.1662\n",
      "epoch [595/50000] s_loss:64.1642 d_loss:-18.9185 val_s_loss:30.6317 val_d_loss:-3.2141\n",
      "epoch [596/50000] s_loss:40.4063 d_loss:-14.4116 val_s_loss:24.6623 val_d_loss:-1.7017\n",
      "epoch [597/50000] s_loss:27.9200 d_loss:-18.3805 val_s_loss:8.0862 val_d_loss:-3.3304\n",
      "epoch [598/50000] s_loss:11.8862 d_loss:-20.4557 val_s_loss:-2.3242 val_d_loss:-4.1486\n",
      "epoch [599/50000] s_loss:3.4176 d_loss:-16.6027 val_s_loss:-7.5498 val_d_loss:-4.5411\n",
      "epoch [600/50000] s_loss:-7.8739 d_loss:-11.6603 val_s_loss:-15.1350 val_d_loss:-1.9737\n",
      "epoch [601/50000] s_loss:16.9792 d_loss:-25.0576 val_s_loss:38.4746 val_d_loss:-39.2549\n",
      "epoch [602/50000] s_loss:22.8506 d_loss:-50.8961 val_s_loss:0.6999 val_d_loss:-1.6911\n",
      "epoch [603/50000] s_loss:31.7120 d_loss:-15.0370 val_s_loss:19.7784 val_d_loss:-2.7166\n",
      "epoch [604/50000] s_loss:43.3402 d_loss:-13.5075 val_s_loss:29.0840 val_d_loss:-2.2313\n",
      "epoch [605/50000] s_loss:31.8059 d_loss:-14.6780 val_s_loss:17.2245 val_d_loss:-3.2976\n",
      "epoch [606/50000] s_loss:23.9354 d_loss:-13.8573 val_s_loss:9.4724 val_d_loss:6.5801\n",
      "epoch [607/50000] s_loss:10.7306 d_loss:-9.6897 val_s_loss:9.0852 val_d_loss:-0.5009\n",
      "epoch [608/50000] s_loss:10.2113 d_loss:-14.5715 val_s_loss:8.7454 val_d_loss:-18.8728\n",
      "epoch [609/50000] s_loss:13.6228 d_loss:-19.9559 val_s_loss:54.4912 val_d_loss:-41.3209\n",
      "epoch [610/50000] s_loss:31.4804 d_loss:-9.3208 val_s_loss:13.8954 val_d_loss:-3.3446\n",
      "epoch [611/50000] s_loss:45.6761 d_loss:-10.6753 val_s_loss:30.0644 val_d_loss:-1.8376\n",
      "epoch [612/50000] s_loss:27.4715 d_loss:-16.6144 val_s_loss:55.6527 val_d_loss:-26.9453\n",
      "epoch [613/50000] s_loss:15.1823 d_loss:-11.1268 val_s_loss:59.8420 val_d_loss:-33.2839\n",
      "epoch [614/50000] s_loss:8.1251 d_loss:-7.3121 val_s_loss:-0.9005 val_d_loss:-2.8413\n",
      "epoch [615/50000] s_loss:9.4676 d_loss:-27.6572 val_s_loss:26.1834 val_d_loss:-30.1716\n",
      "epoch [616/50000] s_loss:24.3697 d_loss:-8.3368 val_s_loss:14.5664 val_d_loss:-2.0644\n",
      "epoch [617/50000] s_loss:33.6091 d_loss:-11.0265 val_s_loss:48.3253 val_d_loss:-23.0786\n",
      "epoch [618/50000] s_loss:28.0864 d_loss:-13.3522 val_s_loss:19.5072 val_d_loss:-2.7471\n",
      "epoch [619/50000] s_loss:30.6835 d_loss:-15.1257 val_s_loss:59.6307 val_d_loss:-24.8192\n",
      "epoch [620/50000] s_loss:8.6257 d_loss:-12.5239 val_s_loss:-3.9972 val_d_loss:0.4014\n",
      "epoch [621/50000] s_loss:17.4890 d_loss:-7.1285 val_s_loss:3.6273 val_d_loss:-3.2481\n",
      "epoch [622/50000] s_loss:14.1713 d_loss:-13.5668 val_s_loss:31.4426 val_d_loss:-26.8704\n",
      "epoch [623/50000] s_loss:11.7234 d_loss:-11.0789 val_s_loss:41.4754 val_d_loss:-36.0288\n",
      "epoch [624/50000] s_loss:17.8613 d_loss:-12.7401 val_s_loss:7.8248 val_d_loss:-1.8405\n",
      "epoch [625/50000] s_loss:17.8510 d_loss:-8.0298 val_s_loss:36.1118 val_d_loss:-20.4212\n",
      "epoch [626/50000] s_loss:11.0266 d_loss:-15.5074 val_s_loss:1.6906 val_d_loss:-1.2540\n",
      "epoch [627/50000] s_loss:2.9193 d_loss:-16.2052 val_s_loss:-3.0498 val_d_loss:-3.0956\n",
      "epoch [628/50000] s_loss:-8.3509 d_loss:-11.8256 val_s_loss:-6.7574 val_d_loss:-2.3012\n",
      "epoch [629/50000] s_loss:-4.3361 d_loss:-24.9936 val_s_loss:-21.2546 val_d_loss:-2.7416\n",
      "epoch [630/50000] s_loss:13.9111 d_loss:-16.2760 val_s_loss:42.4012 val_d_loss:-24.9886\n",
      "epoch [631/50000] s_loss:9.0285 d_loss:-11.6832 val_s_loss:-0.7592 val_d_loss:-3.7998\n",
      "epoch [632/50000] s_loss:3.0283 d_loss:-10.8233 val_s_loss:-7.7620 val_d_loss:-3.6425\n",
      "epoch [633/50000] s_loss:-7.7641 d_loss:-12.2486 val_s_loss:8.8731 val_d_loss:-15.6685\n",
      "epoch [634/50000] s_loss:-3.8133 d_loss:-13.5647 val_s_loss:-14.0622 val_d_loss:-3.5962\n",
      "epoch [635/50000] s_loss:1.3029 d_loss:-12.8174 val_s_loss:16.1630 val_d_loss:-30.6645\n",
      "epoch [636/50000] s_loss:6.2223 d_loss:-10.7140 val_s_loss:20.3114 val_d_loss:-18.4270\n",
      "epoch [637/50000] s_loss:-6.1256 d_loss:-20.8369 val_s_loss:-14.5758 val_d_loss:-2.7349\n",
      "epoch [638/50000] s_loss:4.4275 d_loss:-22.8268 val_s_loss:-11.9376 val_d_loss:4.0302\n",
      "epoch [639/50000] s_loss:9.2076 d_loss:-14.5202 val_s_loss:-0.0737 val_d_loss:-2.4450\n",
      "epoch [640/50000] s_loss:18.9446 d_loss:-10.1251 val_s_loss:34.0477 val_d_loss:-23.5423\n",
      "epoch [641/50000] s_loss:9.0986 d_loss:-12.0570 val_s_loss:-0.7634 val_d_loss:-2.0437\n",
      "epoch [642/50000] s_loss:2.1443 d_loss:-12.7671 val_s_loss:33.7135 val_d_loss:-27.0990\n",
      "epoch [643/50000] s_loss:1.6429 d_loss:-20.0229 val_s_loss:-8.9601 val_d_loss:-1.9314\n",
      "epoch [644/50000] s_loss:-4.8155 d_loss:-14.5385 val_s_loss:6.3228 val_d_loss:-13.5787\n",
      "epoch [645/50000] s_loss:-15.8869 d_loss:-11.6241 val_s_loss:-22.6808 val_d_loss:-4.1534\n",
      "epoch [646/50000] s_loss:-7.2498 d_loss:-35.3963 val_s_loss:5.8582 val_d_loss:-17.3904\n",
      "epoch [647/50000] s_loss:17.2054 d_loss:-15.6618 val_s_loss:43.2364 val_d_loss:-27.5632\n",
      "epoch [648/50000] s_loss:36.5762 d_loss:-16.7480 val_s_loss:29.2035 val_d_loss:-3.1509\n",
      "epoch [649/50000] s_loss:31.2242 d_loss:-19.0693 val_s_loss:19.1145 val_d_loss:-3.1195\n",
      "epoch [650/50000] s_loss:21.0482 d_loss:-15.2836 val_s_loss:9.5844 val_d_loss:-3.6003\n",
      "epoch [651/50000] s_loss:11.9791 d_loss:-13.6423 val_s_loss:36.7585 val_d_loss:-28.4539\n",
      "epoch [652/50000] s_loss:1.5552 d_loss:-15.3315 val_s_loss:-3.5189 val_d_loss:-4.4728\n",
      "epoch [653/50000] s_loss:7.9737 d_loss:-4.5835 val_s_loss:8.6110 val_d_loss:-14.8103\n",
      "epoch [654/50000] s_loss:12.4654 d_loss:-16.1257 val_s_loss:-1.5900 val_d_loss:-3.5091\n",
      "epoch [655/50000] s_loss:1.1014 d_loss:-15.5644 val_s_loss:-12.1038 val_d_loss:-4.8354\n",
      "epoch [656/50000] s_loss:8.6790 d_loss:-12.2496 val_s_loss:0.4805 val_d_loss:-5.1078\n",
      "epoch [657/50000] s_loss:1.8178 d_loss:-13.5071 val_s_loss:-3.0079 val_d_loss:-4.4692\n",
      "epoch [658/50000] s_loss:-9.8045 d_loss:-16.2736 val_s_loss:17.6073 val_d_loss:-24.9734\n",
      "epoch [659/50000] s_loss:-10.2210 d_loss:-29.5584 val_s_loss:-23.7763 val_d_loss:0.6914\n",
      "epoch [660/50000] s_loss:1.3401 d_loss:-11.7292 val_s_loss:-8.4436 val_d_loss:-3.1108\n",
      "epoch [661/50000] s_loss:5.9071 d_loss:-12.8920 val_s_loss:-1.7106 val_d_loss:-1.5634\n",
      "epoch [662/50000] s_loss:4.5633 d_loss:-15.9025 val_s_loss:-9.8071 val_d_loss:-3.5074\n",
      "epoch [663/50000] s_loss:3.8725 d_loss:-11.3733 val_s_loss:-10.0565 val_d_loss:-2.3145\n",
      "epoch [664/50000] s_loss:-11.7817 d_loss:-15.8558 val_s_loss:6.3365 val_d_loss:-17.2325\n",
      "epoch [665/50000] s_loss:-0.6883 d_loss:-19.7335 val_s_loss:-23.2477 val_d_loss:-1.3465\n",
      "epoch [666/50000] s_loss:-0.5209 d_loss:-13.4549 val_s_loss:-11.1114 val_d_loss:-2.2131\n",
      "epoch [667/50000] s_loss:3.5221 d_loss:-15.4395 val_s_loss:-8.3518 val_d_loss:-2.5789\n",
      "epoch [668/50000] s_loss:2.5043 d_loss:-11.6975 val_s_loss:-8.8981 val_d_loss:-1.8975\n",
      "epoch [669/50000] s_loss:-4.2748 d_loss:-11.3772 val_s_loss:-10.0235 val_d_loss:-1.7832\n",
      "epoch [670/50000] s_loss:-7.9557 d_loss:-10.0853 val_s_loss:-15.5639 val_d_loss:-2.4858\n",
      "epoch [671/50000] s_loss:-12.7478 d_loss:-28.6626 val_s_loss:-21.2471 val_d_loss:-3.1219\n",
      "epoch [672/50000] s_loss:-13.8953 d_loss:-15.9719 val_s_loss:-23.1230 val_d_loss:0.9551\n",
      "epoch [673/50000] s_loss:-7.6007 d_loss:-10.4353 val_s_loss:13.8410 val_d_loss:-20.3464\n",
      "epoch [674/50000] s_loss:-14.3350 d_loss:-10.0981 val_s_loss:-22.4664 val_d_loss:1.5425\n",
      "epoch [675/50000] s_loss:-22.5306 d_loss:-2.8856 val_s_loss:-23.3517 val_d_loss:-1.3234\n",
      "epoch [676/50000] s_loss:-16.2179 d_loss:-16.2590 val_s_loss:-31.2981 val_d_loss:-3.3770\n",
      "epoch [677/50000] s_loss:3.4339 d_loss:-20.5356 val_s_loss:-14.7900 val_d_loss:-3.3786\n",
      "epoch [678/50000] s_loss:-4.1546 d_loss:-20.3809 val_s_loss:-14.9767 val_d_loss:-3.4226\n",
      "epoch [679/50000] s_loss:0.2882 d_loss:-11.0824 val_s_loss:15.6581 val_d_loss:-20.3061\n",
      "epoch [680/50000] s_loss:-6.8887 d_loss:-15.1596 val_s_loss:6.2462 val_d_loss:-23.0325\n",
      "epoch [681/50000] s_loss:-2.7452 d_loss:-18.9663 val_s_loss:6.6242 val_d_loss:-10.0168\n",
      "epoch [682/50000] s_loss:-6.3757 d_loss:-12.5614 val_s_loss:-17.5704 val_d_loss:-1.1014\n",
      "epoch [683/50000] s_loss:-14.7463 d_loss:-19.9536 val_s_loss:-29.9902 val_d_loss:-2.8835\n",
      "epoch [684/50000] s_loss:-12.3424 d_loss:-8.6412 val_s_loss:-18.6263 val_d_loss:-4.4979\n",
      "epoch [685/50000] s_loss:-23.7075 d_loss:-4.0186 val_s_loss:-28.9653 val_d_loss:-3.0846\n",
      "epoch [686/50000] s_loss:-26.0932 d_loss:-16.1525 val_s_loss:-27.8157 val_d_loss:-1.2552\n",
      "epoch [687/50000] s_loss:-30.7106 d_loss:-9.4866 val_s_loss:-31.9695 val_d_loss:-3.2795\n",
      "epoch [688/50000] s_loss:-32.2859 d_loss:-17.9944 val_s_loss:-42.5522 val_d_loss:-2.3364\n",
      "epoch [689/50000] s_loss:-19.6746 d_loss:-12.9515 val_s_loss:1.5985 val_d_loss:-20.1374\n",
      "epoch [690/50000] s_loss:-23.7912 d_loss:-14.8578 val_s_loss:-27.2798 val_d_loss:-4.2204\n",
      "epoch [691/50000] s_loss:-37.1177 d_loss:-14.1311 val_s_loss:-32.5384 val_d_loss:-1.7611\n",
      "epoch [692/50000] s_loss:-41.9908 d_loss:-0.5209 val_s_loss:-35.5527 val_d_loss:-3.2466\n",
      "epoch [693/50000] s_loss:-17.7356 d_loss:-17.0841 val_s_loss:-38.5215 val_d_loss:-3.3903\n",
      "epoch [694/50000] s_loss:2.7585 d_loss:-23.7759 val_s_loss:-18.3771 val_d_loss:-1.7279\n",
      "epoch [695/50000] s_loss:11.8943 d_loss:-16.3277 val_s_loss:-2.3027 val_d_loss:-3.2581\n",
      "epoch [696/50000] s_loss:18.6024 d_loss:-13.1373 val_s_loss:23.3783 val_d_loss:-4.3560\n",
      "epoch [697/50000] s_loss:17.0494 d_loss:-12.2222 val_s_loss:7.5058 val_d_loss:-4.6918\n",
      "epoch [698/50000] s_loss:6.2101 d_loss:-12.4276 val_s_loss:6.1787 val_d_loss:-4.6675\n",
      "epoch [699/50000] s_loss:-5.8222 d_loss:-15.4547 val_s_loss:-12.2585 val_d_loss:-4.9861\n",
      "epoch [700/50000] s_loss:-7.4615 d_loss:-11.0806 val_s_loss:-11.5591 val_d_loss:-2.1173\n",
      "epoch [701/50000] s_loss:-8.4881 d_loss:-18.6923 val_s_loss:-2.2340 val_d_loss:-9.7924\n",
      "epoch [702/50000] s_loss:-3.3841 d_loss:-12.8539 val_s_loss:-10.9596 val_d_loss:-3.0969\n",
      "epoch [703/50000] s_loss:-3.2955 d_loss:-9.7599 val_s_loss:20.3480 val_d_loss:-24.5119\n",
      "epoch [704/50000] s_loss:-1.2363 d_loss:-18.8521 val_s_loss:16.7273 val_d_loss:-14.8582\n",
      "epoch [705/50000] s_loss:-10.1324 d_loss:-13.1373 val_s_loss:-12.0067 val_d_loss:-2.6371\n",
      "epoch [706/50000] s_loss:-14.5126 d_loss:-16.4331 val_s_loss:-4.8030 val_d_loss:-5.3401\n",
      "epoch [707/50000] s_loss:-7.5150 d_loss:-13.7079 val_s_loss:-15.6715 val_d_loss:-2.0875\n",
      "epoch [708/50000] s_loss:52.4773 d_loss:-37.5320 val_s_loss:15.6465 val_d_loss:3.6473\n",
      "epoch [709/50000] s_loss:20.4153 d_loss:-11.3709 val_s_loss:15.0902 val_d_loss:-3.2613\n",
      "epoch [710/50000] s_loss:39.5203 d_loss:-15.3477 val_s_loss:23.6836 val_d_loss:-3.5765\n",
      "epoch [711/50000] s_loss:35.1533 d_loss:-15.6997 val_s_loss:46.5754 val_d_loss:-19.3963\n",
      "epoch [712/50000] s_loss:28.7864 d_loss:-16.8807 val_s_loss:39.2534 val_d_loss:-17.2655\n",
      "epoch [713/50000] s_loss:24.0295 d_loss:-11.1640 val_s_loss:19.1040 val_d_loss:-2.4156\n",
      "epoch [714/50000] s_loss:15.2582 d_loss:-5.7606 val_s_loss:11.8603 val_d_loss:-4.4303\n",
      "epoch [715/50000] s_loss:11.4937 d_loss:-13.3954 val_s_loss:-7.3320 val_d_loss:11.1060\n",
      "epoch [716/50000] s_loss:1.6097 d_loss:-9.4626 val_s_loss:-2.9629 val_d_loss:-5.0806\n",
      "epoch [717/50000] s_loss:4.2643 d_loss:-11.6380 val_s_loss:25.2247 val_d_loss:-18.2524\n",
      "epoch [718/50000] s_loss:-7.0348 d_loss:-11.8207 val_s_loss:-10.6844 val_d_loss:-4.4213\n",
      "epoch [719/50000] s_loss:-14.0042 d_loss:-7.9820 val_s_loss:-19.3039 val_d_loss:-3.0855\n",
      "epoch [720/50000] s_loss:-13.5922 d_loss:-9.0810 val_s_loss:-12.0344 val_d_loss:-5.1005\n",
      "epoch [721/50000] s_loss:-2.5443 d_loss:-12.1599 val_s_loss:-10.3174 val_d_loss:-1.4379\n",
      "epoch [722/50000] s_loss:4.4059 d_loss:-2.5217 val_s_loss:2.9774 val_d_loss:-2.0579\n",
      "epoch [723/50000] s_loss:-6.8662 d_loss:-6.0948 val_s_loss:-2.6235 val_d_loss:-5.0698\n",
      "epoch [724/50000] s_loss:-12.6349 d_loss:-4.3362 val_s_loss:-14.3365 val_d_loss:-4.0507\n",
      "epoch [725/50000] s_loss:-6.6111 d_loss:-11.7356 val_s_loss:-13.3595 val_d_loss:-3.6411\n",
      "epoch [726/50000] s_loss:-1.7580 d_loss:-15.9318 val_s_loss:-7.1590 val_d_loss:-2.9937\n",
      "epoch [727/50000] s_loss:6.5976 d_loss:-3.6511 val_s_loss:-0.6297 val_d_loss:1.1740\n",
      "epoch [728/50000] s_loss:-2.4909 d_loss:-11.1026 val_s_loss:-16.4204 val_d_loss:4.9759\n",
      "epoch [729/50000] s_loss:-8.9706 d_loss:-13.1062 val_s_loss:-8.0054 val_d_loss:-3.2697\n",
      "epoch [730/50000] s_loss:-1.1775 d_loss:-13.3944 val_s_loss:-3.0088 val_d_loss:-2.6647\n",
      "epoch [731/50000] s_loss:1.7475 d_loss:-6.0078 val_s_loss:-3.9086 val_d_loss:-1.5946\n",
      "epoch [732/50000] s_loss:3.8009 d_loss:-10.7379 val_s_loss:-2.8394 val_d_loss:-4.5993\n",
      "epoch [733/50000] s_loss:9.9100 d_loss:-14.8585 val_s_loss:4.6888 val_d_loss:-3.4267\n",
      "epoch [734/50000] s_loss:12.9387 d_loss:-11.8956 val_s_loss:8.4957 val_d_loss:-3.2859\n",
      "epoch [735/50000] s_loss:24.5313 d_loss:-18.1353 val_s_loss:16.7454 val_d_loss:-3.2897\n",
      "epoch [736/50000] s_loss:26.9908 d_loss:-5.4044 val_s_loss:20.6053 val_d_loss:-1.9911\n",
      "epoch [737/50000] s_loss:25.4070 d_loss:-1.0443 val_s_loss:34.8997 val_d_loss:-10.9542\n",
      "epoch [738/50000] s_loss:9.3093 d_loss:-9.0609 val_s_loss:9.7598 val_d_loss:-6.4530\n",
      "epoch [739/50000] s_loss:11.8088 d_loss:-9.3297 val_s_loss:9.0433 val_d_loss:-3.9837\n",
      "epoch [740/50000] s_loss:9.2653 d_loss:-12.0144 val_s_loss:5.1134 val_d_loss:-0.8914\n",
      "epoch [741/50000] s_loss:27.8426 d_loss:-9.6241 val_s_loss:18.7105 val_d_loss:-3.3112\n",
      "epoch [742/50000] s_loss:33.4435 d_loss:-5.3627 val_s_loss:31.6386 val_d_loss:-2.4640\n",
      "epoch [743/50000] s_loss:25.7658 d_loss:-10.1808 val_s_loss:18.1936 val_d_loss:-2.0850\n",
      "epoch [744/50000] s_loss:19.2687 d_loss:-7.9828 val_s_loss:21.3030 val_d_loss:-3.7599\n",
      "epoch [745/50000] s_loss:23.5140 d_loss:-9.1839 val_s_loss:21.6232 val_d_loss:-2.5191\n",
      "epoch [746/50000] s_loss:15.9233 d_loss:-6.9572 val_s_loss:16.4904 val_d_loss:-3.1344\n",
      "epoch [747/50000] s_loss:24.7557 d_loss:-6.2897 val_s_loss:23.6433 val_d_loss:-2.8218\n",
      "epoch [748/50000] s_loss:39.3058 d_loss:-10.9286 val_s_loss:42.5891 val_d_loss:-2.3914\n",
      "epoch [749/50000] s_loss:31.7092 d_loss:-14.1621 val_s_loss:23.7393 val_d_loss:6.5002\n",
      "epoch [750/50000] s_loss:27.5814 d_loss:-5.6312 val_s_loss:27.7215 val_d_loss:-3.4861\n",
      "epoch [751/50000] s_loss:22.1897 d_loss:-9.8062 val_s_loss:20.2588 val_d_loss:-3.3558\n",
      "epoch [752/50000] s_loss:23.7321 d_loss:-12.3327 val_s_loss:14.1486 val_d_loss:-2.4507\n",
      "epoch [753/50000] s_loss:23.1217 d_loss:-9.8193 val_s_loss:17.9717 val_d_loss:-3.4461\n",
      "epoch [754/50000] s_loss:35.5123 d_loss:-4.1091 val_s_loss:56.5894 val_d_loss:-20.6340\n",
      "epoch [755/50000] s_loss:38.6672 d_loss:-5.9943 val_s_loss:54.9289 val_d_loss:-19.8357\n",
      "epoch [756/50000] s_loss:19.9353 d_loss:-9.6419 val_s_loss:20.8119 val_d_loss:-3.4893\n",
      "epoch [757/50000] s_loss:21.2628 d_loss:-3.7852 val_s_loss:17.9693 val_d_loss:-3.9843\n",
      "epoch [758/50000] s_loss:13.9463 d_loss:-13.3396 val_s_loss:12.3693 val_d_loss:0.1933\n",
      "epoch [759/50000] s_loss:26.7213 d_loss:-2.8594 val_s_loss:21.7392 val_d_loss:-2.6402\n",
      "epoch [760/50000] s_loss:7.1693 d_loss:-9.9074 val_s_loss:7.7474 val_d_loss:-4.9795\n",
      "epoch [761/50000] s_loss:3.9694 d_loss:-7.8279 val_s_loss:-1.4861 val_d_loss:-1.9455\n",
      "epoch [762/50000] s_loss:6.7978 d_loss:-7.3590 val_s_loss:8.5360 val_d_loss:-3.5133\n",
      "epoch [763/50000] s_loss:7.8741 d_loss:-13.8370 val_s_loss:0.6789 val_d_loss:-2.7644\n",
      "epoch [764/50000] s_loss:31.2502 d_loss:-18.1351 val_s_loss:25.2500 val_d_loss:-3.4663\n",
      "epoch [765/50000] s_loss:15.6787 d_loss:-15.1940 val_s_loss:8.9312 val_d_loss:-4.2948\n",
      "epoch [766/50000] s_loss:7.0728 d_loss:-10.6231 val_s_loss:0.1163 val_d_loss:-4.2921\n",
      "epoch [767/50000] s_loss:-7.7621 d_loss:-8.1706 val_s_loss:-9.4554 val_d_loss:-2.1262\n",
      "epoch [768/50000] s_loss:-18.2795 d_loss:-10.9046 val_s_loss:-17.1829 val_d_loss:-3.8814\n",
      "epoch [769/50000] s_loss:-20.8709 d_loss:-14.6736 val_s_loss:-15.7699 val_d_loss:-4.0490\n",
      "epoch [770/50000] s_loss:-19.6936 d_loss:-13.8347 val_s_loss:-18.8691 val_d_loss:-4.9877\n",
      "epoch [771/50000] s_loss:-2.6331 d_loss:-7.5051 val_s_loss:0.1618 val_d_loss:-7.5287\n",
      "epoch [772/50000] s_loss:16.2825 d_loss:-9.9541 val_s_loss:10.5487 val_d_loss:-2.0507\n",
      "epoch [773/50000] s_loss:22.6861 d_loss:-6.7862 val_s_loss:35.4653 val_d_loss:-14.1814\n",
      "epoch [774/50000] s_loss:24.1038 d_loss:-14.4135 val_s_loss:32.2608 val_d_loss:-10.3024\n",
      "epoch [775/50000] s_loss:20.2520 d_loss:-8.1813 val_s_loss:18.7487 val_d_loss:-3.5097\n",
      "epoch [776/50000] s_loss:17.1567 d_loss:-11.1383 val_s_loss:17.7870 val_d_loss:-3.8862\n",
      "epoch [777/50000] s_loss:17.8446 d_loss:-8.6325 val_s_loss:17.4470 val_d_loss:-2.0630\n",
      "epoch [778/50000] s_loss:9.7009 d_loss:-6.0701 val_s_loss:10.5287 val_d_loss:-3.5597\n",
      "epoch [779/50000] s_loss:7.8363 d_loss:-4.8552 val_s_loss:9.0841 val_d_loss:-1.1904\n",
      "epoch [780/50000] s_loss:-3.2279 d_loss:-9.7707 val_s_loss:1.5415 val_d_loss:-4.0843\n",
      "epoch [781/50000] s_loss:-2.4919 d_loss:-10.9811 val_s_loss:-0.1733 val_d_loss:-3.8244\n",
      "epoch [782/50000] s_loss:6.1287 d_loss:-6.2644 val_s_loss:3.1315 val_d_loss:-1.4943\n",
      "epoch [783/50000] s_loss:15.1444 d_loss:-6.4614 val_s_loss:12.9564 val_d_loss:-2.5152\n",
      "epoch [784/50000] s_loss:26.3807 d_loss:-1.7610 val_s_loss:27.8091 val_d_loss:-3.3497\n",
      "epoch [785/50000] s_loss:18.4839 d_loss:-10.3325 val_s_loss:19.8539 val_d_loss:-2.5887\n",
      "epoch [786/50000] s_loss:7.8180 d_loss:-2.8152 val_s_loss:12.1833 val_d_loss:-7.0369\n",
      "epoch [787/50000] s_loss:0.4115 d_loss:-4.8060 val_s_loss:-8.0494 val_d_loss:9.2996\n",
      "epoch [788/50000] s_loss:4.3027 d_loss:-15.5502 val_s_loss:7.0983 val_d_loss:-4.2294\n",
      "epoch [789/50000] s_loss:1.9175 d_loss:-6.1744 val_s_loss:0.2148 val_d_loss:-2.6654\n",
      "epoch [790/50000] s_loss:11.4833 d_loss:-10.5070 val_s_loss:8.8647 val_d_loss:-4.9039\n",
      "epoch [791/50000] s_loss:18.7602 d_loss:-8.7016 val_s_loss:16.4529 val_d_loss:-4.2048\n",
      "epoch [792/50000] s_loss:23.5508 d_loss:-5.6734 val_s_loss:24.6745 val_d_loss:-4.3356\n",
      "epoch [793/50000] s_loss:17.7288 d_loss:-6.4322 val_s_loss:17.3756 val_d_loss:-3.9312\n",
      "epoch [794/50000] s_loss:28.7169 d_loss:-7.5622 val_s_loss:27.5893 val_d_loss:-4.9447\n",
      "epoch [795/50000] s_loss:34.9012 d_loss:-9.0556 val_s_loss:32.3481 val_d_loss:3.4841\n",
      "epoch [796/50000] s_loss:39.2376 d_loss:-12.4726 val_s_loss:43.8275 val_d_loss:-1.9008\n",
      "epoch [797/50000] s_loss:42.4904 d_loss:-8.5093 val_s_loss:44.3886 val_d_loss:-5.0692\n",
      "epoch [798/50000] s_loss:23.6830 d_loss:-6.4427 val_s_loss:22.8717 val_d_loss:-3.3307\n",
      "epoch [799/50000] s_loss:22.5980 d_loss:-6.6695 val_s_loss:22.9396 val_d_loss:-3.0103\n",
      "epoch [800/50000] s_loss:19.8489 d_loss:-9.9967 val_s_loss:21.3203 val_d_loss:-5.0298\n",
      "epoch [801/50000] s_loss:24.8940 d_loss:-7.8836 val_s_loss:24.5234 val_d_loss:-4.1989\n",
      "epoch [802/50000] s_loss:32.7451 d_loss:-4.7924 val_s_loss:32.3329 val_d_loss:-4.0287\n",
      "epoch [803/50000] s_loss:45.9530 d_loss:-8.6650 val_s_loss:45.3921 val_d_loss:-5.7650\n",
      "epoch [804/50000] s_loss:39.8302 d_loss:-6.6072 val_s_loss:39.3746 val_d_loss:-2.1746\n",
      "epoch [805/50000] s_loss:33.3245 d_loss:-8.7630 val_s_loss:32.9117 val_d_loss:-2.6681\n",
      "epoch [806/50000] s_loss:35.0364 d_loss:-7.8540 val_s_loss:33.0940 val_d_loss:-6.6544\n",
      "epoch [807/50000] s_loss:34.2383 d_loss:-15.1731 val_s_loss:37.3677 val_d_loss:-2.5265\n",
      "epoch [808/50000] s_loss:16.4317 d_loss:-11.8915 val_s_loss:15.5529 val_d_loss:-0.8959\n",
      "epoch [809/50000] s_loss:1.0052 d_loss:-8.0058 val_s_loss:4.6602 val_d_loss:-4.8291\n",
      "epoch [810/50000] s_loss:-1.4066 d_loss:-5.0708 val_s_loss:-2.7527 val_d_loss:-1.5384\n",
      "epoch [811/50000] s_loss:-5.4442 d_loss:-8.5334 val_s_loss:-6.1752 val_d_loss:-5.9526\n",
      "epoch [812/50000] s_loss:-9.5285 d_loss:-8.3304 val_s_loss:-18.7589 val_d_loss:3.2153\n",
      "epoch [813/50000] s_loss:-8.7529 d_loss:-9.5799 val_s_loss:-10.2423 val_d_loss:-0.8446\n",
      "epoch [814/50000] s_loss:-9.6401 d_loss:-10.7082 val_s_loss:-9.3247 val_d_loss:-3.3777\n",
      "epoch [815/50000] s_loss:2.5312 d_loss:-4.8228 val_s_loss:-0.0070 val_d_loss:-2.6523\n",
      "epoch [816/50000] s_loss:10.3307 d_loss:-8.0232 val_s_loss:12.8226 val_d_loss:-5.8079\n",
      "epoch [817/50000] s_loss:12.6039 d_loss:-8.3062 val_s_loss:13.5600 val_d_loss:-3.5418\n",
      "epoch [818/50000] s_loss:8.8864 d_loss:-9.5882 val_s_loss:13.1530 val_d_loss:-4.4436\n",
      "epoch [819/50000] s_loss:4.7969 d_loss:-5.0760 val_s_loss:5.5970 val_d_loss:-3.4743\n",
      "epoch [820/50000] s_loss:-6.8806 d_loss:-3.2499 val_s_loss:-5.2938 val_d_loss:-3.5434\n",
      "epoch [821/50000] s_loss:-11.8872 d_loss:-5.7084 val_s_loss:-13.4902 val_d_loss:-4.6848\n",
      "epoch [822/50000] s_loss:-10.5050 d_loss:-9.4439 val_s_loss:-11.9081 val_d_loss:-2.1365\n",
      "epoch [823/50000] s_loss:-10.2511 d_loss:-6.8574 val_s_loss:-9.6454 val_d_loss:-5.0702\n",
      "epoch [824/50000] s_loss:0.5470 d_loss:-8.1836 val_s_loss:-1.5105 val_d_loss:-2.3152\n",
      "epoch [825/50000] s_loss:8.2668 d_loss:-5.8464 val_s_loss:8.6176 val_d_loss:-4.6049\n",
      "epoch [826/50000] s_loss:14.5294 d_loss:-7.0846 val_s_loss:13.6474 val_d_loss:-5.7060\n",
      "epoch [827/50000] s_loss:18.9957 d_loss:-8.1454 val_s_loss:17.5573 val_d_loss:-4.9073\n",
      "epoch [828/50000] s_loss:14.0941 d_loss:-5.5481 val_s_loss:9.9207 val_d_loss:-4.1181\n",
      "epoch [829/50000] s_loss:14.4997 d_loss:-6.5449 val_s_loss:12.7612 val_d_loss:-5.2122\n",
      "epoch [830/50000] s_loss:10.8941 d_loss:-7.1181 val_s_loss:14.7413 val_d_loss:-4.4570\n",
      "epoch [831/50000] s_loss:13.0577 d_loss:-6.9853 val_s_loss:16.9484 val_d_loss:-5.3234\n",
      "epoch [832/50000] s_loss:13.8540 d_loss:-7.2609 val_s_loss:10.7466 val_d_loss:-2.8846\n",
      "epoch [833/50000] s_loss:13.3382 d_loss:-10.6876 val_s_loss:9.3151 val_d_loss:-4.8151\n",
      "epoch [834/50000] s_loss:12.8264 d_loss:-7.4929 val_s_loss:11.2775 val_d_loss:-6.0533\n",
      "epoch [835/50000] s_loss:11.7406 d_loss:-3.8991 val_s_loss:14.7063 val_d_loss:-5.9020\n",
      "epoch [836/50000] s_loss:10.5986 d_loss:-5.1241 val_s_loss:14.9911 val_d_loss:-6.4495\n",
      "epoch [837/50000] s_loss:14.5177 d_loss:-7.5951 val_s_loss:19.6317 val_d_loss:-5.3143\n",
      "epoch [838/50000] s_loss:13.5710 d_loss:-6.3574 val_s_loss:17.3452 val_d_loss:-5.1995\n",
      "epoch [839/50000] s_loss:13.9231 d_loss:-6.4534 val_s_loss:15.6275 val_d_loss:-5.8503\n",
      "epoch [840/50000] s_loss:10.4659 d_loss:-9.1449 val_s_loss:9.5097 val_d_loss:-3.6725\n",
      "epoch [841/50000] s_loss:4.3444 d_loss:-8.2825 val_s_loss:3.2854 val_d_loss:-5.0361\n",
      "epoch [842/50000] s_loss:8.3231 d_loss:-4.6286 val_s_loss:7.3878 val_d_loss:0.0073\n",
      "epoch [843/50000] s_loss:10.2850 d_loss:-3.2323 val_s_loss:8.4780 val_d_loss:-4.6395\n",
      "epoch [844/50000] s_loss:13.9311 d_loss:-4.3844 val_s_loss:15.7473 val_d_loss:-2.2230\n",
      "epoch [845/50000] s_loss:13.7457 d_loss:-2.9204 val_s_loss:12.4010 val_d_loss:-1.6366\n",
      "epoch [846/50000] s_loss:11.5375 d_loss:-8.4066 val_s_loss:10.7516 val_d_loss:-3.7917\n",
      "epoch [847/50000] s_loss:11.7249 d_loss:-7.8218 val_s_loss:10.9435 val_d_loss:-3.7397\n",
      "epoch [848/50000] s_loss:9.6438 d_loss:-6.2229 val_s_loss:10.6905 val_d_loss:-3.8275\n",
      "epoch [849/50000] s_loss:17.7921 d_loss:-9.3095 val_s_loss:15.9750 val_d_loss:-2.6698\n",
      "epoch [850/50000] s_loss:18.4520 d_loss:-3.7601 val_s_loss:17.4434 val_d_loss:-4.2574\n",
      "epoch [851/50000] s_loss:9.1060 d_loss:-3.9693 val_s_loss:7.2333 val_d_loss:-3.4591\n",
      "epoch [852/50000] s_loss:3.2262 d_loss:-6.6812 val_s_loss:3.3503 val_d_loss:-3.5604\n",
      "epoch [853/50000] s_loss:3.4846 d_loss:-7.5656 val_s_loss:5.0189 val_d_loss:-5.1986\n",
      "epoch [854/50000] s_loss:6.6136 d_loss:-5.0146 val_s_loss:7.6284 val_d_loss:-5.1003\n",
      "epoch [855/50000] s_loss:15.2741 d_loss:-6.6256 val_s_loss:15.5083 val_d_loss:-4.3707\n",
      "epoch [856/50000] s_loss:13.6489 d_loss:-6.6651 val_s_loss:15.6266 val_d_loss:-6.1746\n",
      "epoch [857/50000] s_loss:7.4872 d_loss:-10.5990 val_s_loss:8.5875 val_d_loss:-3.0069\n",
      "epoch [858/50000] s_loss:7.4549 d_loss:-11.3868 val_s_loss:7.2507 val_d_loss:-6.1374\n",
      "epoch [859/50000] s_loss:8.6053 d_loss:-3.2764 val_s_loss:10.6547 val_d_loss:-5.2144\n",
      "epoch [860/50000] s_loss:6.2380 d_loss:-5.2229 val_s_loss:5.2675 val_d_loss:-3.3628\n",
      "epoch [861/50000] s_loss:13.2169 d_loss:-8.1370 val_s_loss:10.6182 val_d_loss:-1.9952\n",
      "epoch [862/50000] s_loss:18.1972 d_loss:-7.3330 val_s_loss:17.3132 val_d_loss:-4.3050\n",
      "epoch [863/50000] s_loss:14.9043 d_loss:-6.7783 val_s_loss:12.6795 val_d_loss:-3.1812\n",
      "epoch [864/50000] s_loss:7.9881 d_loss:-5.1659 val_s_loss:9.3273 val_d_loss:-4.2599\n",
      "epoch [865/50000] s_loss:2.8011 d_loss:-4.7743 val_s_loss:3.6649 val_d_loss:-1.1896\n",
      "epoch [866/50000] s_loss:-2.8444 d_loss:-6.3131 val_s_loss:-3.3385 val_d_loss:-3.6289\n",
      "epoch [867/50000] s_loss:3.7602 d_loss:-8.6129 val_s_loss:2.0559 val_d_loss:-4.4696\n",
      "epoch [868/50000] s_loss:8.9720 d_loss:-9.6520 val_s_loss:6.4469 val_d_loss:-4.2493\n",
      "epoch [869/50000] s_loss:10.9973 d_loss:-8.7817 val_s_loss:10.5825 val_d_loss:-3.5133\n",
      "epoch [870/50000] s_loss:12.4838 d_loss:-5.8605 val_s_loss:13.8780 val_d_loss:-4.5498\n",
      "epoch [871/50000] s_loss:6.8011 d_loss:-7.8839 val_s_loss:5.5375 val_d_loss:-1.8659\n",
      "epoch [872/50000] s_loss:13.0458 d_loss:-4.1396 val_s_loss:14.0122 val_d_loss:-4.1031\n",
      "epoch [873/50000] s_loss:22.1074 d_loss:-7.8299 val_s_loss:21.2280 val_d_loss:-5.8640\n",
      "epoch [874/50000] s_loss:13.5953 d_loss:-8.3595 val_s_loss:16.3722 val_d_loss:-2.4177\n",
      "epoch [875/50000] s_loss:6.9260 d_loss:-5.4784 val_s_loss:8.8959 val_d_loss:-5.4028\n",
      "epoch [876/50000] s_loss:6.3879 d_loss:-6.8331 val_s_loss:9.8668 val_d_loss:-6.5407\n",
      "epoch [877/50000] s_loss:12.3197 d_loss:-4.1088 val_s_loss:11.6660 val_d_loss:1.6439\n",
      "epoch [878/50000] s_loss:19.1224 d_loss:-6.0030 val_s_loss:10.7559 val_d_loss:8.0842\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):    \n",
    "    ######## GAN ################\n",
    "    one = torch.FloatTensor([1])\n",
    "    mone = one * -1\n",
    "    \n",
    "    one = one.cuda()\n",
    "    mone = mone.cuda()\n",
    "    \n",
    "    one = one.mean()\n",
    "    mone = mone.mean()\n",
    "    ## ==== GAN --> D =====\n",
    "    for i in range(3):\n",
    "        for index, img in enumerate(train_loader):\n",
    "            AE.eval(), S.train(), D.train()\n",
    "\n",
    "            img = Variable(img).cuda()\n",
    "\n",
    "            # ====== AE ======\n",
    "            blur_image = AE(img)\n",
    "\n",
    "            _bs, _c, _w, _h = blur_image.shape\n",
    "            noise = torch.zeros(_bs, 1, _w, _h )\n",
    "            noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "            noise = noise.cuda()\n",
    "\n",
    "            blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "            fake_image = S(blur_image_with_noise) # 當成是 residual\n",
    "            \n",
    "            fake_image = fake_image + blur_image # blur image + residual\n",
    "            \n",
    "            fake_pair = torch.cat([img, fake_image], 1)\n",
    "            real_pair = torch.cat([img, img[torch.randperm(img.size(0)), :, :, :]], 1) if UPSET else torch.cat([img, img], 1)\n",
    "            # ====== Train D ======\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            optimizer_AE.zero_grad()\n",
    "            optimizer_S.zero_grad()\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "\n",
    "            real_D = D(real_pair)\n",
    "            real_D = real_D.mean()\n",
    "            real_D.backward(mone)\n",
    "\n",
    "\n",
    "            fake_D = D(fake_pair)\n",
    "            fake_D = fake_D.mean()\n",
    "            fake_D.backward(one)\n",
    "\n",
    "            gradient_penalty = calc_gradient_penalty(D, real_pair, fake_pair)\n",
    "            gradient_penalty.backward()\n",
    "\n",
    "            cost_D = fake_D - real_D + gradient_penalty\n",
    "            Wasserstein_D = real_D - fake_D\n",
    "            optimizer_D.step()\n",
    "    \n",
    "    ## ==== GAN --> G =====\n",
    "    for index, img in enumerate(train_loader):\n",
    "        AE.eval(), S.train(), D.train()\n",
    "\n",
    "        img = Variable(img).cuda()\n",
    "        # ======AE======\n",
    "        blur_image = AE(img)\n",
    "\n",
    "        _bs, _c, _w, _h = blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "        fake_image = S(blur_image_with_noise)\n",
    "        \n",
    "        fake_image = fake_image + blur_image\n",
    "        \n",
    "        fake_pair = torch.cat([img, fake_image], 1)\n",
    "        # ====== Train G ======\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        G = D(fake_pair)\n",
    "        G = G.mean()\n",
    "        \n",
    "        optimizer_AE.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        G.backward(mone)\n",
    "        \n",
    "        cost_G = -G\n",
    "        optimizer_S.step()\n",
    "        \n",
    "    \n",
    "    # validation set\n",
    "    for index, val_img in enumerate(val_loader):\n",
    "        AE.eval(), S.eval(), D.eval()\n",
    "\n",
    "        val_img = Variable(val_img).cuda()\n",
    "        # ======AE======\n",
    "        val_blur_image = AE(val_img)\n",
    "\n",
    "        _bs, _c, _w, _h = val_blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        val_blur_image_with_noise = torch.cat([val_blur_image, noise], 1)\n",
    "\n",
    "        val_fake_image = S(val_blur_image_with_noise)       \n",
    "        val_fake_image = val_fake_image + val_blur_image\n",
    "        \n",
    "        \n",
    "        val_fake_pair = torch.cat([val_img, val_fake_image], 1)\n",
    "        val_real_pair = torch.cat([val_img, val_img[torch.randperm(val_img.size(0)), :, :, :]], 1) if UPSET else torch.cat([val_img, val_img], 1)\n",
    "        \n",
    "        val_real_D = D(val_real_pair)\n",
    "        val_real_D = val_real_D.mean()\n",
    "        \n",
    "        val_fake_D = D(val_fake_pair)\n",
    "        val_fake_D = val_fake_D.mean()\n",
    "        \n",
    "        val_gradient_penalty = calc_gradient_penalty(D, val_real_pair, val_fake_pair)\n",
    "        \n",
    "        # =========== Losses =========\n",
    "        val_Wasserstein_D = val_real_D - val_fake_D\n",
    "        \n",
    "        val_cost_G = -val_fake_D\n",
    "        val_cost_D = val_fake_D - val_real_D + val_gradient_penalty\n",
    "    \n",
    "    # evaluate\n",
    "    test_total_AUC = 0\n",
    "    test_total_AUC2 = 0\n",
    "    test_total_image = 0\n",
    "\n",
    "    for index, (test_img, mask) in enumerate(test_loader):\n",
    "        AE.eval(), S.eval(), D.eval()\n",
    "        test_img = Variable(test_img).cuda()\n",
    "        test_blur_image = AE(test_img)\n",
    "\n",
    "        _bs, _c, _w, _h = test_blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        test_blur_image_with_noise = torch.cat([test_blur_image, noise], 1)\n",
    "\n",
    "        test_fake_image = S(test_blur_image_with_noise)       \n",
    "        test_fake_image = test_fake_image + test_blur_image\n",
    "\n",
    "        # 計算 dif (相似度以及 L2)\n",
    "        dif, _ = perceptual_loss.forward(test_fake_image, test_img)\n",
    "        l2Dif = L2_loss(test_fake_image, test_img)\n",
    "        l2Dif = torch.mean(l2Dif, 1, True)\n",
    "        \n",
    "        pred_mask2 = difNormalize(dif[0].cpu().detach().numpy())\n",
    "        pred_mask2 = pred_mask2.flatten()\n",
    "        \n",
    "        pred_mask = difNormalize(dif[0].cpu().detach().numpy() * l2Dif[0].cpu().detach().numpy())\n",
    "        pred_mask = pred_mask.flatten()\n",
    "\n",
    "        mask = torch.mean(mask, 1, True)\n",
    "        true_mask = mask[0].cpu().detach().numpy().flatten()\n",
    "        true_mask = true_mask.astype(int)\n",
    "\n",
    "        AUC = roc_auc_score(true_mask, pred_mask)\n",
    "        AUC2 = roc_auc_score(true_mask, pred_mask2)\n",
    "\n",
    "        test_total_AUC += AUC\n",
    "        test_total_AUC2 += AUC2\n",
    "        test_total_image += 1\n",
    "    \n",
    "    # =================== GAN log========================\n",
    "    print('epoch [{}/{}] s_loss:{:.4f} d_loss:{:.4f} val_s_loss:{:.4f} val_d_loss:{:.4f}'.format(epoch+1, num_epochs, cost_G.item(), cost_D.item(), val_cost_G.item(), val_cost_D.item()))\n",
    "    writer.add_scalars('eval', {\n",
    "        \"auc_roc_score\": test_total_AUC / test_total_image,\n",
    "        \"auc_roc_score(w/o L2)\": test_total_AUC2 / test_total_image,\n",
    "    }, epoch)\n",
    "    \n",
    "    writer.add_scalars('loss', {\n",
    "        \"Wasserstein Distance\": Wasserstein_D.item(),\n",
    "        \"Val Wasserstein Distance\": val_Wasserstein_D.item(),\n",
    "        \"gradient penalty\": gradient_penalty,\n",
    "        \"val gradient penalty\": val_gradient_penalty\n",
    "    }, epoch)\n",
    "    \n",
    "    writer.add_scalars('gan loss', {\n",
    "        \"g_loss\": cost_G.item(),\n",
    "        \"d_loss\": cost_D.item(),\n",
    "        \"val_g_loss\": val_cost_G.item(),\n",
    "        \"val_d_loss\": val_cost_D.item()\n",
    "    }, epoch)\n",
    "\n",
    "    writer.add_images('Blur', blur_image, epoch)\n",
    "    writer.add_images('Reconstruct', fake_image, epoch)\n",
    "    writer.add_images('Origin', img, epoch)\n",
    "\n",
    "    writer.add_images('Val Blur', val_blur_image, epoch)\n",
    "    writer.add_images('Val Reconstruct', val_fake_image, epoch)\n",
    "    writer.add_images('Val Origin', val_img, epoch)\n",
    "\n",
    "\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        if not os.path.exists('./save_weight/{}'.format(expName)):\n",
    "            os.makedirs('./save_weight/{}'.format(expName))\n",
    "        torch.save(S.state_dict(), './save_weight/{}/S_{}.npy'.format(expName, epoch))\n",
    "        torch.save(D.state_dict(), './save_weight/{}/D_{}.npy'.format(expName, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.eval()\n",
    "S.eval()\n",
    "for index, img in enumerate(test_loader):\n",
    "    test_img = Variable(img[0]).cuda()\n",
    "\n",
    "    # ======AE======\n",
    "    blur_image = AE(test_img)\n",
    "    \n",
    "    noise = torch.zeros(blur_image.shape[0], 1, blur_image.shape[2], blur_image.shape[3] )\n",
    "    noise = noise + (0.01**0.5)*torch.randn(blur_image.shape[0], 1, blur_image.shape[2], blur_image.shape[3])\n",
    "    noise = noise.cuda()\n",
    "    blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "    fake_image = S(blur_image_with_noise)\n",
    "    \n",
    "    \n",
    "    vutils.save_image(fake_image[0], './test_result/{}_simulated.png'.format(index))\n",
    "    vutils.save_image(blur_image[0], './test_result/{}_blur.png'.format(index))\n",
    "    vutils.save_image(test_img, './test_result/{}_origin.png'.format(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
