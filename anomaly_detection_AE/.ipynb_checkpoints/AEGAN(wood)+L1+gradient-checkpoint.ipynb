{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from utils.tools import get_config, default_loader, is_image_file, normalize\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sys.path.append('../PerceptualSimilarity')\n",
    "import models as PerceptualSimilarity\n",
    "\n",
    "# personal library\n",
    "from networks import autoencoder, coordSimulator, discriminator\n",
    "from dataloader import MVTecDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限制可以使用的 GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER parameters\n",
    "num_epochs = 50000\n",
    "batch_size = 32\n",
    "val_batch_size = 4\n",
    "ae_lr = 1e-4\n",
    "s_lr = 5e-4\n",
    "d_lr = 5e-4\n",
    "weight_decay = 1e-5\n",
    "UPSET=True\n",
    "expName = 'AEGAN-exp2(wood + L1)'\n",
    "writer = SummaryWriter('checkpoints/'+expName)\n",
    "TYPE='wood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='train')\n",
    "testDatset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='test')\n",
    "valDataset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='val')\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=valDataset,\n",
    "    batch_size=val_batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=trainDatset,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=testDatset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n",
      "Loading model from: /workspace/PerceptualSimilarity/models/weights/v0.1/alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "AE = autoencoder.Autoencoder().cuda()\n",
    "S = nn.DataParallel(coordSimulator.Simulator(3, 8)).cuda()\n",
    "D = nn.DataParallel(discriminator.Discriminator(6, 16)).cuda()\n",
    "\n",
    "# Loss\n",
    "L1_loss = nn.L1Loss()\n",
    "L2_loss = nn.MSELoss(reduction='none')\n",
    "perceptual_loss = PerceptualSimilarity.PerceptualLoss(model='net-lin', net='alex', use_gpu=True, gpu_ids=[0])\n",
    "\n",
    "# Optimizer\n",
    "optimizer_AE = torch.optim.Adam(\n",
    "    AE.parameters(), \n",
    "    lr=ae_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optimizer_S = torch.optim.Adam(\n",
    "    S.parameters(), \n",
    "    lr=s_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    D.parameters(), \n",
    "    lr=d_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.load_state_dict(torch.load('./save_weight/AE-wood-z-2x2-exp2/AE_2500.npy', map_location=\"cuda:0\"), False)\n",
    "\n",
    "AE = nn.DataParallel(AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Solve: RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n",
    "torch.backends.cudnn.enabled = False \n",
    "\n",
    "# 拿掉煩人的 warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "\n",
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    # print \"real_data: \", real_data.size(), fake_data.size()\n",
    "    BATCH_SIZE = real_data.size(0)\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(BATCH_SIZE, real_data.nelement()//BATCH_SIZE).contiguous().view(BATCH_SIZE, 6, 256, 256)\n",
    "    alpha = alpha.cuda()\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(\n",
    "        outputs=disc_interpolates, \n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
    "        create_graph=True, \n",
    "        retain_graph=True, \n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "def gradient_loss(gen_frames, gt_frames, alpha=1):\n",
    "    def gradient(x):\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        # gradient step=1\n",
    "        left = x\n",
    "        right = F.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = F.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        # dx, dy = torch.abs(right - left), torch.abs(bottom - top)\n",
    "        dx, dy = right - left, bottom - top \n",
    "        # dx will always have zeros in the last column, right-left\n",
    "        # dy will always have zeros in the last row,    bottom-top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return dx, dy\n",
    "\n",
    "    # gradient\n",
    "    gen_dx, gen_dy = gradient(gen_frames)\n",
    "    gt_dx, gt_dy = gradient(gt_frames)\n",
    "    #\n",
    "    grad_diff_x = torch.abs(gt_dx - gen_dx)\n",
    "    grad_diff_y = torch.abs(gt_dy - gen_dy)\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return torch.mean(grad_diff_x ** alpha + grad_diff_y ** alpha)\n",
    "\n",
    "def difNormalize(input_matrix, threshold=None):\n",
    "    _min = torch.min(input_matrix)\n",
    "    _max = torch.max(input_matrix)\n",
    "    \n",
    "    input_matrix = (input_matrix - _min) / (_max - _min)\n",
    "    \n",
    "    if threshold != None:\n",
    "        input_matrix[input_matrix < threshold] = 0\n",
    "        input_matrix[input_matrix >= threshold] = 1\n",
    "        \n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs): \n",
    "    start = time.time()\n",
    "    ######## GAN ################\n",
    "    one = torch.FloatTensor([1])\n",
    "    mone = one * -1\n",
    "    \n",
    "    one = one.cuda()\n",
    "    mone = mone.cuda()\n",
    "    \n",
    "    one = one.mean()\n",
    "    mone = mone.mean()\n",
    "    ## ==== GAN --> D =====\n",
    "    for i in range(3):\n",
    "        for index, img in enumerate(train_loader):\n",
    "            AE.eval(), S.train(), D.train()\n",
    "\n",
    "            img = Variable(img).cuda()\n",
    "\n",
    "            # ====== AE ======\n",
    "            blur_image = AE(img)\n",
    "\n",
    "            _bs, _c, _w, _h = blur_image.shape\n",
    "            noise = torch.zeros(_bs, 1, _w, _h )\n",
    "            noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "            noise = noise.cuda()\n",
    "\n",
    "            blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "            fake_image = S(blur_image_with_noise) # 當成是 residual\n",
    "            \n",
    "            fake_image = fake_image + blur_image # blur image + residual\n",
    "            \n",
    "            fake_pair = torch.cat([img, fake_image], 1)\n",
    "            real_pair = torch.cat([img, img[torch.randperm(img.size(0)), :, :, :]], 1) if UPSET else torch.cat([img, img], 1)\n",
    "            # ====== Train D ======\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            optimizer_AE.zero_grad()\n",
    "            optimizer_S.zero_grad()\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "\n",
    "            real_D = D(real_pair)\n",
    "            real_D = real_D.mean()\n",
    "            real_D.backward(mone)\n",
    "\n",
    "\n",
    "            fake_D = D(fake_pair)\n",
    "            fake_D = fake_D.mean()\n",
    "            fake_D.backward(one)\n",
    "\n",
    "            gradient_penalty = calc_gradient_penalty(D, real_pair, fake_pair)\n",
    "            gradient_penalty.backward()\n",
    "\n",
    "            cost_D = fake_D - real_D + gradient_penalty\n",
    "            Wasserstein_D = real_D - fake_D\n",
    "            optimizer_D.step()\n",
    "    \n",
    "    ## ==== GAN --> G =====\n",
    "    for index, img in enumerate(train_loader):\n",
    "        AE.eval(), S.train(), D.train()\n",
    "\n",
    "        img = Variable(img).cuda()\n",
    "        # ======AE======\n",
    "        blur_image = AE(img)\n",
    "\n",
    "        _bs, _c, _w, _h = blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "        fake_image = S(blur_image_with_noise)\n",
    "        \n",
    "        fake_image = fake_image + blur_image\n",
    "        \n",
    "        fake_pair = torch.cat([img, fake_image], 1)\n",
    "        # ====== Train G ======\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        G_L1 = L1_loss(img, fake_image)\n",
    "        \n",
    "        G = D(fake_pair)\n",
    "        G = G.mean()\n",
    "        G = G + G_L1 * ( G / G_L1) * 100\n",
    "        \n",
    "        optimizer_AE.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        G.backward(mone)\n",
    "        \n",
    "        cost_G = -G\n",
    "        optimizer_S.step()\n",
    "        \n",
    "    \n",
    "    # validation set\n",
    "    for index, val_img in enumerate(val_loader):\n",
    "        AE.eval(), S.eval(), D.eval()\n",
    "\n",
    "        val_img = Variable(val_img).cuda()\n",
    "        # ======AE======\n",
    "        val_blur_image = AE(val_img)\n",
    "\n",
    "        _bs, _c, _w, _h = val_blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        val_blur_image_with_noise = torch.cat([val_blur_image, noise], 1)\n",
    "\n",
    "        val_fake_image = S(val_blur_image_with_noise)       \n",
    "        val_fake_image = val_fake_image + val_blur_image\n",
    "        \n",
    "        \n",
    "        val_fake_pair = torch.cat([val_img, val_fake_image], 1)\n",
    "        val_real_pair = torch.cat([val_img, val_img[torch.randperm(val_img.size(0)), :, :, :]], 1) if UPSET else torch.cat([val_img, val_img], 1)\n",
    "        \n",
    "        val_real_D = D(val_real_pair)\n",
    "        val_real_D = val_real_D.mean()\n",
    "        \n",
    "        val_fake_D = D(val_fake_pair)\n",
    "        val_fake_D = val_fake_D.mean()\n",
    "        \n",
    "        val_gradient_penalty = calc_gradient_penalty(D, val_real_pair, val_fake_pair)\n",
    "        \n",
    "        val_G_L1 = L1_loss(val_img, val_fake_image)\n",
    "        # =========== Losses =========\n",
    "        val_Wasserstein_D = val_real_D - val_fake_D\n",
    "        \n",
    "        val_cost_G = -val_fake_D\n",
    "        val_cost_D = val_fake_D - val_real_D + val_gradient_penalty\n",
    "    \n",
    "    # evaluate\n",
    "    test_total_AUC = 0\n",
    "    test_total_AUC2 = 0\n",
    "    test_total_image = 0\n",
    "\n",
    "    for index, (test_img, mask) in enumerate(test_loader):\n",
    "        AE.eval(), S.eval(), D.eval()\n",
    "        test_img = Variable(test_img).cuda()\n",
    "        test_blur_image = AE(test_img)\n",
    "\n",
    "        _bs, _c, _w, _h = test_blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        test_blur_image_with_noise = torch.cat([test_blur_image, noise], 1)\n",
    "\n",
    "        test_fake_image = S(test_blur_image_with_noise)       \n",
    "        test_fake_image = test_fake_image + test_blur_image\n",
    "\n",
    "        # 計算 dif (相似度以及 L2)\n",
    "        dif, _ = perceptual_loss.forward(test_fake_image, test_img)\n",
    "        l2Dif = L2_loss(test_fake_image, test_img)\n",
    "        l2Dif = torch.mean(l2Dif, 1, True)\n",
    "        \n",
    "        pred_mask2 = difNormalize(dif)\n",
    "        pred_mask2 = torch.flatten(pred_mask2[0])\n",
    "        \n",
    "        pred_mask = difNormalize(dif[0] * l2Dif[0])\n",
    "        pred_mask = torch.flatten(pred_mask)\n",
    "        \n",
    "        mask = torch.mean(mask, 1, True)\n",
    "        true_mask = mask[0].cpu().detach().numpy().flatten()\n",
    "        true_mask = true_mask.astype(int)\n",
    "\n",
    "        AUC = roc_auc_score(true_mask, pred_mask.cpu().detach().numpy())\n",
    "        AUC2 = roc_auc_score(true_mask, pred_mask2.cpu().detach().numpy())\n",
    "\n",
    "        test_total_AUC += AUC\n",
    "        test_total_AUC2 += AUC2\n",
    "        test_total_image += 1\n",
    "    \n",
    "    # =================== GAN log========================\n",
    "    end = time.time()\n",
    "    print('epoch [{}/{}] s_loss:{:.4f} d_loss:{:.4f} val_s_loss:{:.4f} val_d_loss:{:.4f} cost:{:.2f}'.format(epoch+1, num_epochs, cost_G.item(), cost_D.item(), val_cost_G.item(), val_cost_D.item(), end-start ))\n",
    "    writer.add_scalars('eval', {\n",
    "        \"auc_roc_score\": test_total_AUC / test_total_image,\n",
    "        \"auc_roc_score(w/o L2)\": test_total_AUC2 / test_total_image,\n",
    "    }, epoch)\n",
    "    \n",
    "    writer.add_scalars('loss', {\n",
    "        \"Wasserstein Distance\": Wasserstein_D.item(),\n",
    "        \"Val Wasserstein Distance\": val_Wasserstein_D.item(),\n",
    "        \"gradient penalty\": gradient_penalty,\n",
    "        \"val gradient penalty\": val_gradient_penalty\n",
    "    }, epoch)\n",
    "    \n",
    "    writer.add_scalars('gan loss', {\n",
    "        \"l1_loss\": G_L1.item(),\n",
    "        \"g_loss\": cost_G.item(),\n",
    "        \"d_loss\": cost_D.item(),\n",
    "        \"val_l1_loss\": val_G_L1.item(),\n",
    "        \"val_g_loss\": val_cost_G.item(),\n",
    "        \"val_d_loss\": val_cost_D.item(),\n",
    "    }, epoch)\n",
    "\n",
    "    writer.add_images('Blur', blur_image, epoch)\n",
    "    writer.add_images('Reconstruct', fake_image, epoch)\n",
    "    writer.add_images('Origin', img, epoch)\n",
    "\n",
    "    writer.add_images('Val Blur', val_blur_image, epoch)\n",
    "    writer.add_images('Val Reconstruct', val_fake_image, epoch)\n",
    "    writer.add_images('Val Origin', val_img, epoch)\n",
    "\n",
    "\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        if not os.path.exists('./save_weight/{}'.format(expName)):\n",
    "            os.makedirs('./save_weight/{}'.format(expName))\n",
    "        torch.save(S.state_dict(), './save_weight/{}/S_{}.npy'.format(expName, epoch))\n",
    "        torch.save(D.state_dict(), './save_weight/{}/D_{}.npy'.format(expName, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.eval()\n",
    "S.eval()\n",
    "for index, img in enumerate(test_loader):\n",
    "    test_img = Variable(img[0]).cuda()\n",
    "\n",
    "    # ======AE======\n",
    "    blur_image = AE(test_img)\n",
    "    \n",
    "    noise = torch.zeros(blur_image.shape[0], 1, blur_image.shape[2], blur_image.shape[3] )\n",
    "    noise = noise + (0.01**0.5)*torch.randn(blur_image.shape[0], 1, blur_image.shape[2], blur_image.shape[3])\n",
    "    noise = noise.cuda()\n",
    "    blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "    fake_image = S(blur_image_with_noise)\n",
    "    \n",
    "    \n",
    "    vutils.save_image(fake_image[0], './test_result/{}_simulated.png'.format(index))\n",
    "    vutils.save_image(blur_image[0], './test_result/{}_blur.png'.format(index))\n",
    "    vutils.save_image(test_img, './test_result/{}_origin.png'.format(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
