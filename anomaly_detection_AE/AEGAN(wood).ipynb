{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from utils.tools import get_config, default_loader, is_image_file, normalize\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sys.path.append('../PerceptualSimilarity')\n",
    "import models as PerceptualSimilarity\n",
    "\n",
    "# personal library\n",
    "from networks import autoencoder, simulator, discriminator\n",
    "from dataloader import MVTecDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限制可以使用的 GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER parameters\n",
    "num_epochs = 50000\n",
    "batch_size = 32\n",
    "val_batch_size = 4\n",
    "ae_lr = 1e-4\n",
    "s_lr = 5e-4\n",
    "d_lr = 5e-4\n",
    "weight_decay = 1e-5\n",
    "UPSET=True\n",
    "expName = 'AEGAN-exp2'\n",
    "writer = SummaryWriter('checkpoint/'+expName)\n",
    "TYPE='wood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDatset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='train')\n",
    "testDatset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='test')\n",
    "valDataset = MVTecDataset.MVTecDataset(TYPE=TYPE, isTrain='val')\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=valDataset,\n",
    "    batch_size=val_batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=trainDatset,\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=testDatset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n",
      "Loading model from: /workspace/PerceptualSimilarity/models/weights/v0.1/alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "AE = autoencoder.Autoencoder().cuda()\n",
    "S = nn.DataParallel(simulator.Simulator(3, 8)).cuda()\n",
    "D = nn.DataParallel(discriminator.Discriminator(6, 16)).cuda()\n",
    "\n",
    "# Loss\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "L2_loss = nn.MSELoss(reduction='none')\n",
    "perceptual_loss = PerceptualSimilarity.PerceptualLoss(model='net-lin', net='alex', use_gpu=True, gpu_ids=[0])\n",
    "\n",
    "# Optimizer\n",
    "optimizer_AE = torch.optim.Adam(\n",
    "    AE.parameters(), \n",
    "    lr=ae_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optimizer_S = torch.optim.Adam(\n",
    "    S.parameters(), \n",
    "    lr=s_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    D.parameters(), \n",
    "    lr=d_lr,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.load_state_dict(torch.load('./save_weight/AE-wood-z-2x2-exp2/AE_870.npy'), False)\n",
    "\n",
    "AE = nn.DataParallel(AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Solve: RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED\n",
    "torch.backends.cudnn.enabled = False \n",
    "\n",
    "# 拿掉煩人的 warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "\n",
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    # print \"real_data: \", real_data.size(), fake_data.size()\n",
    "    BATCH_SIZE = real_data.size(0)\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(BATCH_SIZE, real_data.nelement()//BATCH_SIZE).contiguous().view(BATCH_SIZE, 6, 256, 256)\n",
    "    alpha = alpha.cuda()\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    interpolates = interpolates.cuda()\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(\n",
    "        outputs=disc_interpolates, \n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
    "        create_graph=True, \n",
    "        retain_graph=True, \n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n",
    "\n",
    "def difNormalize(input_matrix, threshold=None):\n",
    "    _min = input_matrix.min()\n",
    "    _max = input_matrix.max()\n",
    "    \n",
    "    input_matrix = (input_matrix - _min) / (_max - _min)\n",
    "    \n",
    "    if threshold != None:\n",
    "        input_matrix[input_matrix < threshold] = 0\n",
    "        input_matrix[input_matrix >= threshold] = 1\n",
    "        \n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50000] s_loss:690.0697 d_loss:-269.8229 val_s_loss:432.1385 val_d_loss:224.3205\n",
      "epoch [2/50000] s_loss:741.3499 d_loss:-193.4608 val_s_loss:1102.1472 val_d_loss:-329.5411\n",
      "epoch [3/50000] s_loss:668.0259 d_loss:-151.9991 val_s_loss:615.1177 val_d_loss:-18.3876\n",
      "epoch [4/50000] s_loss:476.6786 d_loss:-149.9790 val_s_loss:421.7453 val_d_loss:-30.0035\n",
      "epoch [5/50000] s_loss:405.4678 d_loss:-172.2160 val_s_loss:426.5683 val_d_loss:-101.0911\n",
      "epoch [6/50000] s_loss:239.5502 d_loss:-84.0852 val_s_loss:455.3849 val_d_loss:-249.5774\n",
      "epoch [7/50000] s_loss:287.5941 d_loss:-79.7907 val_s_loss:628.8970 val_d_loss:-339.0989\n",
      "epoch [8/50000] s_loss:240.3503 d_loss:-62.0685 val_s_loss:244.3835 val_d_loss:-47.4549\n",
      "epoch [9/50000] s_loss:245.1088 d_loss:-30.1329 val_s_loss:309.5803 val_d_loss:-91.5243\n",
      "epoch [10/50000] s_loss:232.1994 d_loss:-54.3959 val_s_loss:165.7977 val_d_loss:18.1455\n",
      "epoch [11/50000] s_loss:52.4000 d_loss:-22.0637 val_s_loss:43.7108 val_d_loss:-14.2442\n",
      "epoch [12/50000] s_loss:159.5164 d_loss:-56.2647 val_s_loss:102.3001 val_d_loss:4.8925\n",
      "epoch [13/50000] s_loss:137.1059 d_loss:-40.9238 val_s_loss:137.5478 val_d_loss:-40.8712\n",
      "epoch [14/50000] s_loss:121.2328 d_loss:-24.9260 val_s_loss:82.5653 val_d_loss:13.4835\n",
      "epoch [15/50000] s_loss:113.8743 d_loss:-36.0986 val_s_loss:207.6464 val_d_loss:-78.0323\n",
      "epoch [16/50000] s_loss:141.5413 d_loss:-25.1381 val_s_loss:79.8349 val_d_loss:3.7143\n",
      "epoch [17/50000] s_loss:137.8370 d_loss:-40.5139 val_s_loss:88.9469 val_d_loss:-5.5142\n",
      "epoch [18/50000] s_loss:81.2060 d_loss:-35.7305 val_s_loss:89.9136 val_d_loss:-43.1831\n",
      "epoch [19/50000] s_loss:69.3946 d_loss:-27.7805 val_s_loss:25.9520 val_d_loss:-1.8447\n",
      "epoch [20/50000] s_loss:38.8385 d_loss:-29.0659 val_s_loss:888.5984 val_d_loss:-643.0487\n",
      "epoch [21/50000] s_loss:95.9884 d_loss:-24.1452 val_s_loss:68.3180 val_d_loss:2.8626\n",
      "epoch [22/50000] s_loss:38.5973 d_loss:-35.1569 val_s_loss:34.0665 val_d_loss:-18.6894\n",
      "epoch [23/50000] s_loss:33.7014 d_loss:-24.8477 val_s_loss:36.7293 val_d_loss:-57.8366\n",
      "epoch [24/50000] s_loss:9.5650 d_loss:-27.5852 val_s_loss:92.4920 val_d_loss:-86.8432\n",
      "epoch [25/50000] s_loss:-2.0331 d_loss:-25.8020 val_s_loss:-6.2928 val_d_loss:-12.6113\n",
      "epoch [26/50000] s_loss:54.2502 d_loss:-18.9785 val_s_loss:29.3337 val_d_loss:7.9051\n",
      "epoch [27/50000] s_loss:29.7687 d_loss:-25.5215 val_s_loss:0.8063 val_d_loss:-1.0920\n",
      "epoch [28/50000] s_loss:40.3565 d_loss:-24.7124 val_s_loss:11.2777 val_d_loss:1.4076\n",
      "epoch [29/50000] s_loss:-21.7276 d_loss:-23.5440 val_s_loss:-42.5392 val_d_loss:4.6455\n",
      "epoch [30/50000] s_loss:88.6465 d_loss:-20.6953 val_s_loss:143.2243 val_d_loss:-60.5724\n",
      "epoch [31/50000] s_loss:143.4924 d_loss:-25.9600 val_s_loss:130.5649 val_d_loss:-25.5703\n",
      "epoch [32/50000] s_loss:-1.7427 d_loss:-30.4053 val_s_loss:70.1573 val_d_loss:-91.8212\n",
      "epoch [33/50000] s_loss:-41.2585 d_loss:-26.2881 val_s_loss:177.9815 val_d_loss:-169.7817\n",
      "epoch [34/50000] s_loss:64.3920 d_loss:-18.2484 val_s_loss:30.8243 val_d_loss:2.6506\n",
      "epoch [35/50000] s_loss:109.7214 d_loss:-14.3398 val_s_loss:81.9313 val_d_loss:0.5444\n",
      "epoch [36/50000] s_loss:26.9525 d_loss:-26.7968 val_s_loss:6.5524 val_d_loss:3.9007\n",
      "epoch [37/50000] s_loss:84.7645 d_loss:-22.0498 val_s_loss:62.8782 val_d_loss:-0.7801\n",
      "epoch [38/50000] s_loss:31.7656 d_loss:-35.9016 val_s_loss:11.7373 val_d_loss:-3.0823\n",
      "epoch [39/50000] s_loss:48.2979 d_loss:-22.1286 val_s_loss:23.0246 val_d_loss:12.7152\n",
      "epoch [40/50000] s_loss:7.4892 d_loss:-20.0073 val_s_loss:-9.8968 val_d_loss:2.4677\n",
      "epoch [41/50000] s_loss:3.8791 d_loss:-22.5766 val_s_loss:-18.9140 val_d_loss:19.1504\n",
      "epoch [42/50000] s_loss:45.7532 d_loss:-24.5654 val_s_loss:14.4220 val_d_loss:-2.7401\n",
      "epoch [43/50000] s_loss:-5.4139 d_loss:-33.9927 val_s_loss:-39.7152 val_d_loss:-0.9423\n",
      "epoch [44/50000] s_loss:-41.2952 d_loss:-23.0469 val_s_loss:-42.1208 val_d_loss:-12.4415\n",
      "epoch [45/50000] s_loss:-80.8898 d_loss:-29.6546 val_s_loss:-105.9697 val_d_loss:-6.0430\n",
      "epoch [46/50000] s_loss:-62.2142 d_loss:-28.1882 val_s_loss:-78.3987 val_d_loss:-9.5364\n",
      "epoch [47/50000] s_loss:74.7200 d_loss:-20.2161 val_s_loss:88.1682 val_d_loss:-35.1917\n",
      "epoch [48/50000] s_loss:38.5705 d_loss:-22.9354 val_s_loss:16.6621 val_d_loss:-3.2328\n",
      "epoch [49/50000] s_loss:-36.0348 d_loss:-20.9466 val_s_loss:-22.5311 val_d_loss:-12.0239\n",
      "epoch [50/50000] s_loss:-18.7636 d_loss:-7.7226 val_s_loss:169.6463 val_d_loss:-184.6445\n",
      "epoch [51/50000] s_loss:-183.8507 d_loss:-5.4414 val_s_loss:-175.2035 val_d_loss:0.2348\n",
      "epoch [52/50000] s_loss:-87.9383 d_loss:-8.6229 val_s_loss:-93.3450 val_d_loss:5.3840\n",
      "epoch [53/50000] s_loss:557.4001 d_loss:-418.0918 val_s_loss:1433.9819 val_d_loss:-596.1753\n",
      "epoch [54/50000] s_loss:-11.6184 d_loss:8.1142 val_s_loss:-10.1992 val_d_loss:7.1409\n",
      "epoch [55/50000] s_loss:-27.1687 d_loss:7.4904 val_s_loss:-36.9805 val_d_loss:17.7651\n",
      "epoch [56/50000] s_loss:-90.3114 d_loss:-4.8718 val_s_loss:-88.9469 val_d_loss:-9.3470\n",
      "epoch [57/50000] s_loss:-43.8814 d_loss:-39.7792 val_s_loss:-59.7419 val_d_loss:-9.3802\n",
      "epoch [58/50000] s_loss:199.1661 d_loss:-38.7343 val_s_loss:402.8442 val_d_loss:-234.8601\n",
      "epoch [59/50000] s_loss:84.2955 d_loss:-14.0511 val_s_loss:188.3979 val_d_loss:-93.9140\n",
      "epoch [60/50000] s_loss:465.2578 d_loss:-31.4202 val_s_loss:709.4019 val_d_loss:-259.1047\n",
      "epoch [61/50000] s_loss:269.3911 d_loss:-43.5811 val_s_loss:260.5119 val_d_loss:-12.5999\n",
      "epoch [62/50000] s_loss:239.3134 d_loss:-15.8886 val_s_loss:249.5297 val_d_loss:-54.3498\n",
      "epoch [63/50000] s_loss:240.5729 d_loss:-75.6648 val_s_loss:150.1838 val_d_loss:10.7748\n",
      "epoch [64/50000] s_loss:169.7298 d_loss:-52.4290 val_s_loss:92.3194 val_d_loss:24.1648\n",
      "epoch [65/50000] s_loss:193.3267 d_loss:-53.5813 val_s_loss:174.3947 val_d_loss:-13.9220\n",
      "epoch [66/50000] s_loss:162.1561 d_loss:-52.8062 val_s_loss:1209.2192 val_d_loss:-940.5879\n",
      "epoch [67/50000] s_loss:134.4257 d_loss:-49.1247 val_s_loss:80.9895 val_d_loss:2.3845\n",
      "epoch [68/50000] s_loss:85.4731 d_loss:-17.4002 val_s_loss:53.0790 val_d_loss:16.0883\n",
      "epoch [69/50000] s_loss:59.2500 d_loss:-28.2866 val_s_loss:9.9653 val_d_loss:-1.8189\n",
      "epoch [70/50000] s_loss:51.7527 d_loss:-33.6648 val_s_loss:7.4616 val_d_loss:-1.6193\n",
      "epoch [71/50000] s_loss:14.8804 d_loss:-23.4200 val_s_loss:-4.9580 val_d_loss:-1.8422\n",
      "epoch [72/50000] s_loss:34.3119 d_loss:-21.6890 val_s_loss:8.6138 val_d_loss:-2.2999\n",
      "epoch [73/50000] s_loss:85.0378 d_loss:-17.6708 val_s_loss:43.4892 val_d_loss:0.1475\n",
      "epoch [74/50000] s_loss:67.9983 d_loss:-35.2525 val_s_loss:55.8146 val_d_loss:-18.7618\n",
      "epoch [75/50000] s_loss:50.8256 d_loss:-26.2232 val_s_loss:19.3816 val_d_loss:-1.7836\n",
      "epoch [76/50000] s_loss:38.3050 d_loss:-27.5712 val_s_loss:-1.6008 val_d_loss:-2.5894\n",
      "epoch [77/50000] s_loss:17.3688 d_loss:-16.3357 val_s_loss:19.5739 val_d_loss:-16.9320\n",
      "epoch [78/50000] s_loss:29.8852 d_loss:-16.3389 val_s_loss:-7.4467 val_d_loss:0.7948\n",
      "epoch [79/50000] s_loss:23.3064 d_loss:-24.2600 val_s_loss:9.7413 val_d_loss:-11.3413\n",
      "epoch [80/50000] s_loss:9.0386 d_loss:-12.6556 val_s_loss:20.1184 val_d_loss:-31.3817\n",
      "epoch [81/50000] s_loss:-0.6971 d_loss:-13.8186 val_s_loss:-14.7642 val_d_loss:0.3495\n",
      "epoch [82/50000] s_loss:5.1347 d_loss:-23.7956 val_s_loss:-6.8943 val_d_loss:2.6256\n",
      "epoch [83/50000] s_loss:79.0008 d_loss:-3.2720 val_s_loss:113.0954 val_d_loss:-37.5262\n",
      "epoch [84/50000] s_loss:57.6546 d_loss:-9.8050 val_s_loss:56.0722 val_d_loss:-9.5069\n",
      "epoch [85/50000] s_loss:35.8406 d_loss:-15.2051 val_s_loss:23.2743 val_d_loss:-2.7891\n",
      "epoch [86/50000] s_loss:-12.7027 d_loss:-13.9227 val_s_loss:-26.7191 val_d_loss:-0.7793\n",
      "epoch [87/50000] s_loss:-45.4308 d_loss:-14.7758 val_s_loss:-63.8793 val_d_loss:23.4950\n",
      "epoch [88/50000] s_loss:313.6015 d_loss:-69.8738 val_s_loss:1117.5530 val_d_loss:-773.6379\n",
      "epoch [89/50000] s_loss:297.1780 d_loss:-58.1950 val_s_loss:1508.8535 val_d_loss:-856.8199\n",
      "epoch [90/50000] s_loss:172.4895 d_loss:-54.0621 val_s_loss:129.8206 val_d_loss:-4.4186\n",
      "epoch [91/50000] s_loss:182.0157 d_loss:-15.1585 val_s_loss:213.8430 val_d_loss:-38.5850\n",
      "epoch [92/50000] s_loss:183.2452 d_loss:-33.0630 val_s_loss:187.1861 val_d_loss:-29.9121\n",
      "epoch [93/50000] s_loss:247.1057 d_loss:-51.4636 val_s_loss:236.3359 val_d_loss:-26.7753\n",
      "epoch [94/50000] s_loss:188.8959 d_loss:-30.0358 val_s_loss:157.8149 val_d_loss:-4.2615\n",
      "epoch [95/50000] s_loss:197.2478 d_loss:-29.1971 val_s_loss:187.3108 val_d_loss:-15.7255\n",
      "epoch [96/50000] s_loss:129.0091 d_loss:-24.7934 val_s_loss:110.5955 val_d_loss:-15.9664\n",
      "epoch [97/50000] s_loss:103.4549 d_loss:-25.8300 val_s_loss:88.9818 val_d_loss:-12.3884\n",
      "epoch [98/50000] s_loss:75.2514 d_loss:-24.7360 val_s_loss:53.9252 val_d_loss:0.0244\n",
      "epoch [99/50000] s_loss:89.7951 d_loss:-16.4243 val_s_loss:62.7221 val_d_loss:1.3747\n",
      "epoch [100/50000] s_loss:29.7641 d_loss:-27.9646 val_s_loss:9.5170 val_d_loss:0.3030\n",
      "epoch [101/50000] s_loss:63.8735 d_loss:-28.9241 val_s_loss:37.7650 val_d_loss:-2.2378\n",
      "epoch [102/50000] s_loss:41.5460 d_loss:-28.2432 val_s_loss:55.8352 val_d_loss:-26.1600\n",
      "epoch [103/50000] s_loss:58.4599 d_loss:-36.9021 val_s_loss:9.1180 val_d_loss:-3.0280\n",
      "epoch [104/50000] s_loss:113.3514 d_loss:-41.3670 val_s_loss:38.8330 val_d_loss:-5.6191\n",
      "epoch [105/50000] s_loss:85.5328 d_loss:-48.1623 val_s_loss:13.9245 val_d_loss:-1.8349\n",
      "epoch [106/50000] s_loss:19.9777 d_loss:-60.5794 val_s_loss:27.1742 val_d_loss:-10.8451\n",
      "epoch [107/50000] s_loss:13.3028 d_loss:-36.2789 val_s_loss:-25.3201 val_d_loss:-9.3901\n",
      "epoch [108/50000] s_loss:3.5357 d_loss:-34.6600 val_s_loss:-23.7018 val_d_loss:0.7473\n",
      "epoch [109/50000] s_loss:2.4314 d_loss:-26.4254 val_s_loss:9.1711 val_d_loss:-24.5993\n",
      "epoch [110/50000] s_loss:-15.0499 d_loss:-28.8963 val_s_loss:-35.0915 val_d_loss:-4.1453\n",
      "epoch [111/50000] s_loss:-21.1831 d_loss:-22.1360 val_s_loss:-51.7212 val_d_loss:-8.6881\n",
      "epoch [112/50000] s_loss:-32.3778 d_loss:-35.0607 val_s_loss:-68.5408 val_d_loss:1.6900\n",
      "epoch [113/50000] s_loss:-50.7523 d_loss:-31.4578 val_s_loss:-82.1228 val_d_loss:-0.4890\n",
      "epoch [114/50000] s_loss:-48.8279 d_loss:-22.2957 val_s_loss:-78.4710 val_d_loss:-7.9152\n",
      "epoch [115/50000] s_loss:125.8988 d_loss:-4.6071 val_s_loss:133.2251 val_d_loss:-12.0481\n",
      "epoch [116/50000] s_loss:124.2761 d_loss:-5.7126 val_s_loss:126.9176 val_d_loss:-10.9690\n",
      "epoch [117/50000] s_loss:94.2876 d_loss:-15.2087 val_s_loss:83.3577 val_d_loss:2.2242\n",
      "epoch [118/50000] s_loss:15.1910 d_loss:-16.6629 val_s_loss:8.4602 val_d_loss:-3.1057\n",
      "epoch [119/50000] s_loss:-56.1086 d_loss:-13.6039 val_s_loss:-53.5845 val_d_loss:1.0650\n",
      "epoch [120/50000] s_loss:152.9441 d_loss:-21.9181 val_s_loss:175.1199 val_d_loss:-22.7254\n",
      "epoch [121/50000] s_loss:86.6992 d_loss:-8.5301 val_s_loss:79.7539 val_d_loss:2.4662\n",
      "epoch [122/50000] s_loss:118.7649 d_loss:-17.5195 val_s_loss:98.3218 val_d_loss:0.9266\n",
      "epoch [123/50000] s_loss:92.8973 d_loss:-17.8688 val_s_loss:79.9738 val_d_loss:-5.0543\n",
      "epoch [124/50000] s_loss:65.9339 d_loss:-17.5383 val_s_loss:59.2494 val_d_loss:-1.0269\n",
      "epoch [125/50000] s_loss:48.1199 d_loss:-13.8173 val_s_loss:67.6353 val_d_loss:-22.4854\n",
      "epoch [126/50000] s_loss:46.0039 d_loss:-15.7985 val_s_loss:71.7373 val_d_loss:-32.8545\n",
      "epoch [127/50000] s_loss:119.2777 d_loss:-14.6065 val_s_loss:102.3684 val_d_loss:1.0670\n",
      "epoch [128/50000] s_loss:129.9034 d_loss:-18.0149 val_s_loss:112.4157 val_d_loss:-7.2948\n",
      "epoch [129/50000] s_loss:99.4300 d_loss:-21.1552 val_s_loss:99.6780 val_d_loss:-11.7663\n",
      "epoch [130/50000] s_loss:39.4235 d_loss:-15.4932 val_s_loss:34.6785 val_d_loss:1.5377\n",
      "epoch [131/50000] s_loss:25.8151 d_loss:-12.8422 val_s_loss:2.2674 val_d_loss:-6.1334\n",
      "epoch [132/50000] s_loss:22.6159 d_loss:-9.1299 val_s_loss:55.3776 val_d_loss:-39.3385\n",
      "epoch [133/50000] s_loss:44.1989 d_loss:-21.2747 val_s_loss:54.0862 val_d_loss:-23.3027\n",
      "epoch [134/50000] s_loss:34.1186 d_loss:-22.0103 val_s_loss:69.3018 val_d_loss:-46.6240\n",
      "epoch [135/50000] s_loss:15.8975 d_loss:-17.5497 val_s_loss:52.4507 val_d_loss:-41.9948\n",
      "epoch [136/50000] s_loss:6.4538 d_loss:-20.3793 val_s_loss:2.0951 val_d_loss:-8.1219\n",
      "epoch [137/50000] s_loss:-7.3724 d_loss:-36.3354 val_s_loss:-1.9055 val_d_loss:-20.9905\n",
      "epoch [138/50000] s_loss:2.8679 d_loss:-18.5934 val_s_loss:23.4039 val_d_loss:-52.2873\n",
      "epoch [139/50000] s_loss:-3.9901 d_loss:-15.4213 val_s_loss:-16.8697 val_d_loss:-3.0377\n",
      "epoch [140/50000] s_loss:41.3031 d_loss:-1.9422 val_s_loss:227.6221 val_d_loss:-187.4203\n",
      "epoch [141/50000] s_loss:87.2765 d_loss:-17.2332 val_s_loss:151.6773 val_d_loss:-78.5229\n",
      "epoch [142/50000] s_loss:116.3972 d_loss:-29.8491 val_s_loss:195.1071 val_d_loss:-98.5198\n",
      "epoch [143/50000] s_loss:213.1565 d_loss:-21.3963 val_s_loss:144.7475 val_d_loss:2.1267\n",
      "epoch [144/50000] s_loss:56.2424 d_loss:-36.5678 val_s_loss:56.1991 val_d_loss:-28.7992\n",
      "epoch [145/50000] s_loss:25.1545 d_loss:-7.0216 val_s_loss:35.6958 val_d_loss:-34.4258\n",
      "epoch [146/50000] s_loss:64.1885 d_loss:-33.9148 val_s_loss:51.0164 val_d_loss:-5.4886\n",
      "epoch [147/50000] s_loss:83.0113 d_loss:-23.5633 val_s_loss:67.6710 val_d_loss:0.1207\n",
      "epoch [148/50000] s_loss:56.2934 d_loss:-19.6196 val_s_loss:36.7230 val_d_loss:-2.8949\n",
      "epoch [149/50000] s_loss:14.7467 d_loss:-21.4548 val_s_loss:0.7359 val_d_loss:-6.8528\n",
      "epoch [150/50000] s_loss:76.4790 d_loss:-19.1074 val_s_loss:65.3265 val_d_loss:-2.3026\n",
      "epoch [151/50000] s_loss:-5.7476 d_loss:-25.8391 val_s_loss:-25.3007 val_d_loss:-7.5644\n",
      "epoch [152/50000] s_loss:-42.5136 d_loss:-28.5235 val_s_loss:-56.9961 val_d_loss:-16.1173\n",
      "epoch [153/50000] s_loss:-48.8340 d_loss:-23.6971 val_s_loss:-57.1192 val_d_loss:-16.9864\n",
      "epoch [154/50000] s_loss:-68.3313 d_loss:-25.0772 val_s_loss:-80.3640 val_d_loss:-10.8608\n",
      "epoch [155/50000] s_loss:-79.1711 d_loss:-24.4845 val_s_loss:-65.0137 val_d_loss:-12.6556\n",
      "epoch [156/50000] s_loss:184.3525 d_loss:-15.7630 val_s_loss:171.8734 val_d_loss:-1.9413\n",
      "epoch [157/50000] s_loss:210.2190 d_loss:-9.2704 val_s_loss:206.1504 val_d_loss:-6.4780\n",
      "epoch [158/50000] s_loss:94.2140 d_loss:-12.0433 val_s_loss:88.0324 val_d_loss:-8.0805\n",
      "epoch [159/50000] s_loss:-75.3781 d_loss:-16.7834 val_s_loss:-79.4871 val_d_loss:-8.8318\n",
      "epoch [160/50000] s_loss:-94.2354 d_loss:-22.9063 val_s_loss:-105.2562 val_d_loss:-9.6863\n",
      "epoch [161/50000] s_loss:-114.9059 d_loss:-20.4073 val_s_loss:-123.0601 val_d_loss:-11.1434\n",
      "epoch [162/50000] s_loss:-96.1118 d_loss:-19.0794 val_s_loss:-93.2829 val_d_loss:-20.6672\n",
      "epoch [163/50000] s_loss:-103.8552 d_loss:-18.5170 val_s_loss:-109.7889 val_d_loss:-13.7833\n",
      "epoch [164/50000] s_loss:54.7954 d_loss:-12.8220 val_s_loss:47.3414 val_d_loss:-8.6809\n",
      "epoch [165/50000] s_loss:-83.5266 d_loss:-21.3571 val_s_loss:-84.9950 val_d_loss:-13.9942\n",
      "epoch [166/50000] s_loss:-98.9295 d_loss:-24.9674 val_s_loss:-98.5520 val_d_loss:-13.8617\n",
      "epoch [167/50000] s_loss:200.6191 d_loss:8.2163 val_s_loss:194.9105 val_d_loss:9.7249\n",
      "epoch [168/50000] s_loss:12.2870 d_loss:-16.3347 val_s_loss:19.2183 val_d_loss:-22.9381\n",
      "epoch [169/50000] s_loss:-64.2135 d_loss:-22.9384 val_s_loss:-58.1377 val_d_loss:-29.7042\n",
      "epoch [170/50000] s_loss:-81.1285 d_loss:-27.7290 val_s_loss:-71.5477 val_d_loss:-29.7050\n",
      "epoch [171/50000] s_loss:-91.4510 d_loss:-24.6088 val_s_loss:-71.7357 val_d_loss:-31.1185\n",
      "epoch [172/50000] s_loss:-41.3458 d_loss:-20.4384 val_s_loss:-30.8756 val_d_loss:-23.0759\n",
      "epoch [173/50000] s_loss:5.5192 d_loss:-20.8339 val_s_loss:-6.1489 val_d_loss:-10.1621\n",
      "epoch [174/50000] s_loss:30.9167 d_loss:-22.0073 val_s_loss:26.3337 val_d_loss:-9.9234\n",
      "epoch [175/50000] s_loss:22.3231 d_loss:-22.5606 val_s_loss:15.7130 val_d_loss:-12.7192\n",
      "epoch [176/50000] s_loss:137.1944 d_loss:-22.9927 val_s_loss:125.9340 val_d_loss:-7.5557\n",
      "epoch [177/50000] s_loss:69.2010 d_loss:-23.4656 val_s_loss:57.0220 val_d_loss:-11.5446\n",
      "epoch [178/50000] s_loss:-29.2435 d_loss:-27.2272 val_s_loss:-39.8253 val_d_loss:-18.0712\n",
      "epoch [179/50000] s_loss:-50.4015 d_loss:-28.2506 val_s_loss:-56.8262 val_d_loss:-11.8416\n",
      "epoch [180/50000] s_loss:-35.8447 d_loss:-23.9713 val_s_loss:-48.5946 val_d_loss:-13.6943\n",
      "epoch [181/50000] s_loss:-42.0512 d_loss:-29.2821 val_s_loss:-19.1436 val_d_loss:-37.6682\n",
      "epoch [182/50000] s_loss:50.3545 d_loss:-16.6571 val_s_loss:45.4845 val_d_loss:-8.0491\n",
      "epoch [183/50000] s_loss:1.7758 d_loss:-22.7293 val_s_loss:-11.7435 val_d_loss:-10.5661\n",
      "epoch [184/50000] s_loss:-9.8635 d_loss:-20.8584 val_s_loss:-19.0123 val_d_loss:-5.9092\n",
      "epoch [185/50000] s_loss:27.9277 d_loss:-5.1819 val_s_loss:19.6613 val_d_loss:0.9329\n",
      "epoch [186/50000] s_loss:-1.4085 d_loss:-10.5271 val_s_loss:10.9540 val_d_loss:-21.3776\n",
      "epoch [187/50000] s_loss:-17.8390 d_loss:-18.0911 val_s_loss:-33.4663 val_d_loss:-4.3534\n",
      "epoch [188/50000] s_loss:-84.3972 d_loss:-22.8329 val_s_loss:-88.5787 val_d_loss:-12.8411\n",
      "epoch [189/50000] s_loss:-114.3235 d_loss:-23.0952 val_s_loss:-103.7804 val_d_loss:-26.4814\n",
      "epoch [190/50000] s_loss:-35.0375 d_loss:-14.0329 val_s_loss:-35.8733 val_d_loss:-3.2470\n",
      "epoch [191/50000] s_loss:151.4211 d_loss:-28.3102 val_s_loss:137.4755 val_d_loss:-2.5843\n",
      "epoch [192/50000] s_loss:152.7364 d_loss:-10.6569 val_s_loss:154.9265 val_d_loss:-4.4733\n",
      "epoch [193/50000] s_loss:134.6698 d_loss:-13.7691 val_s_loss:127.3203 val_d_loss:-10.1895\n",
      "epoch [194/50000] s_loss:76.9845 d_loss:-18.3381 val_s_loss:71.9137 val_d_loss:-15.4738\n",
      "epoch [195/50000] s_loss:34.5150 d_loss:-22.6440 val_s_loss:28.0848 val_d_loss:-15.4307\n",
      "epoch [196/50000] s_loss:4.7551 d_loss:-20.7269 val_s_loss:0.7525 val_d_loss:-15.2508\n",
      "epoch [197/50000] s_loss:1.9902 d_loss:-19.6385 val_s_loss:-10.2321 val_d_loss:-13.3810\n",
      "epoch [198/50000] s_loss:-29.3228 d_loss:-30.2573 val_s_loss:0.6033 val_d_loss:-41.7479\n",
      "epoch [199/50000] s_loss:-26.2053 d_loss:-20.9371 val_s_loss:-32.2415 val_d_loss:-15.2245\n",
      "epoch [200/50000] s_loss:-11.9416 d_loss:-28.5123 val_s_loss:-16.9631 val_d_loss:-4.5855\n",
      "epoch [201/50000] s_loss:156.8647 d_loss:-72.3690 val_s_loss:150.4937 val_d_loss:24.4772\n",
      "epoch [202/50000] s_loss:17.5048 d_loss:-12.5805 val_s_loss:8.8097 val_d_loss:-7.6164\n",
      "epoch [203/50000] s_loss:39.7412 d_loss:-25.7363 val_s_loss:27.1999 val_d_loss:-12.1886\n",
      "epoch [204/50000] s_loss:-12.4614 d_loss:-26.5913 val_s_loss:-24.9777 val_d_loss:-14.2652\n",
      "epoch [205/50000] s_loss:-29.3325 d_loss:-32.2213 val_s_loss:-28.9287 val_d_loss:-28.4280\n",
      "epoch [206/50000] s_loss:-18.4137 d_loss:-28.4150 val_s_loss:-29.1827 val_d_loss:-9.0810\n",
      "epoch [207/50000] s_loss:38.1438 d_loss:-21.4779 val_s_loss:17.6004 val_d_loss:-10.5562\n",
      "epoch [208/50000] s_loss:16.2022 d_loss:-26.4478 val_s_loss:9.7073 val_d_loss:-18.2497\n",
      "epoch [209/50000] s_loss:0.8407 d_loss:-25.1123 val_s_loss:-12.4047 val_d_loss:-14.5091\n",
      "epoch [210/50000] s_loss:124.0088 d_loss:-29.4471 val_s_loss:116.2585 val_d_loss:-13.8221\n",
      "epoch [211/50000] s_loss:81.0891 d_loss:-28.5948 val_s_loss:68.7653 val_d_loss:-12.9780\n",
      "epoch [212/50000] s_loss:30.6853 d_loss:-27.0970 val_s_loss:16.5135 val_d_loss:-9.5567\n",
      "epoch [213/50000] s_loss:39.4126 d_loss:-23.6361 val_s_loss:33.8984 val_d_loss:-11.0869\n",
      "epoch [214/50000] s_loss:139.4421 d_loss:-53.1179 val_s_loss:164.3663 val_d_loss:-18.7261\n",
      "epoch [215/50000] s_loss:18.1177 d_loss:-8.4233 val_s_loss:17.3866 val_d_loss:-7.5503\n",
      "epoch [216/50000] s_loss:-32.9385 d_loss:-10.0949 val_s_loss:-35.3197 val_d_loss:-7.1339\n",
      "epoch [217/50000] s_loss:-81.3247 d_loss:-17.6054 val_s_loss:-78.5960 val_d_loss:-15.9981\n",
      "epoch [218/50000] s_loss:-100.7799 d_loss:-19.6931 val_s_loss:-99.1696 val_d_loss:-21.7604\n",
      "epoch [219/50000] s_loss:-34.2170 d_loss:-26.6597 val_s_loss:-40.5996 val_d_loss:-13.8927\n",
      "epoch [220/50000] s_loss:0.9160 d_loss:-21.5213 val_s_loss:-13.2526 val_d_loss:-8.2106\n",
      "epoch [221/50000] s_loss:-53.4183 d_loss:-33.0651 val_s_loss:-61.2249 val_d_loss:-19.0161\n",
      "epoch [222/50000] s_loss:-34.2553 d_loss:-28.0878 val_s_loss:-46.0918 val_d_loss:-14.5534\n",
      "epoch [223/50000] s_loss:-46.5624 d_loss:-32.2390 val_s_loss:-37.9691 val_d_loss:-29.2352\n",
      "epoch [224/50000] s_loss:-63.2201 d_loss:-29.5222 val_s_loss:-77.5108 val_d_loss:-12.4890\n",
      "epoch [225/50000] s_loss:-65.7370 d_loss:-31.5375 val_s_loss:-82.9377 val_d_loss:-16.3124\n",
      "epoch [226/50000] s_loss:-80.9116 d_loss:-31.3683 val_s_loss:-79.5607 val_d_loss:-17.4254\n",
      "epoch [227/50000] s_loss:-78.9395 d_loss:-22.8573 val_s_loss:-85.5310 val_d_loss:-11.9071\n",
      "epoch [228/50000] s_loss:-63.4527 d_loss:-26.7475 val_s_loss:-73.0075 val_d_loss:-16.2652\n",
      "epoch [229/50000] s_loss:-67.5058 d_loss:-28.4729 val_s_loss:-74.2550 val_d_loss:-15.3104\n",
      "epoch [230/50000] s_loss:-11.0357 d_loss:-24.0497 val_s_loss:-19.2891 val_d_loss:-13.6422\n",
      "epoch [231/50000] s_loss:19.1095 d_loss:-22.1867 val_s_loss:11.6925 val_d_loss:-10.6809\n",
      "epoch [232/50000] s_loss:83.6326 d_loss:-7.8992 val_s_loss:58.0034 val_d_loss:1.2517\n",
      "epoch [233/50000] s_loss:14.7314 d_loss:-21.9007 val_s_loss:7.9628 val_d_loss:-14.1892\n",
      "epoch [234/50000] s_loss:-18.3526 d_loss:-27.3808 val_s_loss:-27.1690 val_d_loss:-15.4734\n",
      "epoch [235/50000] s_loss:-39.6237 d_loss:-26.3081 val_s_loss:-16.6266 val_d_loss:-27.4315\n",
      "epoch [236/50000] s_loss:155.5617 d_loss:-28.7476 val_s_loss:169.0182 val_d_loss:-18.8801\n",
      "epoch [237/50000] s_loss:50.8382 d_loss:-14.1642 val_s_loss:55.2499 val_d_loss:-20.6582\n",
      "epoch [238/50000] s_loss:-40.4730 d_loss:-18.1770 val_s_loss:-43.2034 val_d_loss:-13.7336\n",
      "epoch [239/50000] s_loss:-58.2957 d_loss:-20.5656 val_s_loss:-51.7849 val_d_loss:-25.3786\n",
      "epoch [240/50000] s_loss:-78.2324 d_loss:-23.8392 val_s_loss:-58.3544 val_d_loss:-28.3433\n",
      "epoch [241/50000] s_loss:-76.1866 d_loss:-23.9644 val_s_loss:-82.7065 val_d_loss:-8.4495\n",
      "epoch [242/50000] s_loss:-80.3282 d_loss:-25.4909 val_s_loss:-78.4513 val_d_loss:-21.3589\n",
      "epoch [243/50000] s_loss:-73.9882 d_loss:-19.6708 val_s_loss:-59.4783 val_d_loss:-20.8874\n",
      "epoch [244/50000] s_loss:-67.4959 d_loss:-21.6302 val_s_loss:-66.1223 val_d_loss:-11.2236\n",
      "epoch [245/50000] s_loss:8.7477 d_loss:-19.0414 val_s_loss:5.2049 val_d_loss:-13.0364\n",
      "epoch [246/50000] s_loss:24.3935 d_loss:-14.8017 val_s_loss:17.8510 val_d_loss:-8.0872\n",
      "epoch [247/50000] s_loss:15.2032 d_loss:-23.3972 val_s_loss:5.5714 val_d_loss:-12.4299\n",
      "epoch [248/50000] s_loss:12.0294 d_loss:-24.0604 val_s_loss:8.8314 val_d_loss:-20.8243\n",
      "epoch [249/50000] s_loss:-23.7809 d_loss:-23.4447 val_s_loss:-35.7956 val_d_loss:-10.3589\n",
      "epoch [250/50000] s_loss:-35.9977 d_loss:-23.2734 val_s_loss:-48.6327 val_d_loss:-15.6333\n",
      "epoch [251/50000] s_loss:-42.0536 d_loss:-22.9554 val_s_loss:-51.8849 val_d_loss:-20.0016\n",
      "epoch [252/50000] s_loss:-5.1173 d_loss:-21.9852 val_s_loss:-16.3725 val_d_loss:-11.2438\n",
      "epoch [253/50000] s_loss:21.1660 d_loss:-23.6699 val_s_loss:39.0359 val_d_loss:-31.4759\n",
      "epoch [254/50000] s_loss:49.7744 d_loss:-22.0801 val_s_loss:40.2295 val_d_loss:-5.9308\n",
      "epoch [255/50000] s_loss:40.3794 d_loss:-22.2933 val_s_loss:54.1222 val_d_loss:-23.6011\n",
      "epoch [256/50000] s_loss:39.4306 d_loss:-19.3055 val_s_loss:45.6254 val_d_loss:-21.0368\n",
      "epoch [257/50000] s_loss:54.5293 d_loss:-18.2230 val_s_loss:37.1061 val_d_loss:0.5680\n",
      "epoch [258/50000] s_loss:110.8481 d_loss:-12.0508 val_s_loss:111.2862 val_d_loss:-15.3172\n",
      "epoch [259/50000] s_loss:40.9303 d_loss:-20.0372 val_s_loss:35.9442 val_d_loss:-17.1242\n",
      "epoch [260/50000] s_loss:-3.1493 d_loss:-24.1812 val_s_loss:1.8270 val_d_loss:-17.2327\n",
      "epoch [261/50000] s_loss:-31.4609 d_loss:-25.2777 val_s_loss:-31.0883 val_d_loss:-15.4628\n",
      "epoch [262/50000] s_loss:49.4446 d_loss:-45.7132 val_s_loss:37.8907 val_d_loss:-10.7212\n",
      "epoch [263/50000] s_loss:67.0584 d_loss:-18.5973 val_s_loss:60.8009 val_d_loss:-9.3627\n",
      "epoch [264/50000] s_loss:44.2180 d_loss:-20.6577 val_s_loss:49.7693 val_d_loss:-22.2738\n",
      "epoch [265/50000] s_loss:43.8436 d_loss:-22.0816 val_s_loss:24.5086 val_d_loss:-8.0518\n",
      "epoch [266/50000] s_loss:102.5831 d_loss:-18.8274 val_s_loss:104.6093 val_d_loss:-17.5205\n",
      "epoch [267/50000] s_loss:96.9391 d_loss:-19.0521 val_s_loss:90.5916 val_d_loss:-17.2398\n",
      "epoch [268/50000] s_loss:67.6115 d_loss:-20.8553 val_s_loss:54.6717 val_d_loss:-4.1293\n",
      "epoch [269/50000] s_loss:93.8330 d_loss:-12.7107 val_s_loss:89.0169 val_d_loss:-6.6315\n",
      "epoch [270/50000] s_loss:80.6193 d_loss:-15.3481 val_s_loss:76.6125 val_d_loss:-4.2888\n",
      "epoch [271/50000] s_loss:-14.7096 d_loss:-13.6102 val_s_loss:-6.2716 val_d_loss:3.6549\n",
      "epoch [272/50000] s_loss:468.1899 d_loss:-110.9745 val_s_loss:452.8492 val_d_loss:88.0656\n",
      "epoch [273/50000] s_loss:37.7515 d_loss:-1.8362 val_s_loss:39.1260 val_d_loss:-4.5702\n",
      "epoch [274/50000] s_loss:38.9644 d_loss:-2.4908 val_s_loss:36.9970 val_d_loss:-1.6179\n",
      "epoch [275/50000] s_loss:40.4561 d_loss:-3.4348 val_s_loss:38.2675 val_d_loss:-2.9976\n",
      "epoch [276/50000] s_loss:42.0370 d_loss:-3.6539 val_s_loss:42.8464 val_d_loss:-4.1354\n",
      "epoch [277/50000] s_loss:47.3626 d_loss:-4.1507 val_s_loss:49.0221 val_d_loss:-6.7033\n",
      "epoch [278/50000] s_loss:56.0944 d_loss:-5.1186 val_s_loss:51.5097 val_d_loss:-4.3890\n",
      "epoch [279/50000] s_loss:64.8586 d_loss:-5.4015 val_s_loss:68.2662 val_d_loss:-7.8049\n",
      "epoch [280/50000] s_loss:79.5964 d_loss:-6.6353 val_s_loss:72.7872 val_d_loss:-0.5082\n",
      "epoch [281/50000] s_loss:103.0267 d_loss:-8.0873 val_s_loss:95.6004 val_d_loss:-1.0636\n",
      "epoch [282/50000] s_loss:126.0958 d_loss:-10.1867 val_s_loss:133.0102 val_d_loss:-21.9528\n",
      "epoch [283/50000] s_loss:128.9753 d_loss:-10.5885 val_s_loss:117.8447 val_d_loss:0.6477\n",
      "epoch [284/50000] s_loss:95.2083 d_loss:-11.3271 val_s_loss:95.1795 val_d_loss:-13.2278\n",
      "epoch [285/50000] s_loss:63.1621 d_loss:-14.9185 val_s_loss:46.4091 val_d_loss:0.7163\n",
      "epoch [286/50000] s_loss:33.1323 d_loss:-13.8633 val_s_loss:36.1178 val_d_loss:-17.1434\n",
      "epoch [287/50000] s_loss:6.1380 d_loss:-13.9481 val_s_loss:-10.0220 val_d_loss:-1.7044\n",
      "epoch [288/50000] s_loss:-24.6394 d_loss:-13.3399 val_s_loss:-42.0836 val_d_loss:1.5242\n",
      "epoch [289/50000] s_loss:-71.1316 d_loss:-11.5658 val_s_loss:-41.7892 val_d_loss:-28.6109\n",
      "epoch [290/50000] s_loss:-92.8295 d_loss:-13.1337 val_s_loss:-65.5382 val_d_loss:-27.0920\n",
      "epoch [291/50000] s_loss:-104.2949 d_loss:-12.3717 val_s_loss:-110.9675 val_d_loss:2.2894\n",
      "epoch [292/50000] s_loss:-78.0263 d_loss:-14.1331 val_s_loss:-78.1897 val_d_loss:3.0027\n",
      "epoch [293/50000] s_loss:-16.1400 d_loss:-5.3733 val_s_loss:-21.3474 val_d_loss:-0.2110\n",
      "epoch [294/50000] s_loss:40.1286 d_loss:-20.2514 val_s_loss:32.7616 val_d_loss:13.1620\n",
      "epoch [295/50000] s_loss:76.9062 d_loss:-4.8944 val_s_loss:68.2255 val_d_loss:-1.5795\n",
      "epoch [296/50000] s_loss:77.6226 d_loss:-8.1457 val_s_loss:66.5954 val_d_loss:-0.1272\n",
      "epoch [297/50000] s_loss:59.2556 d_loss:-11.9687 val_s_loss:46.5080 val_d_loss:0.0094\n",
      "epoch [298/50000] s_loss:28.5464 d_loss:-12.2692 val_s_loss:14.4032 val_d_loss:2.5897\n",
      "epoch [299/50000] s_loss:-25.3972 d_loss:-16.6298 val_s_loss:-35.7016 val_d_loss:-1.5391\n",
      "epoch [300/50000] s_loss:-64.8234 d_loss:-16.2450 val_s_loss:-70.5696 val_d_loss:-7.9525\n",
      "epoch [301/50000] s_loss:-60.1659 d_loss:-16.2866 val_s_loss:-68.1600 val_d_loss:-6.4157\n",
      "epoch [302/50000] s_loss:-52.1693 d_loss:-16.3070 val_s_loss:-59.3279 val_d_loss:-0.1606\n",
      "epoch [303/50000] s_loss:85.0992 d_loss:-6.7907 val_s_loss:62.4649 val_d_loss:-0.2429\n",
      "epoch [304/50000] s_loss:63.7483 d_loss:-7.6117 val_s_loss:68.2042 val_d_loss:-12.1750\n",
      "epoch [305/50000] s_loss:21.8382 d_loss:-15.2040 val_s_loss:17.0736 val_d_loss:-8.5733\n",
      "epoch [306/50000] s_loss:-24.7626 d_loss:-13.3409 val_s_loss:-36.9229 val_d_loss:-2.2342\n",
      "epoch [307/50000] s_loss:-13.7841 d_loss:-14.1383 val_s_loss:-19.4878 val_d_loss:-9.1742\n",
      "epoch [308/50000] s_loss:-19.5082 d_loss:-14.1002 val_s_loss:-24.0456 val_d_loss:1.0467\n",
      "epoch [309/50000] s_loss:-15.1565 d_loss:-16.2484 val_s_loss:-19.9774 val_d_loss:4.4605\n",
      "epoch [310/50000] s_loss:-0.3621 d_loss:-13.7739 val_s_loss:-9.7468 val_d_loss:1.9663\n",
      "epoch [311/50000] s_loss:86.9070 d_loss:-6.5158 val_s_loss:96.6808 val_d_loss:-10.7446\n",
      "epoch [312/50000] s_loss:84.1978 d_loss:-7.5772 val_s_loss:73.1393 val_d_loss:-0.5260\n",
      "epoch [313/50000] s_loss:43.1224 d_loss:-14.2600 val_s_loss:36.8192 val_d_loss:-1.7399\n",
      "epoch [314/50000] s_loss:3.7934 d_loss:-17.9362 val_s_loss:-6.4515 val_d_loss:-1.5294\n",
      "epoch [315/50000] s_loss:140.3366 d_loss:-7.9554 val_s_loss:131.4481 val_d_loss:-4.3260\n",
      "epoch [316/50000] s_loss:198.0760 d_loss:-5.4349 val_s_loss:209.6507 val_d_loss:-9.0756\n",
      "epoch [317/50000] s_loss:146.7196 d_loss:-8.3942 val_s_loss:135.6315 val_d_loss:1.3022\n",
      "epoch [318/50000] s_loss:99.7803 d_loss:-14.0566 val_s_loss:88.5684 val_d_loss:-4.8727\n",
      "epoch [319/50000] s_loss:63.2566 d_loss:-14.8814 val_s_loss:55.1991 val_d_loss:-12.3541\n",
      "epoch [320/50000] s_loss:14.9419 d_loss:-16.3800 val_s_loss:9.7878 val_d_loss:0.0277\n",
      "epoch [321/50000] s_loss:2.7010 d_loss:-17.6816 val_s_loss:10.9513 val_d_loss:-16.5762\n",
      "epoch [322/50000] s_loss:3.3007 d_loss:-13.6391 val_s_loss:10.2956 val_d_loss:-2.5851\n",
      "epoch [323/50000] s_loss:121.7928 d_loss:-96.6992 val_s_loss:107.8990 val_d_loss:19.4970\n",
      "epoch [324/50000] s_loss:116.9309 d_loss:-15.8452 val_s_loss:101.5292 val_d_loss:-1.9650\n",
      "epoch [325/50000] s_loss:63.5073 d_loss:-15.8476 val_s_loss:47.7317 val_d_loss:-0.5558\n",
      "epoch [326/50000] s_loss:33.2619 d_loss:-23.6233 val_s_loss:20.9256 val_d_loss:-5.0032\n",
      "epoch [327/50000] s_loss:31.4838 d_loss:-25.4288 val_s_loss:38.8311 val_d_loss:-13.4909\n",
      "epoch [328/50000] s_loss:13.8723 d_loss:-21.4099 val_s_loss:10.3580 val_d_loss:-12.4657\n",
      "epoch [329/50000] s_loss:-2.0666 d_loss:-21.9899 val_s_loss:12.4606 val_d_loss:-19.8746\n",
      "epoch [330/50000] s_loss:-17.3201 d_loss:-20.1897 val_s_loss:-29.5408 val_d_loss:-4.6373\n",
      "epoch [331/50000] s_loss:-1.4615 d_loss:-23.2691 val_s_loss:-19.2565 val_d_loss:-3.0724\n",
      "epoch [332/50000] s_loss:4.9672 d_loss:-13.3633 val_s_loss:-6.0575 val_d_loss:-5.3063\n",
      "epoch [333/50000] s_loss:56.4373 d_loss:-11.3975 val_s_loss:47.7141 val_d_loss:3.0717\n",
      "epoch [334/50000] s_loss:18.4088 d_loss:-13.1585 val_s_loss:25.1863 val_d_loss:-19.3287\n",
      "epoch [335/50000] s_loss:-30.3497 d_loss:-19.0143 val_s_loss:-35.9150 val_d_loss:-9.7367\n",
      "epoch [336/50000] s_loss:-63.0899 d_loss:-26.0773 val_s_loss:-77.7723 val_d_loss:-7.9872\n",
      "epoch [337/50000] s_loss:-73.3464 d_loss:-23.3677 val_s_loss:-87.5639 val_d_loss:-3.3123\n",
      "epoch [338/50000] s_loss:-73.1041 d_loss:-24.9685 val_s_loss:-80.4853 val_d_loss:-5.4377\n",
      "epoch [339/50000] s_loss:-21.6554 d_loss:-17.5748 val_s_loss:-20.1571 val_d_loss:12.3706\n",
      "epoch [340/50000] s_loss:527.6524 d_loss:-100.2927 val_s_loss:534.7777 val_d_loss:14.1200\n",
      "epoch [341/50000] s_loss:84.5123 d_loss:0.1042 val_s_loss:82.9832 val_d_loss:-0.6933\n",
      "epoch [342/50000] s_loss:44.4315 d_loss:-4.5624 val_s_loss:41.7226 val_d_loss:-3.3472\n",
      "epoch [343/50000] s_loss:22.3408 d_loss:-7.2411 val_s_loss:18.5922 val_d_loss:-5.8391\n",
      "epoch [344/50000] s_loss:-0.3323 d_loss:-10.4678 val_s_loss:2.3882 val_d_loss:-10.8824\n",
      "epoch [345/50000] s_loss:-2.8259 d_loss:-13.1946 val_s_loss:6.3851 val_d_loss:-21.7037\n",
      "epoch [346/50000] s_loss:14.3626 d_loss:-17.6912 val_s_loss:21.0102 val_d_loss:-20.9810\n",
      "epoch [347/50000] s_loss:11.0328 d_loss:-17.5221 val_s_loss:3.5699 val_d_loss:-6.8789\n",
      "epoch [348/50000] s_loss:-30.4843 d_loss:-20.0487 val_s_loss:-37.5443 val_d_loss:-8.7844\n",
      "epoch [349/50000] s_loss:-47.2094 d_loss:-20.7611 val_s_loss:-51.5181 val_d_loss:-13.1425\n",
      "epoch [350/50000] s_loss:-56.4843 d_loss:-19.0641 val_s_loss:-63.0753 val_d_loss:-10.2933\n",
      "epoch [351/50000] s_loss:-64.6818 d_loss:-21.1168 val_s_loss:-67.4926 val_d_loss:-11.7655\n",
      "epoch [352/50000] s_loss:-61.6843 d_loss:-20.5504 val_s_loss:-67.9855 val_d_loss:-12.8090\n",
      "epoch [353/50000] s_loss:-63.8909 d_loss:-20.5548 val_s_loss:-73.1839 val_d_loss:-7.2396\n",
      "epoch [354/50000] s_loss:-59.9403 d_loss:-20.1720 val_s_loss:-49.7368 val_d_loss:-16.0546\n",
      "epoch [355/50000] s_loss:-47.8399 d_loss:-23.2079 val_s_loss:-56.3502 val_d_loss:-11.6191\n",
      "epoch [356/50000] s_loss:-29.8056 d_loss:-18.4736 val_s_loss:-32.9982 val_d_loss:-4.5292\n",
      "epoch [357/50000] s_loss:219.3483 d_loss:-60.4377 val_s_loss:209.1370 val_d_loss:17.5104\n",
      "epoch [358/50000] s_loss:54.1180 d_loss:-14.2253 val_s_loss:47.6894 val_d_loss:-7.6600\n",
      "epoch [359/50000] s_loss:-31.2567 d_loss:-15.0610 val_s_loss:-33.9040 val_d_loss:-10.7916\n",
      "epoch [360/50000] s_loss:-27.1161 d_loss:-16.6351 val_s_loss:-33.1828 val_d_loss:-13.7931\n",
      "epoch [361/50000] s_loss:19.4319 d_loss:-17.0441 val_s_loss:17.3776 val_d_loss:-11.3805\n",
      "epoch [362/50000] s_loss:39.6182 d_loss:-16.7501 val_s_loss:32.6023 val_d_loss:-10.8855\n",
      "epoch [363/50000] s_loss:62.8334 d_loss:-18.5437 val_s_loss:53.6164 val_d_loss:-11.1304\n",
      "epoch [364/50000] s_loss:28.0016 d_loss:-16.4677 val_s_loss:31.3593 val_d_loss:-14.9113\n",
      "epoch [365/50000] s_loss:55.6345 d_loss:-16.1561 val_s_loss:49.6019 val_d_loss:-6.1884\n",
      "epoch [366/50000] s_loss:225.9496 d_loss:-15.1466 val_s_loss:226.1499 val_d_loss:15.9384\n",
      "epoch [367/50000] s_loss:35.2753 d_loss:-11.9218 val_s_loss:30.3163 val_d_loss:-10.7869\n",
      "epoch [368/50000] s_loss:-10.4293 d_loss:-16.8207 val_s_loss:-9.7619 val_d_loss:-17.2793\n",
      "epoch [369/50000] s_loss:-61.8450 d_loss:-18.6268 val_s_loss:-57.5604 val_d_loss:-21.4451\n",
      "epoch [370/50000] s_loss:-37.5246 d_loss:-19.0356 val_s_loss:-44.7069 val_d_loss:-8.8160\n",
      "epoch [371/50000] s_loss:-43.7458 d_loss:-23.3319 val_s_loss:-54.8829 val_d_loss:-15.1685\n",
      "epoch [372/50000] s_loss:-80.5312 d_loss:-20.9699 val_s_loss:-87.0684 val_d_loss:-15.7588\n",
      "epoch [373/50000] s_loss:-76.7248 d_loss:-19.4459 val_s_loss:-82.4041 val_d_loss:-17.9684\n",
      "epoch [374/50000] s_loss:-66.5404 d_loss:-23.2812 val_s_loss:-71.2703 val_d_loss:-11.5609\n",
      "epoch [375/50000] s_loss:-48.0900 d_loss:-19.5543 val_s_loss:-50.6942 val_d_loss:-6.3678\n",
      "epoch [376/50000] s_loss:-6.0802 d_loss:-16.1783 val_s_loss:-9.5479 val_d_loss:-13.0172\n",
      "epoch [377/50000] s_loss:93.7636 d_loss:-20.1976 val_s_loss:115.7587 val_d_loss:-29.7204\n",
      "epoch [378/50000] s_loss:11.4987 d_loss:-20.8107 val_s_loss:3.4879 val_d_loss:-13.3745\n",
      "epoch [379/50000] s_loss:-16.3621 d_loss:-19.5343 val_s_loss:-20.1903 val_d_loss:-11.7804\n",
      "epoch [380/50000] s_loss:-29.2938 d_loss:-23.6528 val_s_loss:-22.3594 val_d_loss:-23.5476\n",
      "epoch [381/50000] s_loss:-32.6654 d_loss:-25.4618 val_s_loss:-39.8009 val_d_loss:-12.3678\n",
      "epoch [382/50000] s_loss:-17.5679 d_loss:-20.5996 val_s_loss:-20.7621 val_d_loss:-8.2701\n",
      "epoch [383/50000] s_loss:23.3395 d_loss:-18.1233 val_s_loss:17.6479 val_d_loss:-5.6551\n",
      "epoch [384/50000] s_loss:169.1897 d_loss:-16.1537 val_s_loss:162.2711 val_d_loss:-6.7556\n",
      "epoch [385/50000] s_loss:123.1561 d_loss:-19.2060 val_s_loss:117.3802 val_d_loss:-5.5540\n",
      "epoch [386/50000] s_loss:34.7114 d_loss:-17.6396 val_s_loss:25.8654 val_d_loss:-14.2504\n",
      "epoch [387/50000] s_loss:38.3194 d_loss:-20.6681 val_s_loss:33.7619 val_d_loss:-10.4463\n",
      "epoch [388/50000] s_loss:24.8974 d_loss:-23.2301 val_s_loss:18.8554 val_d_loss:-7.6126\n",
      "epoch [389/50000] s_loss:7.2468 d_loss:-18.4298 val_s_loss:-1.3555 val_d_loss:-11.5384\n",
      "epoch [390/50000] s_loss:5.7848 d_loss:-15.4381 val_s_loss:4.0778 val_d_loss:-14.8859\n",
      "epoch [391/50000] s_loss:144.1876 d_loss:-15.5849 val_s_loss:145.9208 val_d_loss:-14.8683\n",
      "epoch [392/50000] s_loss:215.7922 d_loss:-12.9160 val_s_loss:212.9122 val_d_loss:-3.8125\n",
      "epoch [393/50000] s_loss:89.4533 d_loss:-14.4117 val_s_loss:81.4913 val_d_loss:-11.1564\n",
      "epoch [394/50000] s_loss:30.5355 d_loss:-19.9349 val_s_loss:32.1411 val_d_loss:-17.9405\n",
      "epoch [395/50000] s_loss:2.0625 d_loss:-21.9849 val_s_loss:-4.5814 val_d_loss:-8.9619\n",
      "epoch [396/50000] s_loss:-22.5035 d_loss:-22.3234 val_s_loss:-26.3806 val_d_loss:-11.5910\n",
      "epoch [397/50000] s_loss:-36.7805 d_loss:-21.6364 val_s_loss:-39.0563 val_d_loss:-3.9795\n",
      "epoch [398/50000] s_loss:-6.5002 d_loss:-15.1218 val_s_loss:14.1879 val_d_loss:-28.0058\n",
      "epoch [399/50000] s_loss:158.9680 d_loss:-17.7154 val_s_loss:155.5592 val_d_loss:-5.9861\n",
      "epoch [400/50000] s_loss:284.3009 d_loss:-102.6077 val_s_loss:280.9535 val_d_loss:0.1967\n",
      "epoch [401/50000] s_loss:71.8307 d_loss:-14.1949 val_s_loss:65.3297 val_d_loss:-6.0956\n",
      "epoch [402/50000] s_loss:38.5900 d_loss:-17.2829 val_s_loss:34.5586 val_d_loss:-8.9431\n",
      "epoch [403/50000] s_loss:2.6304 d_loss:-19.7634 val_s_loss:-3.6847 val_d_loss:-8.8184\n",
      "epoch [404/50000] s_loss:-11.2047 d_loss:-21.1195 val_s_loss:-16.2638 val_d_loss:-8.0235\n",
      "epoch [405/50000] s_loss:-18.7218 d_loss:-23.6653 val_s_loss:-22.9028 val_d_loss:-12.3391\n",
      "epoch [406/50000] s_loss:9.3152 d_loss:-22.2986 val_s_loss:15.1075 val_d_loss:-16.5255\n",
      "epoch [407/50000] s_loss:40.8360 d_loss:-20.2611 val_s_loss:35.5249 val_d_loss:-12.7869\n",
      "epoch [408/50000] s_loss:108.6387 d_loss:-20.7308 val_s_loss:97.7126 val_d_loss:-9.7492\n",
      "epoch [409/50000] s_loss:66.3516 d_loss:-18.0033 val_s_loss:61.4384 val_d_loss:-12.4797\n",
      "epoch [410/50000] s_loss:4.2130 d_loss:-17.8792 val_s_loss:0.7584 val_d_loss:-14.9708\n",
      "epoch [411/50000] s_loss:62.7553 d_loss:-16.1356 val_s_loss:57.9764 val_d_loss:-12.9894\n",
      "epoch [412/50000] s_loss:128.7126 d_loss:-13.1818 val_s_loss:133.9279 val_d_loss:-18.0407\n",
      "epoch [413/50000] s_loss:43.2535 d_loss:-12.0611 val_s_loss:50.1563 val_d_loss:-13.0611\n",
      "epoch [414/50000] s_loss:7.8422 d_loss:-13.6687 val_s_loss:7.7431 val_d_loss:-9.5592\n",
      "epoch [415/50000] s_loss:65.5457 d_loss:-14.9342 val_s_loss:59.9038 val_d_loss:-3.5384\n",
      "epoch [416/50000] s_loss:254.4351 d_loss:-6.0417 val_s_loss:226.1010 val_d_loss:-0.1213\n",
      "epoch [417/50000] s_loss:117.0671 d_loss:-12.2023 val_s_loss:107.2197 val_d_loss:-3.5431\n",
      "epoch [418/50000] s_loss:56.9368 d_loss:-13.9705 val_s_loss:53.9707 val_d_loss:-11.4017\n",
      "epoch [419/50000] s_loss:7.3516 d_loss:-16.6874 val_s_loss:2.6816 val_d_loss:-8.1388\n",
      "epoch [420/50000] s_loss:148.4865 d_loss:-14.7355 val_s_loss:145.6795 val_d_loss:-12.1204\n",
      "epoch [421/50000] s_loss:218.1486 d_loss:-17.6137 val_s_loss:214.9453 val_d_loss:-2.8578\n",
      "epoch [422/50000] s_loss:134.0730 d_loss:-8.5666 val_s_loss:127.3539 val_d_loss:-5.8014\n",
      "epoch [423/50000] s_loss:12.8672 d_loss:-13.1725 val_s_loss:7.3338 val_d_loss:-8.8815\n",
      "epoch [424/50000] s_loss:-38.3505 d_loss:-12.6884 val_s_loss:-30.7654 val_d_loss:3.2852\n",
      "epoch [425/50000] s_loss:59.7727 d_loss:-13.3730 val_s_loss:53.0167 val_d_loss:-0.7200\n",
      "epoch [426/50000] s_loss:321.3162 d_loss:-35.7732 val_s_loss:296.4088 val_d_loss:4.9650\n",
      "epoch [427/50000] s_loss:74.3924 d_loss:-12.4471 val_s_loss:66.4664 val_d_loss:-0.1317\n",
      "epoch [428/50000] s_loss:39.9700 d_loss:-24.2326 val_s_loss:32.1705 val_d_loss:-8.7213\n",
      "epoch [429/50000] s_loss:-2.6515 d_loss:-22.0643 val_s_loss:-8.7147 val_d_loss:-11.4878\n",
      "epoch [430/50000] s_loss:-19.7435 d_loss:-25.1883 val_s_loss:-30.5545 val_d_loss:-10.5927\n",
      "epoch [431/50000] s_loss:-41.9903 d_loss:-27.8194 val_s_loss:-49.3696 val_d_loss:-12.3025\n",
      "epoch [432/50000] s_loss:-67.9086 d_loss:-24.2426 val_s_loss:-71.3007 val_d_loss:-19.7801\n",
      "epoch [433/50000] s_loss:-83.7455 d_loss:-26.9558 val_s_loss:-83.4163 val_d_loss:-16.2978\n",
      "epoch [434/50000] s_loss:-68.9202 d_loss:-22.9804 val_s_loss:-80.6136 val_d_loss:-17.7717\n",
      "epoch [435/50000] s_loss:-67.7067 d_loss:-21.9123 val_s_loss:-62.8858 val_d_loss:-12.1213\n",
      "epoch [436/50000] s_loss:-65.3040 d_loss:-23.5167 val_s_loss:-55.1545 val_d_loss:-11.9062\n",
      "epoch [437/50000] s_loss:-8.9706 d_loss:-33.4320 val_s_loss:-13.9004 val_d_loss:-13.1489\n",
      "epoch [438/50000] s_loss:34.2234 d_loss:-14.9361 val_s_loss:31.7113 val_d_loss:-6.4250\n",
      "epoch [439/50000] s_loss:23.0294 d_loss:-19.6121 val_s_loss:18.8113 val_d_loss:-5.4514\n",
      "epoch [440/50000] s_loss:-32.0904 d_loss:-19.9440 val_s_loss:-42.5998 val_d_loss:-0.8770\n",
      "epoch [441/50000] s_loss:109.3274 d_loss:-11.6388 val_s_loss:144.5856 val_d_loss:-53.6081\n",
      "epoch [442/50000] s_loss:135.2209 d_loss:-16.7263 val_s_loss:249.2825 val_d_loss:-102.5658\n",
      "epoch [443/50000] s_loss:24.4138 d_loss:-15.3818 val_s_loss:20.6549 val_d_loss:-7.5284\n",
      "epoch [444/50000] s_loss:-6.4033 d_loss:-18.6206 val_s_loss:-15.4927 val_d_loss:-5.2704\n",
      "epoch [445/50000] s_loss:-20.5402 d_loss:-15.6280 val_s_loss:-25.7865 val_d_loss:-1.8223\n",
      "epoch [446/50000] s_loss:12.6393 d_loss:-16.2717 val_s_loss:9.8005 val_d_loss:-9.8638\n",
      "epoch [447/50000] s_loss:190.4599 d_loss:-13.1780 val_s_loss:187.9512 val_d_loss:-16.3244\n",
      "epoch [448/50000] s_loss:168.6282 d_loss:-12.4210 val_s_loss:165.6043 val_d_loss:-8.1774\n",
      "epoch [449/50000] s_loss:63.0628 d_loss:-14.7110 val_s_loss:71.7840 val_d_loss:-20.8609\n",
      "epoch [450/50000] s_loss:-1.0485 d_loss:-17.1442 val_s_loss:-3.8844 val_d_loss:-7.6536\n",
      "epoch [451/50000] s_loss:-14.9100 d_loss:-19.6916 val_s_loss:-20.5730 val_d_loss:-10.9572\n",
      "epoch [452/50000] s_loss:6.3851 d_loss:-15.0509 val_s_loss:3.1891 val_d_loss:-5.0407\n",
      "epoch [453/50000] s_loss:196.7302 d_loss:-7.4028 val_s_loss:200.7385 val_d_loss:-2.1057\n",
      "epoch [454/50000] s_loss:166.1242 d_loss:-4.8159 val_s_loss:157.8880 val_d_loss:-3.0542\n",
      "epoch [455/50000] s_loss:83.9227 d_loss:-12.0545 val_s_loss:77.4488 val_d_loss:-5.6891\n",
      "epoch [456/50000] s_loss:29.5691 d_loss:-16.5413 val_s_loss:26.2648 val_d_loss:-16.3975\n",
      "epoch [457/50000] s_loss:-28.0229 d_loss:-17.6839 val_s_loss:-27.0737 val_d_loss:-11.5267\n",
      "epoch [458/50000] s_loss:-17.8495 d_loss:-13.1600 val_s_loss:-25.2324 val_d_loss:-4.4426\n",
      "epoch [459/50000] s_loss:6.0332 d_loss:-13.5602 val_s_loss:-2.5575 val_d_loss:-4.1601\n",
      "epoch [460/50000] s_loss:50.4708 d_loss:-13.0143 val_s_loss:46.3582 val_d_loss:-1.7477\n",
      "epoch [461/50000] s_loss:37.3138 d_loss:-12.3722 val_s_loss:30.0672 val_d_loss:4.2328\n",
      "epoch [462/50000] s_loss:17.3174 d_loss:-14.0266 val_s_loss:16.7491 val_d_loss:-6.1845\n",
      "epoch [463/50000] s_loss:13.3124 d_loss:-10.9715 val_s_loss:7.8811 val_d_loss:-4.3462\n",
      "epoch [464/50000] s_loss:121.0304 d_loss:-11.7251 val_s_loss:131.8225 val_d_loss:-22.2336\n",
      "epoch [465/50000] s_loss:71.1359 d_loss:-9.6230 val_s_loss:69.8041 val_d_loss:-3.2031\n",
      "epoch [466/50000] s_loss:49.2327 d_loss:-9.3002 val_s_loss:50.2577 val_d_loss:-11.3374\n",
      "epoch [467/50000] s_loss:27.5970 d_loss:-11.9659 val_s_loss:21.1369 val_d_loss:-3.8079\n",
      "epoch [468/50000] s_loss:-10.9467 d_loss:-5.8302 val_s_loss:-7.3563 val_d_loss:-17.6014\n",
      "epoch [469/50000] s_loss:-34.5266 d_loss:-11.4255 val_s_loss:-39.6009 val_d_loss:5.2626\n",
      "epoch [470/50000] s_loss:-11.1173 d_loss:-16.3061 val_s_loss:-15.2638 val_d_loss:-7.2708\n",
      "epoch [471/50000] s_loss:17.1515 d_loss:-10.7449 val_s_loss:8.5243 val_d_loss:-2.4487\n",
      "epoch [472/50000] s_loss:13.1775 d_loss:-9.7885 val_s_loss:8.8962 val_d_loss:-6.2005\n",
      "epoch [473/50000] s_loss:6.3938 d_loss:-9.5703 val_s_loss:4.1718 val_d_loss:2.2650\n",
      "epoch [474/50000] s_loss:-22.9158 d_loss:-9.1750 val_s_loss:-27.9653 val_d_loss:2.1207\n",
      "epoch [475/50000] s_loss:33.1273 d_loss:-9.1254 val_s_loss:34.8174 val_d_loss:-10.8952\n",
      "epoch [476/50000] s_loss:78.6343 d_loss:-29.4620 val_s_loss:106.9252 val_d_loss:-27.6452\n",
      "epoch [477/50000] s_loss:28.1154 d_loss:-8.9364 val_s_loss:35.8138 val_d_loss:-15.7631\n",
      "epoch [478/50000] s_loss:21.2383 d_loss:-15.8557 val_s_loss:20.6530 val_d_loss:-11.4372\n",
      "epoch [479/50000] s_loss:-21.1674 d_loss:-16.5931 val_s_loss:-27.0470 val_d_loss:-7.5491\n",
      "epoch [480/50000] s_loss:-52.8511 d_loss:-14.6895 val_s_loss:-42.1271 val_d_loss:-9.1818\n",
      "epoch [481/50000] s_loss:22.9615 d_loss:-10.8809 val_s_loss:19.6401 val_d_loss:-11.2439\n",
      "epoch [482/50000] s_loss:145.4784 d_loss:-13.0526 val_s_loss:139.7861 val_d_loss:-3.0505\n",
      "epoch [483/50000] s_loss:67.8610 d_loss:-7.2779 val_s_loss:60.1167 val_d_loss:-1.3595\n",
      "epoch [484/50000] s_loss:19.4843 d_loss:-14.9758 val_s_loss:14.9304 val_d_loss:-4.9558\n",
      "epoch [485/50000] s_loss:-19.6918 d_loss:-13.1802 val_s_loss:-22.5182 val_d_loss:-2.5762\n",
      "epoch [486/50000] s_loss:-52.4783 d_loss:-12.6661 val_s_loss:-61.7131 val_d_loss:5.5068\n",
      "epoch [487/50000] s_loss:-61.0911 d_loss:-9.9774 val_s_loss:-66.1796 val_d_loss:-10.7513\n",
      "epoch [488/50000] s_loss:-26.6985 d_loss:-14.7000 val_s_loss:-33.3142 val_d_loss:-2.2436\n",
      "epoch [489/50000] s_loss:13.3757 d_loss:-11.8741 val_s_loss:10.1077 val_d_loss:-2.2919\n",
      "epoch [490/50000] s_loss:28.9712 d_loss:-11.2018 val_s_loss:18.7519 val_d_loss:-3.2548\n",
      "epoch [491/50000] s_loss:30.5519 d_loss:-5.1217 val_s_loss:22.1824 val_d_loss:2.2423\n",
      "epoch [492/50000] s_loss:33.3946 d_loss:-9.1011 val_s_loss:41.1752 val_d_loss:-12.1637\n",
      "epoch [493/50000] s_loss:64.7631 d_loss:-8.8717 val_s_loss:60.9575 val_d_loss:-9.6512\n",
      "epoch [494/50000] s_loss:74.9637 d_loss:-11.8655 val_s_loss:69.2379 val_d_loss:-6.2809\n",
      "epoch [495/50000] s_loss:49.0821 d_loss:-9.1966 val_s_loss:53.1312 val_d_loss:-11.3990\n",
      "epoch [496/50000] s_loss:-18.5794 d_loss:-12.4732 val_s_loss:-15.9342 val_d_loss:-9.0101\n",
      "epoch [497/50000] s_loss:-54.4945 d_loss:-9.8814 val_s_loss:-56.6314 val_d_loss:-8.8042\n",
      "epoch [498/50000] s_loss:30.1841 d_loss:-14.7345 val_s_loss:47.0464 val_d_loss:-16.3410\n",
      "epoch [499/50000] s_loss:71.6231 d_loss:-10.4342 val_s_loss:66.7534 val_d_loss:-3.3329\n",
      "epoch [500/50000] s_loss:26.0938 d_loss:-13.4091 val_s_loss:22.0557 val_d_loss:-5.5958\n",
      "epoch [501/50000] s_loss:-11.1417 d_loss:-17.9057 val_s_loss:-2.9671 val_d_loss:-9.5210\n",
      "epoch [502/50000] s_loss:-3.2517 d_loss:-9.1505 val_s_loss:-7.6879 val_d_loss:-4.4219\n",
      "epoch [503/50000] s_loss:32.9270 d_loss:-11.4542 val_s_loss:31.1819 val_d_loss:-5.1723\n",
      "epoch [504/50000] s_loss:14.7807 d_loss:-11.9411 val_s_loss:8.0044 val_d_loss:-0.5929\n",
      "epoch [505/50000] s_loss:1.4677 d_loss:-11.9078 val_s_loss:20.1563 val_d_loss:-22.9244\n",
      "epoch [506/50000] s_loss:-28.4009 d_loss:-7.9736 val_s_loss:-29.5787 val_d_loss:-0.5600\n",
      "epoch [507/50000] s_loss:9.9573 d_loss:-7.8932 val_s_loss:5.7681 val_d_loss:-6.7344\n",
      "epoch [508/50000] s_loss:31.4154 d_loss:-9.5357 val_s_loss:27.8920 val_d_loss:-6.7733\n",
      "epoch [509/50000] s_loss:56.9639 d_loss:-8.7949 val_s_loss:51.9248 val_d_loss:-6.1505\n",
      "epoch [510/50000] s_loss:27.3905 d_loss:-14.5232 val_s_loss:20.4790 val_d_loss:-7.9394\n",
      "epoch [511/50000] s_loss:-36.7565 d_loss:-10.6917 val_s_loss:-24.6013 val_d_loss:-9.0646\n",
      "epoch [512/50000] s_loss:-50.5342 d_loss:-7.9597 val_s_loss:-55.6124 val_d_loss:-1.7045\n",
      "epoch [513/50000] s_loss:-17.6102 d_loss:-9.5097 val_s_loss:-12.2598 val_d_loss:-15.4457\n",
      "epoch [514/50000] s_loss:42.4194 d_loss:-6.2392 val_s_loss:44.7388 val_d_loss:-6.2880\n",
      "epoch [515/50000] s_loss:61.3050 d_loss:-10.4639 val_s_loss:57.2548 val_d_loss:-1.9841\n",
      "epoch [516/50000] s_loss:-0.4582 d_loss:-9.9132 val_s_loss:-3.0513 val_d_loss:-3.7659\n",
      "epoch [517/50000] s_loss:-24.6162 d_loss:-11.0821 val_s_loss:-25.0182 val_d_loss:-1.0741\n",
      "epoch [518/50000] s_loss:-4.5664 d_loss:-8.6921 val_s_loss:-20.2674 val_d_loss:-3.7279\n",
      "epoch [519/50000] s_loss:13.1998 d_loss:-11.1305 val_s_loss:12.3139 val_d_loss:-3.4435\n",
      "epoch [520/50000] s_loss:30.3424 d_loss:-8.0112 val_s_loss:17.4238 val_d_loss:3.2945\n",
      "epoch [521/50000] s_loss:-11.6797 d_loss:-11.4226 val_s_loss:-17.4954 val_d_loss:-3.3883\n",
      "epoch [522/50000] s_loss:-37.2975 d_loss:-9.2647 val_s_loss:-36.5900 val_d_loss:-4.0346\n",
      "epoch [523/50000] s_loss:-7.5600 d_loss:-12.2300 val_s_loss:-4.0922 val_d_loss:-11.2689\n",
      "epoch [524/50000] s_loss:42.7094 d_loss:-9.6798 val_s_loss:38.0540 val_d_loss:-1.7237\n",
      "epoch [525/50000] s_loss:77.3321 d_loss:-9.8463 val_s_loss:67.0712 val_d_loss:-3.5232\n",
      "epoch [526/50000] s_loss:-0.6504 d_loss:-14.5972 val_s_loss:3.1978 val_d_loss:-13.5347\n",
      "epoch [527/50000] s_loss:-28.9231 d_loss:-13.1784 val_s_loss:-31.1688 val_d_loss:-4.0221\n",
      "epoch [528/50000] s_loss:17.5388 d_loss:-9.6204 val_s_loss:33.2699 val_d_loss:-17.5510\n",
      "epoch [529/50000] s_loss:-5.8644 d_loss:-8.4498 val_s_loss:0.9298 val_d_loss:-14.6705\n",
      "epoch [530/50000] s_loss:14.4494 d_loss:-8.8173 val_s_loss:13.6276 val_d_loss:-1.1102\n",
      "epoch [531/50000] s_loss:-13.5057 d_loss:-5.1485 val_s_loss:-17.3525 val_d_loss:-0.4962\n",
      "epoch [532/50000] s_loss:35.5632 d_loss:-5.7613 val_s_loss:33.3826 val_d_loss:-10.3025\n",
      "epoch [533/50000] s_loss:39.4690 d_loss:-6.5870 val_s_loss:47.4312 val_d_loss:-9.7167\n",
      "epoch [534/50000] s_loss:47.1680 d_loss:-12.9768 val_s_loss:41.7930 val_d_loss:-1.4866\n",
      "epoch [535/50000] s_loss:-4.5335 d_loss:-10.9249 val_s_loss:-4.1050 val_d_loss:-2.5828\n",
      "epoch [536/50000] s_loss:-17.3239 d_loss:-6.4926 val_s_loss:-22.4877 val_d_loss:-3.1055\n",
      "epoch [537/50000] s_loss:-1.0332 d_loss:-15.7394 val_s_loss:-1.5748 val_d_loss:-5.4083\n",
      "epoch [538/50000] s_loss:18.5580 d_loss:-6.7710 val_s_loss:25.2617 val_d_loss:-11.5986\n",
      "epoch [539/50000] s_loss:18.3854 d_loss:-2.8408 val_s_loss:36.1355 val_d_loss:-22.4192\n",
      "epoch [540/50000] s_loss:24.4616 d_loss:-5.6143 val_s_loss:61.4784 val_d_loss:-39.4603\n",
      "epoch [541/50000] s_loss:56.8458 d_loss:-18.6089 val_s_loss:56.6286 val_d_loss:-10.5750\n",
      "epoch [542/50000] s_loss:4.7574 d_loss:-25.1509 val_s_loss:-4.2249 val_d_loss:-11.6555\n",
      "epoch [543/50000] s_loss:-27.7533 d_loss:-17.9415 val_s_loss:-33.2063 val_d_loss:-2.9562\n",
      "epoch [544/50000] s_loss:59.5720 d_loss:-11.7965 val_s_loss:57.0782 val_d_loss:-11.5405\n",
      "epoch [545/50000] s_loss:-6.8846 d_loss:-4.5061 val_s_loss:-8.5771 val_d_loss:-1.4189\n",
      "epoch [546/50000] s_loss:-14.6953 d_loss:-4.9652 val_s_loss:-22.7466 val_d_loss:-2.1089\n",
      "epoch [547/50000] s_loss:-40.2404 d_loss:-10.2644 val_s_loss:-39.3071 val_d_loss:-7.6020\n",
      "epoch [548/50000] s_loss:-78.7487 d_loss:-12.5680 val_s_loss:-80.0572 val_d_loss:-5.9306\n",
      "epoch [549/50000] s_loss:-131.3338 d_loss:-16.3212 val_s_loss:-130.7356 val_d_loss:-7.5465\n",
      "epoch [550/50000] s_loss:-129.5727 d_loss:-14.3213 val_s_loss:-91.5342 val_d_loss:-24.1250\n",
      "epoch [551/50000] s_loss:198.5052 d_loss:-32.8212 val_s_loss:293.7867 val_d_loss:-97.1013\n",
      "epoch [552/50000] s_loss:76.3442 d_loss:-5.5398 val_s_loss:76.2474 val_d_loss:-2.7377\n",
      "epoch [553/50000] s_loss:81.5999 d_loss:-7.8545 val_s_loss:77.8233 val_d_loss:-2.0797\n",
      "epoch [554/50000] s_loss:35.2698 d_loss:-10.8676 val_s_loss:26.7340 val_d_loss:-2.2237\n",
      "epoch [555/50000] s_loss:-7.9008 d_loss:-16.4844 val_s_loss:-8.7057 val_d_loss:-3.2376\n",
      "epoch [556/50000] s_loss:83.7492 d_loss:-17.1152 val_s_loss:183.2918 val_d_loss:-102.8958\n",
      "epoch [557/50000] s_loss:155.2793 d_loss:-21.1091 val_s_loss:506.0668 val_d_loss:-345.1834\n",
      "epoch [558/50000] s_loss:120.8704 d_loss:-12.7668 val_s_loss:434.6968 val_d_loss:-306.9626\n",
      "epoch [559/50000] s_loss:74.9718 d_loss:-9.9899 val_s_loss:374.6660 val_d_loss:-293.5337\n",
      "epoch [560/50000] s_loss:-20.9118 d_loss:-15.0680 val_s_loss:305.9099 val_d_loss:-307.3624\n",
      "epoch [561/50000] s_loss:-146.1577 d_loss:-19.4219 val_s_loss:96.8592 val_d_loss:-240.8314\n",
      "epoch [562/50000] s_loss:-191.0155 d_loss:-19.1795 val_s_loss:103.8836 val_d_loss:-264.1878\n",
      "epoch [563/50000] s_loss:-121.9133 d_loss:-2.8583 val_s_loss:-47.8445 val_d_loss:-68.4887\n",
      "epoch [564/50000] s_loss:-56.6408 d_loss:-13.7411 val_s_loss:-63.5922 val_d_loss:-7.4196\n",
      "epoch [565/50000] s_loss:101.0570 d_loss:-22.7643 val_s_loss:102.5459 val_d_loss:-17.9562\n",
      "epoch [566/50000] s_loss:82.4044 d_loss:-18.0170 val_s_loss:107.4732 val_d_loss:-27.1282\n",
      "epoch [567/50000] s_loss:20.9469 d_loss:-11.9677 val_s_loss:10.1447 val_d_loss:5.5645\n",
      "epoch [568/50000] s_loss:-41.7530 d_loss:-8.6034 val_s_loss:-44.5802 val_d_loss:-1.8150\n",
      "epoch [569/50000] s_loss:-84.8189 d_loss:-8.6604 val_s_loss:-94.3486 val_d_loss:1.0649\n",
      "epoch [570/50000] s_loss:-149.5550 d_loss:-12.7422 val_s_loss:-119.9657 val_d_loss:-34.1202\n",
      "epoch [571/50000] s_loss:-138.7113 d_loss:-7.6864 val_s_loss:-139.5445 val_d_loss:-0.3043\n",
      "epoch [572/50000] s_loss:-45.1539 d_loss:-8.1488 val_s_loss:-31.6502 val_d_loss:-20.4843\n",
      "epoch [573/50000] s_loss:-23.8782 d_loss:-11.1854 val_s_loss:-31.8252 val_d_loss:-3.4984\n",
      "epoch [574/50000] s_loss:-142.1120 d_loss:-13.8767 val_s_loss:-134.1794 val_d_loss:5.2572\n",
      "epoch [575/50000] s_loss:-60.0215 d_loss:-4.7521 val_s_loss:-47.5826 val_d_loss:-15.4643\n",
      "epoch [576/50000] s_loss:40.5277 d_loss:-7.4582 val_s_loss:40.0120 val_d_loss:-7.6070\n",
      "epoch [577/50000] s_loss:52.8640 d_loss:-7.7268 val_s_loss:54.7712 val_d_loss:-5.4588\n",
      "epoch [578/50000] s_loss:29.6048 d_loss:-7.1316 val_s_loss:25.2779 val_d_loss:0.4981\n",
      "epoch [579/50000] s_loss:-3.7510 d_loss:-9.6861 val_s_loss:-6.9747 val_d_loss:-6.8934\n",
      "epoch [580/50000] s_loss:-39.7472 d_loss:-10.8010 val_s_loss:-37.8139 val_d_loss:-10.9692\n",
      "epoch [581/50000] s_loss:-103.1418 d_loss:-12.6989 val_s_loss:-106.4320 val_d_loss:-1.3565\n",
      "epoch [582/50000] s_loss:-162.7925 d_loss:-12.9285 val_s_loss:-169.1361 val_d_loss:-8.8662\n",
      "epoch [583/50000] s_loss:-188.1934 d_loss:-10.5949 val_s_loss:-195.6110 val_d_loss:3.4118\n",
      "epoch [584/50000] s_loss:-146.4507 d_loss:-9.3139 val_s_loss:-160.9109 val_d_loss:15.4313\n",
      "epoch [585/50000] s_loss:-91.6896 d_loss:-12.6321 val_s_loss:-87.3560 val_d_loss:-4.3403\n",
      "epoch [586/50000] s_loss:-38.1668 d_loss:-10.2536 val_s_loss:-29.7515 val_d_loss:-12.1133\n",
      "epoch [587/50000] s_loss:63.9924 d_loss:-14.2179 val_s_loss:61.5058 val_d_loss:-9.9448\n",
      "epoch [588/50000] s_loss:45.7507 d_loss:-14.4946 val_s_loss:61.0108 val_d_loss:-11.6338\n",
      "epoch [589/50000] s_loss:63.5611 d_loss:-6.6019 val_s_loss:60.0609 val_d_loss:-0.7904\n",
      "epoch [590/50000] s_loss:56.6563 d_loss:-7.1735 val_s_loss:57.1155 val_d_loss:-8.1939\n",
      "epoch [591/50000] s_loss:-32.3199 d_loss:-12.4621 val_s_loss:-36.8106 val_d_loss:-4.1559\n",
      "epoch [592/50000] s_loss:-104.3935 d_loss:-10.7170 val_s_loss:-105.3743 val_d_loss:-5.0763\n",
      "epoch [593/50000] s_loss:-132.3830 d_loss:-11.1344 val_s_loss:-136.6397 val_d_loss:-1.0316\n",
      "epoch [594/50000] s_loss:-59.4525 d_loss:-12.4932 val_s_loss:-56.9961 val_d_loss:-7.5572\n",
      "epoch [595/50000] s_loss:28.8703 d_loss:-11.4837 val_s_loss:23.7870 val_d_loss:-12.3219\n",
      "epoch [596/50000] s_loss:22.4201 d_loss:-10.6486 val_s_loss:22.5702 val_d_loss:-7.6176\n",
      "epoch [597/50000] s_loss:-106.5287 d_loss:-10.5210 val_s_loss:-99.5004 val_d_loss:-0.4952\n",
      "epoch [598/50000] s_loss:-84.0840 d_loss:-11.4149 val_s_loss:-79.9039 val_d_loss:-6.2399\n",
      "epoch [599/50000] s_loss:37.0025 d_loss:-8.3239 val_s_loss:38.2229 val_d_loss:-6.0075\n",
      "epoch [600/50000] s_loss:111.9038 d_loss:-8.9117 val_s_loss:110.9845 val_d_loss:-12.0350\n",
      "epoch [601/50000] s_loss:132.6364 d_loss:-7.7785 val_s_loss:134.6050 val_d_loss:-16.0010\n",
      "epoch [602/50000] s_loss:73.9681 d_loss:-7.2045 val_s_loss:72.8667 val_d_loss:-8.1662\n",
      "epoch [603/50000] s_loss:16.9672 d_loss:-7.8776 val_s_loss:18.7388 val_d_loss:-6.4441\n",
      "epoch [604/50000] s_loss:-25.3428 d_loss:-7.4944 val_s_loss:-21.4269 val_d_loss:-8.1681\n",
      "epoch [605/50000] s_loss:-26.5147 d_loss:-9.7969 val_s_loss:-25.7643 val_d_loss:-6.3803\n",
      "epoch [606/50000] s_loss:-22.6054 d_loss:-9.1215 val_s_loss:-20.9976 val_d_loss:-8.5337\n",
      "epoch [607/50000] s_loss:-8.9053 d_loss:-8.3976 val_s_loss:-8.3163 val_d_loss:-7.5727\n",
      "epoch [608/50000] s_loss:4.5880 d_loss:-9.4379 val_s_loss:5.1012 val_d_loss:-6.6873\n",
      "epoch [609/50000] s_loss:8.4995 d_loss:-8.5941 val_s_loss:7.3449 val_d_loss:-6.0962\n",
      "epoch [610/50000] s_loss:20.7969 d_loss:-10.0768 val_s_loss:21.1258 val_d_loss:-8.2906\n",
      "epoch [611/50000] s_loss:23.1163 d_loss:-8.5067 val_s_loss:21.3552 val_d_loss:-7.9374\n",
      "epoch [612/50000] s_loss:27.5425 d_loss:-8.2215 val_s_loss:27.3962 val_d_loss:-7.9006\n",
      "epoch [613/50000] s_loss:20.6277 d_loss:-8.8867 val_s_loss:21.2977 val_d_loss:-8.9236\n",
      "epoch [614/50000] s_loss:13.8291 d_loss:-8.2806 val_s_loss:12.7345 val_d_loss:-7.5930\n",
      "epoch [615/50000] s_loss:8.8438 d_loss:-8.4062 val_s_loss:8.0358 val_d_loss:-7.0134\n",
      "epoch [616/50000] s_loss:-0.2025 d_loss:-8.2293 val_s_loss:-2.5219 val_d_loss:-5.5691\n",
      "epoch [617/50000] s_loss:10.9348 d_loss:-7.9806 val_s_loss:11.3017 val_d_loss:-7.2632\n",
      "epoch [618/50000] s_loss:17.7714 d_loss:-9.0654 val_s_loss:17.3171 val_d_loss:-7.4728\n",
      "epoch [619/50000] s_loss:29.8948 d_loss:-7.7739 val_s_loss:30.6241 val_d_loss:-9.2956\n",
      "epoch [620/50000] s_loss:38.0709 d_loss:-7.9746 val_s_loss:34.8543 val_d_loss:-5.0715\n",
      "epoch [621/50000] s_loss:22.3820 d_loss:-8.5634 val_s_loss:23.5854 val_d_loss:-9.2595\n",
      "epoch [622/50000] s_loss:-7.5739 d_loss:-7.4679 val_s_loss:-7.8585 val_d_loss:-6.0858\n",
      "epoch [623/50000] s_loss:-17.8898 d_loss:-7.5218 val_s_loss:-18.2526 val_d_loss:-5.9886\n",
      "epoch [624/50000] s_loss:-14.0182 d_loss:-8.2765 val_s_loss:-14.0147 val_d_loss:-7.2773\n",
      "epoch [625/50000] s_loss:17.4100 d_loss:-7.5937 val_s_loss:16.6152 val_d_loss:-5.9472\n",
      "epoch [626/50000] s_loss:49.1936 d_loss:-8.1734 val_s_loss:49.9760 val_d_loss:-6.9602\n",
      "epoch [627/50000] s_loss:57.8808 d_loss:-8.3072 val_s_loss:54.4589 val_d_loss:-6.4325\n",
      "epoch [628/50000] s_loss:51.0065 d_loss:-7.7714 val_s_loss:45.7817 val_d_loss:-5.2539\n",
      "epoch [629/50000] s_loss:49.9879 d_loss:-8.3240 val_s_loss:48.2922 val_d_loss:-5.6601\n",
      "epoch [630/50000] s_loss:36.5107 d_loss:-7.5348 val_s_loss:34.0187 val_d_loss:-7.9866\n",
      "epoch [631/50000] s_loss:22.0723 d_loss:-8.1754 val_s_loss:21.2967 val_d_loss:-7.5153\n",
      "epoch [632/50000] s_loss:-1.7411 d_loss:-8.5372 val_s_loss:-2.5462 val_d_loss:-7.1066\n",
      "epoch [633/50000] s_loss:-16.1465 d_loss:-8.3769 val_s_loss:-16.8447 val_d_loss:-5.9213\n",
      "epoch [634/50000] s_loss:-15.7757 d_loss:-7.4548 val_s_loss:-17.5222 val_d_loss:-5.1467\n",
      "epoch [635/50000] s_loss:-3.5584 d_loss:-7.4153 val_s_loss:-3.5643 val_d_loss:-6.8842\n",
      "epoch [636/50000] s_loss:18.5301 d_loss:-8.4568 val_s_loss:19.1137 val_d_loss:-8.2377\n",
      "epoch [637/50000] s_loss:34.3761 d_loss:-7.6443 val_s_loss:34.0127 val_d_loss:-8.0608\n",
      "epoch [638/50000] s_loss:42.6347 d_loss:-8.4201 val_s_loss:42.5437 val_d_loss:-9.2453\n",
      "epoch [639/50000] s_loss:26.8371 d_loss:-8.3920 val_s_loss:27.1989 val_d_loss:-7.8287\n",
      "epoch [640/50000] s_loss:2.5762 d_loss:-8.3154 val_s_loss:2.7815 val_d_loss:-5.4486\n",
      "epoch [641/50000] s_loss:-6.7741 d_loss:-8.3015 val_s_loss:-6.8534 val_d_loss:-6.1187\n",
      "epoch [642/50000] s_loss:-5.5522 d_loss:-8.6586 val_s_loss:-5.9071 val_d_loss:-6.9839\n",
      "epoch [643/50000] s_loss:5.4320 d_loss:-8.6886 val_s_loss:5.0252 val_d_loss:-7.5733\n",
      "epoch [644/50000] s_loss:9.5357 d_loss:-8.1941 val_s_loss:8.7723 val_d_loss:-4.5893\n",
      "epoch [645/50000] s_loss:0.2557 d_loss:-8.6081 val_s_loss:0.1070 val_d_loss:-8.9184\n",
      "epoch [646/50000] s_loss:8.6631 d_loss:-9.0521 val_s_loss:7.8832 val_d_loss:-6.4377\n",
      "epoch [647/50000] s_loss:5.0069 d_loss:-8.0927 val_s_loss:4.6990 val_d_loss:-8.2706\n",
      "epoch [648/50000] s_loss:19.5207 d_loss:-8.2337 val_s_loss:18.0953 val_d_loss:-7.2330\n",
      "epoch [649/50000] s_loss:13.0979 d_loss:-8.7351 val_s_loss:12.3533 val_d_loss:-6.3609\n",
      "epoch [650/50000] s_loss:4.9213 d_loss:-8.8002 val_s_loss:4.4333 val_d_loss:-7.5055\n",
      "epoch [651/50000] s_loss:1.3646 d_loss:-8.5008 val_s_loss:0.1043 val_d_loss:-6.2120\n",
      "epoch [652/50000] s_loss:4.1229 d_loss:-9.4812 val_s_loss:3.8254 val_d_loss:-5.9660\n",
      "epoch [653/50000] s_loss:9.0311 d_loss:-7.9997 val_s_loss:10.0012 val_d_loss:-7.5149\n",
      "epoch [654/50000] s_loss:5.8080 d_loss:-8.8388 val_s_loss:4.7460 val_d_loss:-8.2664\n",
      "epoch [655/50000] s_loss:12.4124 d_loss:-9.7476 val_s_loss:11.7586 val_d_loss:-7.4780\n",
      "epoch [656/50000] s_loss:12.6851 d_loss:-8.7613 val_s_loss:11.1123 val_d_loss:-6.0952\n",
      "epoch [657/50000] s_loss:5.6298 d_loss:-8.7231 val_s_loss:4.8491 val_d_loss:-6.5901\n",
      "epoch [658/50000] s_loss:-0.6923 d_loss:-9.1000 val_s_loss:-0.9388 val_d_loss:-7.5094\n",
      "epoch [659/50000] s_loss:-3.3243 d_loss:-9.0680 val_s_loss:-4.0689 val_d_loss:-5.8539\n",
      "epoch [660/50000] s_loss:-2.8030 d_loss:-8.3152 val_s_loss:-3.0298 val_d_loss:-9.7298\n",
      "epoch [661/50000] s_loss:3.2696 d_loss:-8.8667 val_s_loss:2.5432 val_d_loss:-8.5556\n",
      "epoch [662/50000] s_loss:10.7319 d_loss:-9.0386 val_s_loss:11.2779 val_d_loss:-8.1226\n",
      "epoch [663/50000] s_loss:6.7005 d_loss:-8.8270 val_s_loss:6.0391 val_d_loss:-7.7988\n",
      "epoch [664/50000] s_loss:-4.0290 d_loss:-8.2580 val_s_loss:-5.2065 val_d_loss:-5.9980\n",
      "epoch [665/50000] s_loss:-11.8557 d_loss:-8.0003 val_s_loss:-12.3996 val_d_loss:-9.3141\n",
      "epoch [666/50000] s_loss:-6.2459 d_loss:-8.7179 val_s_loss:-6.8538 val_d_loss:-7.3623\n",
      "epoch [667/50000] s_loss:4.1402 d_loss:-8.1811 val_s_loss:2.8297 val_d_loss:-6.3600\n",
      "epoch [668/50000] s_loss:12.4907 d_loss:-9.2441 val_s_loss:11.9796 val_d_loss:-5.5030\n",
      "epoch [669/50000] s_loss:8.4598 d_loss:-9.1398 val_s_loss:7.9103 val_d_loss:-7.6157\n",
      "epoch [670/50000] s_loss:-9.1970 d_loss:-8.3137 val_s_loss:-9.4389 val_d_loss:-8.9333\n",
      "epoch [671/50000] s_loss:-11.7581 d_loss:-9.9417 val_s_loss:-12.6028 val_d_loss:-9.5761\n",
      "epoch [672/50000] s_loss:-18.8152 d_loss:-9.3399 val_s_loss:-18.4202 val_d_loss:-7.9168\n",
      "epoch [673/50000] s_loss:6.8831 d_loss:-8.2421 val_s_loss:6.5756 val_d_loss:-6.6301\n",
      "epoch [674/50000] s_loss:35.6459 d_loss:-9.0906 val_s_loss:34.9173 val_d_loss:-7.7615\n",
      "epoch [675/50000] s_loss:32.9327 d_loss:-8.9178 val_s_loss:34.1060 val_d_loss:-7.7981\n",
      "epoch [676/50000] s_loss:3.4058 d_loss:-9.2798 val_s_loss:2.9297 val_d_loss:-6.1456\n",
      "epoch [677/50000] s_loss:-24.0616 d_loss:-9.2144 val_s_loss:-23.5602 val_d_loss:-5.0857\n",
      "epoch [678/50000] s_loss:-14.3901 d_loss:-9.5408 val_s_loss:-15.0699 val_d_loss:-8.3847\n",
      "epoch [679/50000] s_loss:-7.2771 d_loss:-9.0504 val_s_loss:-9.7325 val_d_loss:-4.8800\n",
      "epoch [680/50000] s_loss:15.5593 d_loss:-8.8045 val_s_loss:14.0892 val_d_loss:-7.0542\n",
      "epoch [681/50000] s_loss:39.1619 d_loss:-8.2562 val_s_loss:38.1489 val_d_loss:-8.2792\n",
      "epoch [682/50000] s_loss:12.1652 d_loss:-9.1066 val_s_loss:11.5291 val_d_loss:-6.6238\n",
      "epoch [683/50000] s_loss:-27.4922 d_loss:-8.8699 val_s_loss:-25.3914 val_d_loss:-6.9658\n",
      "epoch [684/50000] s_loss:-36.2543 d_loss:-8.2575 val_s_loss:-34.3834 val_d_loss:-8.4894\n",
      "epoch [685/50000] s_loss:-32.0022 d_loss:-9.0829 val_s_loss:-34.3992 val_d_loss:-4.9269\n",
      "epoch [686/50000] s_loss:-5.4049 d_loss:-9.2135 val_s_loss:-6.3084 val_d_loss:-8.9502\n",
      "epoch [687/50000] s_loss:23.3179 d_loss:-9.7154 val_s_loss:20.0191 val_d_loss:-5.5228\n",
      "epoch [688/50000] s_loss:19.0318 d_loss:-9.5670 val_s_loss:18.2079 val_d_loss:-6.6956\n",
      "epoch [689/50000] s_loss:-9.9487 d_loss:-9.3145 val_s_loss:-9.6670 val_d_loss:-8.8918\n",
      "epoch [690/50000] s_loss:-36.5044 d_loss:-9.3802 val_s_loss:-36.1589 val_d_loss:-5.4663\n",
      "epoch [691/50000] s_loss:-13.8615 d_loss:-8.4499 val_s_loss:-14.3613 val_d_loss:-5.0481\n",
      "epoch [692/50000] s_loss:14.7459 d_loss:-8.5087 val_s_loss:13.6568 val_d_loss:-5.6780\n",
      "epoch [693/50000] s_loss:23.5662 d_loss:-8.6529 val_s_loss:23.7722 val_d_loss:-8.0103\n",
      "epoch [694/50000] s_loss:30.3748 d_loss:-8.9413 val_s_loss:30.2878 val_d_loss:-8.2579\n",
      "epoch [695/50000] s_loss:5.8333 d_loss:-8.9220 val_s_loss:5.0031 val_d_loss:-8.8926\n",
      "epoch [696/50000] s_loss:9.7830 d_loss:-9.3839 val_s_loss:9.2011 val_d_loss:-7.8479\n",
      "epoch [697/50000] s_loss:-9.1000 d_loss:-10.0797 val_s_loss:-8.1384 val_d_loss:-8.6452\n",
      "epoch [698/50000] s_loss:0.5016 d_loss:-9.9110 val_s_loss:0.3449 val_d_loss:-5.8370\n",
      "epoch [699/50000] s_loss:6.8242 d_loss:-9.6975 val_s_loss:5.3957 val_d_loss:-6.6325\n",
      "epoch [700/50000] s_loss:9.0882 d_loss:-9.1081 val_s_loss:8.8314 val_d_loss:-6.1657\n",
      "epoch [701/50000] s_loss:10.1940 d_loss:-9.5094 val_s_loss:10.5717 val_d_loss:-8.3526\n",
      "epoch [702/50000] s_loss:15.6852 d_loss:-9.8924 val_s_loss:16.1255 val_d_loss:-10.1137\n",
      "epoch [703/50000] s_loss:1.1071 d_loss:-9.6968 val_s_loss:1.7967 val_d_loss:-7.8481\n",
      "epoch [704/50000] s_loss:12.2511 d_loss:-8.8029 val_s_loss:10.8216 val_d_loss:-8.1488\n",
      "epoch [705/50000] s_loss:-6.6860 d_loss:-10.5405 val_s_loss:-6.1963 val_d_loss:-6.4965\n",
      "epoch [706/50000] s_loss:-20.5302 d_loss:-8.8151 val_s_loss:-20.2594 val_d_loss:-8.7770\n",
      "epoch [707/50000] s_loss:-5.9500 d_loss:-9.6909 val_s_loss:-6.3458 val_d_loss:-8.2972\n",
      "epoch [708/50000] s_loss:3.7084 d_loss:-7.4795 val_s_loss:3.9661 val_d_loss:-7.9707\n",
      "epoch [709/50000] s_loss:16.2755 d_loss:-9.7874 val_s_loss:15.9549 val_d_loss:-6.1431\n",
      "epoch [710/50000] s_loss:-5.9522 d_loss:-9.6935 val_s_loss:-6.5473 val_d_loss:-6.5293\n",
      "epoch [711/50000] s_loss:-25.1536 d_loss:-10.4297 val_s_loss:-24.8152 val_d_loss:-6.0972\n",
      "epoch [712/50000] s_loss:-26.1801 d_loss:-9.4374 val_s_loss:-25.5144 val_d_loss:-8.0610\n",
      "epoch [713/50000] s_loss:-13.2422 d_loss:-9.7685 val_s_loss:-16.0138 val_d_loss:-3.8361\n",
      "epoch [714/50000] s_loss:18.5963 d_loss:-8.6495 val_s_loss:17.4952 val_d_loss:-5.8669\n",
      "epoch [715/50000] s_loss:53.8688 d_loss:-8.8674 val_s_loss:49.3131 val_d_loss:-5.7933\n",
      "epoch [716/50000] s_loss:16.7801 d_loss:-9.1668 val_s_loss:13.2536 val_d_loss:-4.0360\n",
      "epoch [717/50000] s_loss:-39.9889 d_loss:-8.3746 val_s_loss:-39.2378 val_d_loss:-9.0930\n",
      "epoch [718/50000] s_loss:-41.4238 d_loss:-9.3440 val_s_loss:-41.0836 val_d_loss:-9.5665\n",
      "epoch [719/50000] s_loss:-40.6231 d_loss:-9.6003 val_s_loss:-39.3223 val_d_loss:-8.9111\n",
      "epoch [720/50000] s_loss:14.9577 d_loss:-8.8813 val_s_loss:15.0473 val_d_loss:-8.6357\n",
      "epoch [721/50000] s_loss:24.9920 d_loss:-8.6537 val_s_loss:24.1387 val_d_loss:-7.7943\n",
      "epoch [722/50000] s_loss:2.8567 d_loss:-9.3618 val_s_loss:1.1503 val_d_loss:-7.0532\n",
      "epoch [723/50000] s_loss:-23.9466 d_loss:-9.5330 val_s_loss:-25.7741 val_d_loss:-9.6400\n",
      "epoch [724/50000] s_loss:-30.3458 d_loss:-9.2054 val_s_loss:-31.6388 val_d_loss:-7.2969\n",
      "epoch [725/50000] s_loss:-3.6594 d_loss:-7.7400 val_s_loss:-4.9941 val_d_loss:-5.9176\n",
      "epoch [726/50000] s_loss:26.9776 d_loss:-8.6582 val_s_loss:25.5454 val_d_loss:-7.8557\n",
      "epoch [727/50000] s_loss:14.4324 d_loss:-8.4059 val_s_loss:10.6164 val_d_loss:-5.1301\n",
      "epoch [728/50000] s_loss:1.8015 d_loss:-9.1925 val_s_loss:0.9826 val_d_loss:-6.8650\n",
      "epoch [729/50000] s_loss:18.8657 d_loss:-9.5437 val_s_loss:19.4559 val_d_loss:-8.5766\n",
      "epoch [730/50000] s_loss:11.6367 d_loss:-8.1502 val_s_loss:10.8213 val_d_loss:-7.6026\n",
      "epoch [731/50000] s_loss:-37.3589 d_loss:-9.9968 val_s_loss:-39.3838 val_d_loss:-7.6455\n",
      "epoch [732/50000] s_loss:-43.9736 d_loss:-8.3958 val_s_loss:-43.7573 val_d_loss:-5.0059\n",
      "epoch [733/50000] s_loss:-2.9011 d_loss:-8.8021 val_s_loss:-4.6534 val_d_loss:-6.1323\n",
      "epoch [734/50000] s_loss:44.7495 d_loss:-10.0624 val_s_loss:40.3354 val_d_loss:-4.0878\n",
      "epoch [735/50000] s_loss:50.1686 d_loss:-9.2930 val_s_loss:50.0440 val_d_loss:-7.4964\n",
      "epoch [736/50000] s_loss:16.2139 d_loss:-9.8457 val_s_loss:16.3475 val_d_loss:-6.1270\n",
      "epoch [737/50000] s_loss:-17.4106 d_loss:-9.1292 val_s_loss:-19.2131 val_d_loss:-5.8927\n",
      "epoch [738/50000] s_loss:-21.2857 d_loss:-8.8143 val_s_loss:-21.6646 val_d_loss:-8.0096\n",
      "epoch [739/50000] s_loss:17.8129 d_loss:-9.3188 val_s_loss:16.1262 val_d_loss:-6.8718\n",
      "epoch [740/50000] s_loss:35.6974 d_loss:-8.6107 val_s_loss:35.1953 val_d_loss:-9.9791\n",
      "epoch [741/50000] s_loss:15.5372 d_loss:-8.9437 val_s_loss:15.2767 val_d_loss:-8.7427\n",
      "epoch [742/50000] s_loss:-22.9226 d_loss:-8.6555 val_s_loss:-23.9581 val_d_loss:-9.3117\n",
      "epoch [743/50000] s_loss:-36.0045 d_loss:-11.5069 val_s_loss:-35.6451 val_d_loss:-5.0664\n",
      "epoch [744/50000] s_loss:-9.3443 d_loss:-7.9136 val_s_loss:-10.9714 val_d_loss:-7.0350\n",
      "epoch [745/50000] s_loss:50.9172 d_loss:-10.8740 val_s_loss:47.3060 val_d_loss:-6.4037\n",
      "epoch [746/50000] s_loss:36.4805 d_loss:-9.5707 val_s_loss:36.1954 val_d_loss:-6.9179\n",
      "epoch [747/50000] s_loss:-15.0867 d_loss:-8.9029 val_s_loss:-14.5226 val_d_loss:-6.1280\n",
      "epoch [748/50000] s_loss:-32.7059 d_loss:-9.0049 val_s_loss:-28.4205 val_d_loss:-7.4338\n",
      "epoch [749/50000] s_loss:-1.5136 d_loss:-9.0752 val_s_loss:-1.5980 val_d_loss:-9.0603\n",
      "epoch [750/50000] s_loss:30.6769 d_loss:-8.8522 val_s_loss:29.4175 val_d_loss:-7.8960\n",
      "epoch [751/50000] s_loss:-14.7344 d_loss:-8.5729 val_s_loss:-15.8560 val_d_loss:-7.6460\n",
      "epoch [752/50000] s_loss:-39.9969 d_loss:-9.4895 val_s_loss:-39.2588 val_d_loss:-6.4953\n",
      "epoch [753/50000] s_loss:-16.4355 d_loss:-8.8354 val_s_loss:-14.6350 val_d_loss:-8.0809\n",
      "epoch [754/50000] s_loss:25.7422 d_loss:-8.6890 val_s_loss:25.8410 val_d_loss:-10.9592\n",
      "epoch [755/50000] s_loss:35.2695 d_loss:-9.6092 val_s_loss:34.4866 val_d_loss:-6.5959\n",
      "epoch [756/50000] s_loss:13.3563 d_loss:-8.7338 val_s_loss:11.8922 val_d_loss:-8.1522\n",
      "epoch [757/50000] s_loss:-10.4951 d_loss:-8.6222 val_s_loss:-11.5809 val_d_loss:-8.1886\n",
      "epoch [758/50000] s_loss:-7.4677 d_loss:-8.8502 val_s_loss:-9.2794 val_d_loss:-2.7216\n",
      "epoch [759/50000] s_loss:28.0422 d_loss:-7.6311 val_s_loss:23.4404 val_d_loss:-4.7213\n",
      "epoch [760/50000] s_loss:50.2253 d_loss:-7.9952 val_s_loss:50.4532 val_d_loss:-5.4691\n",
      "epoch [761/50000] s_loss:-52.5272 d_loss:-9.5877 val_s_loss:-54.7731 val_d_loss:-4.7614\n",
      "epoch [762/50000] s_loss:-69.1257 d_loss:-8.9984 val_s_loss:-69.5075 val_d_loss:-2.8838\n",
      "epoch [763/50000] s_loss:-15.2383 d_loss:-8.1024 val_s_loss:-16.7330 val_d_loss:-4.5000\n",
      "epoch [764/50000] s_loss:60.2401 d_loss:-8.6700 val_s_loss:60.2485 val_d_loss:-8.4420\n",
      "epoch [765/50000] s_loss:81.4246 d_loss:-9.3925 val_s_loss:79.9506 val_d_loss:-7.4068\n",
      "epoch [766/50000] s_loss:29.2294 d_loss:-7.4666 val_s_loss:30.7672 val_d_loss:-8.3880\n",
      "epoch [767/50000] s_loss:-40.5698 d_loss:-9.0942 val_s_loss:-40.6353 val_d_loss:-6.6996\n",
      "epoch [768/50000] s_loss:-44.0476 d_loss:-8.2013 val_s_loss:-45.6754 val_d_loss:-6.5463\n",
      "epoch [769/50000] s_loss:9.9436 d_loss:-8.2520 val_s_loss:9.2434 val_d_loss:-6.5886\n",
      "epoch [770/50000] s_loss:59.2756 d_loss:-8.4356 val_s_loss:56.3688 val_d_loss:-4.2606\n",
      "epoch [771/50000] s_loss:22.7975 d_loss:-8.1095 val_s_loss:23.5472 val_d_loss:-6.7048\n",
      "epoch [772/50000] s_loss:-9.2278 d_loss:-8.2931 val_s_loss:-9.4748 val_d_loss:-4.5605\n",
      "epoch [773/50000] s_loss:-28.3694 d_loss:-7.2177 val_s_loss:-28.9430 val_d_loss:-4.8194\n",
      "epoch [774/50000] s_loss:-22.3394 d_loss:-7.7958 val_s_loss:-23.3024 val_d_loss:-5.9734\n",
      "epoch [775/50000] s_loss:-4.5631 d_loss:-7.7641 val_s_loss:-5.2303 val_d_loss:-5.3146\n",
      "epoch [776/50000] s_loss:2.9944 d_loss:-7.0302 val_s_loss:2.7872 val_d_loss:-5.8666\n",
      "epoch [777/50000] s_loss:1.2315 d_loss:-6.8472 val_s_loss:0.5039 val_d_loss:-3.7132\n",
      "epoch [778/50000] s_loss:11.1089 d_loss:-6.3635 val_s_loss:10.7828 val_d_loss:-6.8131\n",
      "epoch [779/50000] s_loss:18.3778 d_loss:-6.7651 val_s_loss:18.1014 val_d_loss:-5.2535\n",
      "epoch [780/50000] s_loss:33.0609 d_loss:-7.2176 val_s_loss:32.6757 val_d_loss:-2.8653\n",
      "epoch [781/50000] s_loss:26.6375 d_loss:-7.1295 val_s_loss:23.6389 val_d_loss:-2.4820\n",
      "epoch [782/50000] s_loss:46.7754 d_loss:-6.8570 val_s_loss:44.1989 val_d_loss:-4.5406\n",
      "epoch [783/50000] s_loss:23.2207 d_loss:-7.2835 val_s_loss:20.6691 val_d_loss:-5.0511\n",
      "epoch [784/50000] s_loss:-12.5376 d_loss:-7.1597 val_s_loss:-11.8736 val_d_loss:-5.8691\n",
      "epoch [785/50000] s_loss:-65.5127 d_loss:-7.8429 val_s_loss:-66.2013 val_d_loss:-5.0833\n",
      "epoch [786/50000] s_loss:-72.3220 d_loss:-6.6986 val_s_loss:-71.4910 val_d_loss:-6.4229\n",
      "epoch [787/50000] s_loss:-24.2329 d_loss:-8.2997 val_s_loss:-23.8958 val_d_loss:-4.3265\n",
      "epoch [788/50000] s_loss:23.6355 d_loss:-7.5759 val_s_loss:23.6651 val_d_loss:-5.9797\n",
      "epoch [789/50000] s_loss:33.6968 d_loss:-7.5351 val_s_loss:34.3972 val_d_loss:-5.0460\n",
      "epoch [790/50000] s_loss:-27.5734 d_loss:-8.3006 val_s_loss:-27.2472 val_d_loss:-5.8266\n",
      "epoch [791/50000] s_loss:-61.0127 d_loss:-7.9280 val_s_loss:-59.3452 val_d_loss:-6.1389\n",
      "epoch [792/50000] s_loss:17.9210 d_loss:-6.9471 val_s_loss:18.1828 val_d_loss:-4.5304\n",
      "epoch [793/50000] s_loss:105.5036 d_loss:-8.4009 val_s_loss:99.6276 val_d_loss:-1.8584\n",
      "epoch [794/50000] s_loss:97.1621 d_loss:-7.9176 val_s_loss:86.9231 val_d_loss:-0.9369\n",
      "epoch [795/50000] s_loss:-3.8692 d_loss:-7.6898 val_s_loss:-5.9129 val_d_loss:-5.8955\n",
      "epoch [796/50000] s_loss:-67.8595 d_loss:-8.4027 val_s_loss:-67.9727 val_d_loss:-6.2598\n",
      "epoch [797/50000] s_loss:-60.5107 d_loss:-9.2117 val_s_loss:-60.6307 val_d_loss:-3.4250\n",
      "epoch [798/50000] s_loss:-23.8449 d_loss:-8.2521 val_s_loss:-22.6611 val_d_loss:-6.4851\n",
      "epoch [799/50000] s_loss:39.1785 d_loss:-6.6561 val_s_loss:34.6011 val_d_loss:-3.3067\n",
      "epoch [800/50000] s_loss:42.4364 d_loss:-7.8465 val_s_loss:38.2546 val_d_loss:-2.9956\n",
      "epoch [801/50000] s_loss:15.8096 d_loss:-9.5964 val_s_loss:18.2489 val_d_loss:-5.3959\n",
      "epoch [802/50000] s_loss:17.7748 d_loss:-7.0932 val_s_loss:18.6036 val_d_loss:-6.4758\n",
      "epoch [803/50000] s_loss:44.8656 d_loss:-8.5693 val_s_loss:43.4713 val_d_loss:-5.0563\n",
      "epoch [804/50000] s_loss:13.9771 d_loss:-7.2215 val_s_loss:12.4202 val_d_loss:-4.3250\n",
      "epoch [805/50000] s_loss:-33.6631 d_loss:-8.2568 val_s_loss:-29.8745 val_d_loss:-9.8917\n",
      "epoch [806/50000] s_loss:-39.0811 d_loss:-8.1731 val_s_loss:-41.4872 val_d_loss:-4.4419\n",
      "epoch [807/50000] s_loss:17.7509 d_loss:-9.1365 val_s_loss:16.4418 val_d_loss:-6.6393\n",
      "epoch [808/50000] s_loss:56.2251 d_loss:-7.5672 val_s_loss:56.8204 val_d_loss:-11.6493\n",
      "epoch [809/50000] s_loss:23.8267 d_loss:-7.9365 val_s_loss:24.3575 val_d_loss:-6.8602\n",
      "epoch [810/50000] s_loss:-30.5673 d_loss:-7.9525 val_s_loss:-32.3883 val_d_loss:-6.0101\n",
      "epoch [811/50000] s_loss:-69.4783 d_loss:-6.5603 val_s_loss:-69.6868 val_d_loss:-2.3123\n",
      "epoch [812/50000] s_loss:-40.6807 d_loss:-7.4305 val_s_loss:-39.9416 val_d_loss:-3.9494\n",
      "epoch [813/50000] s_loss:57.5530 d_loss:-7.4499 val_s_loss:54.6922 val_d_loss:-8.1646\n",
      "epoch [814/50000] s_loss:81.1560 d_loss:-7.7593 val_s_loss:81.6884 val_d_loss:-10.4603\n",
      "epoch [815/50000] s_loss:25.8055 d_loss:-8.0906 val_s_loss:25.7026 val_d_loss:-7.1417\n",
      "epoch [816/50000] s_loss:-53.0729 d_loss:-7.6047 val_s_loss:-49.2705 val_d_loss:-8.0846\n",
      "epoch [817/50000] s_loss:-81.8129 d_loss:-7.1591 val_s_loss:-80.0491 val_d_loss:-3.8286\n",
      "epoch [818/50000] s_loss:-40.5803 d_loss:-7.2910 val_s_loss:-42.5439 val_d_loss:-3.5591\n",
      "epoch [819/50000] s_loss:40.4331 d_loss:-7.1326 val_s_loss:32.7435 val_d_loss:0.8979\n",
      "epoch [820/50000] s_loss:36.9692 d_loss:-8.0416 val_s_loss:35.2145 val_d_loss:-2.7024\n",
      "epoch [821/50000] s_loss:2.0977 d_loss:-8.4581 val_s_loss:1.9692 val_d_loss:-6.2364\n",
      "epoch [822/50000] s_loss:-2.4891 d_loss:-7.4320 val_s_loss:-3.6577 val_d_loss:-7.4547\n",
      "epoch [823/50000] s_loss:-10.2011 d_loss:-7.9668 val_s_loss:-8.6064 val_d_loss:-5.0588\n",
      "epoch [824/50000] s_loss:-2.1898 d_loss:-7.3433 val_s_loss:-3.6483 val_d_loss:-5.9779\n",
      "epoch [825/50000] s_loss:2.5267 d_loss:-6.2397 val_s_loss:1.4077 val_d_loss:-5.8001\n",
      "epoch [826/50000] s_loss:18.0115 d_loss:-6.7347 val_s_loss:18.7016 val_d_loss:-6.8814\n",
      "epoch [827/50000] s_loss:30.5623 d_loss:-6.9914 val_s_loss:30.4025 val_d_loss:-5.9554\n",
      "epoch [828/50000] s_loss:28.4066 d_loss:-7.0317 val_s_loss:29.1675 val_d_loss:-8.6974\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):    \n",
    "    ######## GAN ################\n",
    "    one = torch.FloatTensor([1])\n",
    "    mone = one * -1\n",
    "    \n",
    "    one = one.cuda()\n",
    "    mone = mone.cuda()\n",
    "    \n",
    "    one = one.mean()\n",
    "    mone = mone.mean()\n",
    "    ## ==== GAN --> D =====\n",
    "    for i in range(3):\n",
    "        for index, img in enumerate(train_loader):\n",
    "            AE.eval(), S.train(), D.train()\n",
    "\n",
    "            img = Variable(img).cuda()\n",
    "\n",
    "            # ====== AE ======\n",
    "            blur_image = AE(img)\n",
    "\n",
    "            _bs, _c, _w, _h = blur_image.shape\n",
    "            noise = torch.zeros(_bs, 1, _w, _h )\n",
    "            noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "            noise = noise.cuda()\n",
    "\n",
    "            blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "            fake_image = S(blur_image_with_noise) # 當成是 residual\n",
    "            \n",
    "            fake_image = fake_image + blur_image # blur image + residual\n",
    "            \n",
    "            fake_pair = torch.cat([img, fake_image], 1)\n",
    "            real_pair = torch.cat([img, img[torch.randperm(img.size(0)), :, :, :]], 1) if UPSET else torch.cat([img, img], 1)\n",
    "            # ====== Train D ======\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            optimizer_AE.zero_grad()\n",
    "            optimizer_S.zero_grad()\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "\n",
    "            real_D = D(real_pair)\n",
    "            real_D = real_D.mean()\n",
    "            real_D.backward(mone)\n",
    "\n",
    "\n",
    "            fake_D = D(fake_pair)\n",
    "            fake_D = fake_D.mean()\n",
    "            fake_D.backward(one)\n",
    "\n",
    "            gradient_penalty = calc_gradient_penalty(D, real_pair, fake_pair)\n",
    "            gradient_penalty.backward()\n",
    "\n",
    "            cost_D = fake_D - real_D + gradient_penalty\n",
    "            Wasserstein_D = real_D - fake_D\n",
    "            optimizer_D.step()\n",
    "    \n",
    "    ## ==== GAN --> G =====\n",
    "    for index, img in enumerate(train_loader):\n",
    "        AE.eval(), S.train(), D.train()\n",
    "\n",
    "        img = Variable(img).cuda()\n",
    "        # ======AE======\n",
    "        blur_image = AE(img)\n",
    "\n",
    "        _bs, _c, _w, _h = blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "        fake_image = S(blur_image_with_noise)\n",
    "        \n",
    "        fake_image = fake_image + blur_image\n",
    "        \n",
    "        fake_pair = torch.cat([img, fake_image], 1)\n",
    "        # ====== Train G ======\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        G = D(fake_pair)\n",
    "        G = G.mean()\n",
    "        \n",
    "        optimizer_AE.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        G.backward(mone)\n",
    "        \n",
    "        cost_G = -G\n",
    "        optimizer_S.step()\n",
    "        \n",
    "    \n",
    "    # validation set\n",
    "    for index, val_img in enumerate(val_loader):\n",
    "        AE.eval(), S.eval(), D.eval()\n",
    "\n",
    "        val_img = Variable(val_img).cuda()\n",
    "        # ======AE======\n",
    "        val_blur_image = AE(val_img)\n",
    "\n",
    "        _bs, _c, _w, _h = val_blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        val_blur_image_with_noise = torch.cat([val_blur_image, noise], 1)\n",
    "\n",
    "        val_fake_image = S(val_blur_image_with_noise)       \n",
    "        val_fake_image = val_fake_image + val_blur_image\n",
    "        \n",
    "        \n",
    "        val_fake_pair = torch.cat([val_img, val_fake_image], 1)\n",
    "        val_real_pair = torch.cat([val_img, val_img[torch.randperm(val_img.size(0)), :, :, :]], 1) if UPSET else torch.cat([val_img, val_img], 1)\n",
    "        \n",
    "        val_real_D = D(val_real_pair)\n",
    "        val_real_D = val_real_D.mean()\n",
    "        \n",
    "        val_fake_D = D(val_fake_pair)\n",
    "        val_fake_D = val_fake_D.mean()\n",
    "        \n",
    "        val_gradient_penalty = calc_gradient_penalty(D, val_real_pair, val_fake_pair)\n",
    "        \n",
    "        # =========== Losses =========\n",
    "        val_Wasserstein_D = val_real_D - val_fake_D\n",
    "        \n",
    "        val_cost_G = -val_fake_D\n",
    "        val_cost_D = val_fake_D - val_real_D + val_gradient_penalty\n",
    "    \n",
    "    # evaluate\n",
    "    test_total_AUC = 0\n",
    "    test_total_AUC2 = 0\n",
    "    test_total_image = 0\n",
    "\n",
    "    for index, (test_img, mask) in enumerate(test_loader):\n",
    "        AE.eval(), S.eval(), D.eval()\n",
    "        test_img = Variable(test_img).cuda()\n",
    "        test_blur_image = AE(test_img)\n",
    "\n",
    "        _bs, _c, _w, _h = test_blur_image.shape\n",
    "        noise = torch.zeros(_bs, 1, _w, _h )\n",
    "        noise = noise + (0.01**0.5)*torch.randn(_bs, 1, _w, _h)\n",
    "        noise = noise.cuda()\n",
    "\n",
    "        test_blur_image_with_noise = torch.cat([test_blur_image, noise], 1)\n",
    "\n",
    "        test_fake_image = S(test_blur_image_with_noise)       \n",
    "        test_fake_image = test_fake_image + test_blur_image\n",
    "\n",
    "        # 計算 dif (相似度以及 L2)\n",
    "        dif, _ = perceptual_loss.forward(test_fake_image, test_img)\n",
    "        l2Dif = L2_loss(test_fake_image, test_img)\n",
    "        l2Dif = torch.mean(l2Dif, 1, True)\n",
    "        \n",
    "        pred_mask2 = difNormalize(dif[0].cpu().detach().numpy())\n",
    "        pred_mask2 = pred_mask2.flatten()\n",
    "        \n",
    "        pred_mask = difNormalize(dif[0].cpu().detach().numpy() * l2Dif[0].cpu().detach().numpy())\n",
    "        pred_mask = pred_mask.flatten()\n",
    "\n",
    "        mask = torch.mean(mask, 1, True)\n",
    "        true_mask = mask[0].cpu().detach().numpy().flatten()\n",
    "        true_mask = true_mask.astype(int)\n",
    "\n",
    "        AUC = roc_auc_score(true_mask, pred_mask)\n",
    "        AUC2 = roc_auc_score(true_mask, pred_mask2)\n",
    "\n",
    "        test_total_AUC += AUC\n",
    "        test_total_AUC2 += AUC2\n",
    "        test_total_image += 1\n",
    "    \n",
    "    # =================== GAN log========================\n",
    "    print('epoch [{}/{}] s_loss:{:.4f} d_loss:{:.4f} val_s_loss:{:.4f} val_d_loss:{:.4f}'.format(epoch+1, num_epochs, cost_G.item(), cost_D.item(), val_cost_G.item(), val_cost_D.item()))\n",
    "    writer.add_scalars('eval', {\n",
    "        \"auc_roc_score\": test_total_AUC / test_total_image,\n",
    "        \"auc_roc_score(w/o L2)\": test_total_AUC2 / test_total_image,\n",
    "    }, epoch)\n",
    "    \n",
    "    writer.add_scalars('loss', {\n",
    "        \"Wasserstein Distance\": Wasserstein_D.item(),\n",
    "        \"Val Wasserstein Distance\": val_Wasserstein_D.item(),\n",
    "        \"gradient penalty\": gradient_penalty,\n",
    "        \"val gradient penalty\": val_gradient_penalty\n",
    "    }, epoch)\n",
    "    \n",
    "    writer.add_scalars('gan loss', {\n",
    "        \"g_loss\": cost_G.item(),\n",
    "        \"d_loss\": cost_D.item(),\n",
    "        \"val_g_loss\": val_cost_G.item(),\n",
    "        \"val_d_loss\": val_cost_D.item()\n",
    "    }, epoch)\n",
    "\n",
    "    writer.add_images('Blur', blur_image, epoch)\n",
    "    writer.add_images('Reconstruct', fake_image, epoch)\n",
    "    writer.add_images('Origin', img, epoch)\n",
    "\n",
    "    writer.add_images('Val Blur', val_blur_image, epoch)\n",
    "    writer.add_images('Val Reconstruct', val_fake_image, epoch)\n",
    "    writer.add_images('Val Origin', val_img, epoch)\n",
    "\n",
    "\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        if not os.path.exists('./save_weight/{}'.format(expName)):\n",
    "            os.makedirs('./save_weight/{}'.format(expName))\n",
    "        torch.save(S.state_dict(), './save_weight/{}/S_{}.npy'.format(expName, epoch))\n",
    "        torch.save(D.state_dict(), './save_weight/{}/D_{}.npy'.format(expName, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE.eval()\n",
    "S.eval()\n",
    "for index, img in enumerate(test_loader):\n",
    "    test_img = Variable(img[0]).cuda()\n",
    "\n",
    "    # ======AE======\n",
    "    blur_image = AE(test_img)\n",
    "    \n",
    "    noise = torch.zeros(blur_image.shape[0], 1, blur_image.shape[2], blur_image.shape[3] )\n",
    "    noise = noise + (0.01**0.5)*torch.randn(blur_image.shape[0], 1, blur_image.shape[2], blur_image.shape[3])\n",
    "    noise = noise.cuda()\n",
    "    blur_image_with_noise = torch.cat([blur_image, noise], 1)\n",
    "    fake_image = S(blur_image_with_noise)\n",
    "    \n",
    "    \n",
    "    vutils.save_image(fake_image[0], './test_result/{}_simulated.png'.format(index))\n",
    "    vutils.save_image(blur_image[0], './test_result/{}_blur.png'.format(index))\n",
    "    vutils.save_image(test_img, './test_result/{}_origin.png'.format(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
