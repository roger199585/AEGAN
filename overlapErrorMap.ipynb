{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image converter\n",
    "\n",
    "- 將 MVTect 的 dataset 資料夾中所有圖片轉換成 256x256\n",
    "- 生成資料的時候連同 augmentation 的資料也一同生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from skimage.transform import rotate, AffineTransform, warp, resize\n",
    "from skimage.util import random_noise\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPES = [\"bottle\", \"cable\", \"capsule\", \"carpet\", \"grid\", \"hazelnut\", \"leather\", \"metal_nut\", \"pill\", \"screw\", \"tile\", \"toothbrush\", \"transistor\", \"wood\", \"zipper\"]\n",
    "TYPES = [\"bottle\"]\n",
    "ROOT = 'MVTec/'\n",
    "SIZE = (256, 256)\n",
    "MESSUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResizeImage(im, savePath):\n",
    "    image_resized = resize(im, SIZE, anti_aliasing=True)\n",
    "    io.imsave(fname=savePath, arr=image_resized)\n",
    "\n",
    "def saveRotateImage(im, savePath):\n",
    "    angles = [90, 180, 270]\n",
    "    image_resized = resize(im, SIZE, anti_aliasing=True)\n",
    "    \n",
    "    for angle in angles:\n",
    "        image_rotated = rotate(image_resized, angle=angle)\n",
    "        io.imsave(fname=savePath[:-4]+'_'+str(angle)+'.png', arr=image_rotated)\n",
    "\n",
    "def saveFlipImage(im, savePath):\n",
    "    image_resized = resize(im, SIZE, anti_aliasing=True)\n",
    "    \n",
    "    image_flipLR = np.fliplr(image_resized)\n",
    "    image_flipUD = np.flipud(image_resized)\n",
    "    \n",
    "    io.imsave(fname=savePath[:-4]+'_LR.png', arr=image_flipLR)\n",
    "    io.imsave(fname=savePath[:-4]+'_UD.png', arr=image_flipUD)\n",
    "\n",
    "def saveNoiseImage(im, savePath, sigma=0.155):\n",
    "    image_resized = resize(im, SIZE, anti_aliasing=True)\n",
    "    \n",
    "    image_random_noise = random_noise(image_resized, var=sigma**2)\n",
    "    io.imsave(fname=savePath, arr=image_random_noise)\n",
    "\n",
    "def saveBlueImage(im, savePath, sigma=1.5):\n",
    "    image_resized = resize(im, SIZE, anti_aliasing=True)\n",
    "    \n",
    "    image_blurred = gaussian(image_resized, sigma=sigma, multichannel=True)\n",
    "    io.imsave(fname=savePath, arr=image_blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "# create training set\n",
    "\n",
    "for _type in TYPES:\n",
    "    trainDataPath = ROOT+_type+'/train/good/'\n",
    "    trainResizeDataPath = ROOT+_type+'/train_resize/train/'\n",
    "    valResizeDataPath = ROOT+_type+'/train_resize/validation/'\n",
    "    \n",
    "    trainImages = os.listdir(trainDataPath)\n",
    "    trainImages = [img for img in trainImages if img.endswith('.png')]\n",
    "    random.shuffle(trainImages) if MESSUP else trainImages\n",
    "    \n",
    "    for index, imageName in enumerate(trainImages):\n",
    "        image = io.imread(trainDataPath + imageName)\n",
    "\n",
    "        # CheckDir\n",
    "        if not os.path.isdir(trainResizeDataPath):\n",
    "            os.makedirs(trainResizeDataPath)\n",
    "            os.makedirs(ROOT+_type+'/train_resize/validation')\n",
    "            \n",
    "        \n",
    "        savePath = valResizeDataPath if index < len(trainImages) // 10 else trainResizeDataPath\n",
    "        \n",
    "        # Save Image\n",
    "        saveResizeImage(image, savePath+imageName)\n",
    "#         saveRotateImage(image, savePath+imageName[:-4]+'_rotated.png')\n",
    "#         saveFlipImage(image, savePath+imageName[:-4]+'_flipped.png')\n",
    "#         saveNoiseImage(image, savePath+imageName[:-4]+'_noised.png')\n",
    "#         saveBlueImage(image, savePath+imageName[:-4]+'_blurred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing set\n",
    "for _type in TYPES:\n",
    "    testDataPath = ROOT+_type+'/test/'\n",
    "    testResizeDataPath = ROOT+_type+'/test_resize/'\n",
    "    \n",
    "    gtDataPath = ROOT+_type+'/ground_truth/'\n",
    "    gtResizedDataPath = ROOT+_type+'/ground_truth_resize/'\n",
    "    \n",
    "    testDataType = os.listdir(testDataPath)\n",
    "    \n",
    "    if not os.path.isdir(testResizeDataPath):\n",
    "        os.makedirs(testResizeDataPath)\n",
    "        os.makedirs(testResizeDataPath+'all')\n",
    "    if not os.path.isdir(gtResizedDataPath):\n",
    "        os.makedirs(gtResizedDataPath)\n",
    "        os.makedirs(gtResizedDataPath+'all')\n",
    "        \n",
    "    \n",
    "    index = 0\n",
    "    for anomalyType in testDataType:\n",
    "        imagePath = testDataPath+anomalyType+'/' \n",
    "        savePath = testResizeDataPath+anomalyType+'/'\n",
    "        \n",
    "        gtPath = gtDataPath+anomalyType+'/' \n",
    "        gtSavePath = gtResizedDataPath+anomalyType+'/'\n",
    "        \n",
    "        if not os.path.isdir(savePath):\n",
    "            os.makedirs(savePath)\n",
    "        if not os.path.isdir(gtSavePath):\n",
    "            os.makedirs(gtSavePath)\n",
    "        \n",
    "        testImages = os.listdir(imagePath)\n",
    "        for imageName in testImages:\n",
    "            if imageName.endswith('.png'):\n",
    "                im = Image.open(imagePath+imageName)\n",
    "                im = im.resize(SIZE)\n",
    "                im.save(savePath + imageName)\n",
    "                \n",
    "                if anomalyType != 'good':\n",
    "                    im.save(testResizeDataPath+'all/'+str(index)+'.png')\n",
    "                    _gt = Image.open(gtPath+imageName[:-4]+'_mask.png')\n",
    "                    _gt = _gt.resize(SIZE)\n",
    "                    _gt.save(gtSavePath+imageName[:-4]+'_mask.png')\n",
    "                    _gt.save(gtResizedDataPath+'all/'+str(index)+'.png')\n",
    "                \n",
    "                index+=1\n",
    "            else:\n",
    "                print(imagePath+imageName, \"is not a picture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 3, 123, 1, 3, 123, 0, 2, 54, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "a = [1, 2, 3, 0, 1, 2, 0, 54,3, 3, 123,123]\n",
    "random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask generater\n",
    "\n",
    "1. Test 用的，用來生成圖片的 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定\n",
    "image_size = (256, 256)\n",
    "mask_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = numpy.uint8(numpy.zeros(image_size))\n",
    "m = numpy.uint8(255*numpy.ones(mask_size))\n",
    "\n",
    "divisor = numpy.uint8(255*numpy.zeros(image_size))\n",
    "x = 0\n",
    "y = 0\n",
    "count = 0\n",
    "while x <= 192 and y <= 192:\n",
    "    background = Image.fromarray(bg)\n",
    "    mask = Image.fromarray(m)\n",
    "\n",
    "    background.paste(mask, (x, y))\n",
    "    divisor = divisor + (numpy.array(background.getdata()).reshape(background.size[0], background.size[1])/255).astype(numpy.int8)\n",
    "    #background.save('MVTec/mask/' + str(count) +'.png')\n",
    "    x += 32\n",
    "    if x == 224:\n",
    "        x = 0\n",
    "        y += 32\n",
    "    count += 1\n",
    "    \n",
    "divisor = numpy.reshape(divisor, (1,1,256,256))\n",
    "tmp = divisor\n",
    "divisor = numpy.concatenate((divisor, tmp), axis=1)\n",
    "divisor = numpy.concatenate((divisor, tmp), axis=1)\n",
    "divisor = torch.from_numpy(divisor)\n",
    "#Image.fromarray(divisor,'RGB').save('MVTec/mask/divisor.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Image' and 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2f91f349886b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackground\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbackground\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MVTec/mask/test.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Image' and 'Image'"
     ]
    }
   ],
   "source": [
    "'''bg = numpy.uint8(numpy.zeros(mask_size))\n",
    "m = numpy.uint8(255*numpy.ones(mask_size))\n",
    "background = Image.fromarray(bg)\n",
    "mask = Image.fromarray(m)\n",
    "test = background + mask + background + mask\n",
    "test.save('MVTec/mask/test.png')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test image generater\n",
    "1. 生成 inpaint 後的圖片\n",
    "2. 會將原始圖片切成 16 等分，每一等分都丟進去 netG 進行 inpaint，之後 16 快圖片拼起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from model.networks import Generator\n",
    "from utils.tools import get_config, is_image_file, default_loader, normalize, get_model_list\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/config.yaml\"\n",
    "seed = random.randint(1, 10000)\n",
    "root = \"MVTec/grid/test_resize/all/\" #capsule\n",
    "# root = \"MVTec/grid/train_resize/\"\n",
    "maskRoot = \"MVTec/mask2/\"\n",
    "outputPath = \"output/\"\n",
    "iteration=0 #85000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 4650\n",
      "Configuration: {'dataset_name': 'MVTec/grid_withPerceptualSimilarity_20200715/', 'data_with_subfolder': False, 'train_data_path': 'MVTec/grid/train_resize', 'val_data_path': None, 'resume': None, 'batch_size': 16, 'image_shape': [256, 256, 3], 'mask_shape': [64, 64], 'mask_batch_same': True, 'max_delta_shape': [32, 32], 'margin': [0, 0], 'discounted_mask': True, 'spatial_discounting_gamma': 0.9, 'random_crop': True, 'mask_type': 'hole', 'mosaic_unit_size': 12, 'expname': 'benchmark', 'cuda': True, 'gpu_ids': [0], 'num_workers': 32, 'lr': 0.0001, 'd_lr': 1e-05, 'beta1': 0.5, 'beta2': 0.9, 'n_critic': 5, 'niter': 500000, 'print_iter': 100, 'viz_iter': 1000, 'viz_max_out': 16, 'snapshot_save_iter': 5000, 'coarse_l1_alpha': 1.2, 'l1_loss_alpha': 1.2, 'ae_loss_alpha': 1.2, 'myd_loss_alpha': 0.5, 'global_wgan_loss_alpha': 1.0, 'gan_loss_alpha': 0.001, 'wgan_gp_lambda': 10, 'netG': {'input_dim': 3, 'ngf': 32}, 'netD': {'input_dim': 3, 'ndf': 64}}\n",
      "Saved the inpainted result to output/5.png\n",
      "Saved the inpainted result to output/10.png\n",
      "Saved the inpainted result to output/12.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8869ed342960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# Define the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mnetG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'netG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mnetG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# Resume weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiching/AD/model/networks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, use_cuda, device_ids)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoarse_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoarseGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFineGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiching/AD/model/networks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, cnum, use_cuda, device_ids)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# cnum*4 x 64 x 64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmconv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         self.contextul_attention = ContextualAttention(ksize=3, stride=1, rate=2, fuse_k=3, softmax_scale=10,\n\u001b[1;32m    125\u001b[0m                                                        fuse=True, use_cuda=self.use_cuda, device_ids=self.device_ids)\n",
      "\u001b[0;32m/home/yiching/AD/model/networks.py\u001b[0m in \u001b[0;36mgen_conv\u001b[0;34m(input_dim, output_dim, kernel_size, stride, padding, rate, activation)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mconv_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     )\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiching/AD/model/networks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, output_dim, kernel_size, stride, padding, conv_padding, dilation, weight_norm, norm, activation, pad_type, transpose)\u001b[0m\n\u001b[1;32m    540\u001b[0m             self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride,\n\u001b[1;32m    541\u001b[0m                                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                                   bias=self.use_bias)\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\u001b[0m\n\u001b[1;32m    313\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    314\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             False, _pair(0), groups, bias)\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = get_config(config_path)\n",
    "\n",
    "# CUDA configuration\n",
    "cuda = config['cuda']\n",
    "device_ids = config['gpu_ids']\n",
    "if cuda:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(i) for i in device_ids)\n",
    "    device_ids = list(range(len(device_ids)))\n",
    "    config['gpu_ids'] = device_ids\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Set random seed\n",
    "print(\"Random seed: {}\".format(seed))\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(\"Configuration: {}\".format(config))\n",
    "\n",
    "# 生成的部分\n",
    "# 1. 從 checkpoint 裡面找到 weight 載入 Generator\n",
    "with torch.no_grad():\n",
    "    # Read all image name from root\n",
    "    imageNames = os.listdir(root)\n",
    "\n",
    "    for name in imageNames:\n",
    "        if is_image_file(root + name):\n",
    "            inpainted_image = torch.zeros(1,3,256,256)\n",
    "            error_counts = torch.zeros(1,3,256,256)\n",
    "            maskNames = os.listdir(maskRoot)\n",
    "            for maskName in maskNames:\n",
    "                if maskName=='.ipynb_checkpoints':\n",
    "                    continue\n",
    "                # Test a single masked image with a given mask\n",
    "                origin_img = default_loader(root+name)\n",
    "                x = default_loader(root+name)\n",
    "                mask = default_loader(maskRoot+maskName)\n",
    "                \n",
    "                x = transforms.Resize(config['image_shape'][:-1])(x)\n",
    "                x = transforms.CenterCrop(config['image_shape'][:-1])(x)\n",
    "                mask = transforms.Resize(config['image_shape'][:-1])(mask)\n",
    "                mask = transforms.CenterCrop(config['image_shape'][:-1])(mask)\n",
    "                origin_img = transforms.Resize(config['image_shape'][:-1])(origin_img)\n",
    "                origin_img = transforms.CenterCrop(config['image_shape'][:-1])(origin_img)\n",
    "\n",
    "                x = transforms.ToTensor()(x)\n",
    "                origin_img = transforms.ToTensor()(origin_img)\n",
    "                mask = transforms.ToTensor()(mask)[0].unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "                x = normalize(x)\n",
    "                x = x * (1. - mask)\n",
    "                x = x.unsqueeze(dim=0)\n",
    "\n",
    "                origin_img = normalize(origin_img)\n",
    "                origin_img = origin_img.unsqueeze(dim=0)\n",
    "\n",
    "                mask = mask.unsqueeze(dim=0)\n",
    "\n",
    "                # Set checkpoint path\n",
    "                checkpoint_path = os.path.join('checkpoints', config['dataset_name'], config['mask_type'] + '_' + config['expname'])\n",
    "\n",
    "                # Define the trainer\n",
    "                netG = Generator(config['netG'], cuda, device_ids)\n",
    "                netG = netG.cuda()\n",
    "                # Resume weight\n",
    "                last_model_name = get_model_list(checkpoint_path, \"gen\", iteration=iteration)\n",
    "                netG.load_state_dict(torch.load(last_model_name))\n",
    "                model_iteration = int(last_model_name[-11:-3])\n",
    "\n",
    "                if cuda:\n",
    "                    netG = nn.parallel.DataParallel(netG, device_ids=device_ids)\n",
    "                    x = x.cuda()\n",
    "                    mask = mask.cuda()\n",
    "                    origin_img = origin_img.cuda()\n",
    "\n",
    "                # Inference\n",
    "                x1, x2, offset_flow = netG(x, mask)\n",
    "\n",
    "                inpainted_result = x2 * mask + x\n",
    "                inpainted_patten = x2 * mask\n",
    "                \n",
    "                crop_origin_img = origin_img * mask\n",
    "                \n",
    "                error = torch.abs(crop_origin_img - inpainted_patten)\n",
    "                inpainted_image += inpainted_patten.cpu() \n",
    "                error_counts += error.cpu()\n",
    "            #vutils.save_image(inpainted_image, outputPath+name[:-4]+'_inpainted_nodivisor.png', padding=0, normalize=True)\n",
    "            inpainted_image = torch.div(inpainted_image.float(),divisor.float())\n",
    "            error_counts = torch.div(error_counts.float(),divisor.float())\n",
    "            vutils.save_image(inpainted_image, outputPath+name[:-4]+'_inpainted.png', padding=0, normalize=True)\n",
    "            vutils.save_image(origin_img, outputPath+name, padding=0, normalize=True)\n",
    "            vutils.save_image(error_counts, outputPath+name[:-4]+'_error.png', padding=0, normalize=True)\n",
    "            print(\"Saved the inpainted result to {}\".format(outputPath+name))\n",
    "        else:\n",
    "            print(\"{} is not an image file.\".format(root+name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
